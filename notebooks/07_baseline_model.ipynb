{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed49630",
   "metadata": {},
   "source": [
    "# Baseline Models for Theme Park Wait Time Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082c6f89",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define consistent colors for plots\n",
    "TRAIN_COLOR = 'steelblue'\n",
    "TRAIN_FILL_COLOR = 'steelblue'\n",
    "TRAIN_FILL_ALPHA = 0.3\n",
    "VAL_COLOR = 'coral'\n",
    "VAL_FILL_COLOR = 'coral'\n",
    "VAL_FILL_ALPHA = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c549cad7",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Preprocessing\n",
    "\n",
    "We'll use the same preprocessing as the Prophet model for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10de6a70",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_parquet(file_path)\n",
    "    return data\n",
    "\n",
    "def add_features(data):\n",
    "    data['hour'] = data['timestamp'].dt.hour\n",
    "    data['minute'] = data['timestamp'].dt.minute\n",
    "    data['time_key'] = data['hour'] * 60 + data['minute']\n",
    "    data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
    "    data['month'] = data['timestamp'].dt.month\n",
    "    data['time_key'] = data['hour'] * 60 + data['minute']\n",
    "    return data\n",
    "\n",
    "def check_for_missing_values(data):\n",
    "    missing_values = data.isnull().sum()\n",
    "    if missing_values.any():\n",
    "        print(\"Missing values found in the dataset:\")\n",
    "        print(missing_values[missing_values > 0])\n",
    "    else:\n",
    "        print(\"No missing values found in the dataset.\")\n",
    "    return missing_values\n",
    "\n",
    "def split_data(data, train_years, val_year, test_year):\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    \n",
    "    train_data = data[data['timestamp'].dt.year.isin(train_years)]\n",
    "    val_data = data[data['timestamp'].dt.year == val_year]\n",
    "    test_data = data[data['timestamp'].dt.year == test_year]\n",
    "    \n",
    "    print(f\"Train data size: {len(train_data)}\")\n",
    "    print(f\"Validation data size: {len(val_data)}\")\n",
    "    print(f\"Test data size: {len(test_data)}\")\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def filter_ride_data(data, ride_name):\n",
    "    return data[data[f'ride_name_{ride_name}'] == True].copy()\n",
    "\n",
    "def get_all_rides(data):\n",
    "    ride_columns = [col for col in data.columns if col.startswith('ride_name_')]\n",
    "    return [col.replace('ride_name_', '') for col in ride_columns]\n",
    "\n",
    "def filter_to_operating_hours(ride_data):\n",
    "    # Determine operating hours from data where wait times > 0\n",
    "    operating_hours = ride_data[ride_data[\"wait_time\"] > 0].groupby(\n",
    "        ride_data[\"timestamp\"].dt.date\n",
    "    )[\"timestamp\"].agg(['min', 'max']).reset_index()\n",
    "    \n",
    "    # Extract opening and closing hours\n",
    "    operating_hours['opening_hour'] = pd.to_datetime(operating_hours['min']).dt.hour\n",
    "    operating_hours['closing_hour'] = pd.to_datetime(operating_hours['max']).dt.hour\n",
    "    \n",
    "    # Set reasonable boundaries for operating hours\n",
    "    operating_hours['opening_hour'] = operating_hours['opening_hour'].clip(lower=9, upper=11)\n",
    "    operating_hours['closing_hour'] = operating_hours['closing_hour'].clip(lower=17, upper=21)\n",
    "    \n",
    "    # Create date-to-hours mapping\n",
    "    date_to_hours = {}\n",
    "    for _, row in operating_hours.iterrows():\n",
    "        date_to_hours[row['timestamp']] = (row['opening_hour'], row['closing_hour'])\n",
    "    \n",
    "    # Filter data to operating hours only\n",
    "    def is_operating_hour(timestamp):\n",
    "        date = timestamp.date()\n",
    "        if date not in date_to_hours:\n",
    "            return 0\n",
    "        \n",
    "        open_hour, close_hour = date_to_hours[date]\n",
    "        hour = timestamp.hour\n",
    "        return 1 if open_hour <= hour < close_hour else 0\n",
    "    \n",
    "    ride_data['operating_hour'] = ride_data['timestamp'].apply(is_operating_hour)\n",
    "    ride_data = ride_data[ride_data['operating_hour'] == 1]\n",
    "    ride_data = ride_data.drop(columns=[\"operating_hour\"])\n",
    "    \n",
    "    return ride_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a195aaea",
   "metadata": {},
   "source": [
    "## Holiday Effects\n",
    "\n",
    "We'll create the holiday dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e410f70",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_holiday_dataframes(data):\n",
    "    holiday_dfs = []\n",
    "    \n",
    "    # Process country holidays\n",
    "    for country in ['swiss', 'german', 'french']:\n",
    "        holiday_col = f\"is_{country}_holiday\"\n",
    "        if holiday_col in data.columns:\n",
    "            country_holidays = data.loc[data[holiday_col] == 1, [\"timestamp\"]]\n",
    "            if len(country_holidays) > 0:\n",
    "                country_holidays[\"timestamp\"] = pd.to_datetime(country_holidays[\"timestamp\"]).dt.date\n",
    "                country_holidays = country_holidays.drop_duplicates(subset=[\"timestamp\"])\n",
    "                country_holidays[\"holiday\"] = f\"{country}_holiday\"\n",
    "                holiday_dfs.append(country_holidays.reset_index(drop=True))\n",
    "    # Combine all holidays\n",
    "    if holiday_dfs:\n",
    "        all_holidays = pd.concat(holiday_dfs)\n",
    "        all_holidays[\"timestamp\"] = pd.to_datetime(all_holidays[\"timestamp\"])\n",
    "        return all_holidays.sort_values(by=[\"timestamp\"]).reset_index(drop=True)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38ee93e",
   "metadata": {},
   "source": [
    "## Helper Functions for Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f5a148",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def post_process_forecast(forecast, closed_data):\n",
    "    \"\"\"Apply corrections to forecasted values.\"\"\"\n",
    "    forecast = forecast.copy()\n",
    "    \n",
    "    # Set predictions to zero during known closures (if closed_data has such info)\n",
    "    if 'closed' in closed_data.columns:\n",
    "        closed_mask = forecast['timestamp'].isin(closed_data.loc[closed_data['closed'] == 1, 'timestamp'])\n",
    "        forecast.loc[closed_mask, 'wait_time'] = 0\n",
    "    \n",
    "    # Correct negative predictions\n",
    "    if 'wait_time' in forecast.columns:\n",
    "        negative_mask = forecast['wait_time'] < 0\n",
    "        forecast.loc[negative_mask, 'wait_time'] = 0\n",
    "    elif 'yhat' in forecast.columns:\n",
    "        negative_mask = forecast['yhat'] < 0\n",
    "        forecast.loc[negative_mask, 'yhat'] = 0\n",
    "    \n",
    "    return forecast\n",
    "\n",
    "def evaluate_model(ride_df, actual_values, predictions, title=\"\"):\n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(predictions - actual_values))\n",
    "    rmse = np.sqrt(np.mean(np.square(predictions - actual_values)))\n",
    "    \n",
    "    # For sMAPE, avoid division by zero\n",
    "    epsilon = 1e-8\n",
    "    abs_pct_errors = np.abs(predictions - actual_values) / (np.abs(predictions) + np.abs(actual_values) + epsilon)\n",
    "    # Only include points where actual values are non-zero\n",
    "    non_zero_mask = (actual_values > 0) & (predictions > 0)\n",
    "    smape = np.mean(abs_pct_errors[non_zero_mask]) * 100 if np.any(non_zero_mask) else 0\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"\\n{title} MAE: {mae:.2f} minutes\")\n",
    "    print(f\"{title} RMSE: {rmse:.2f} minutes\")\n",
    "    print(f\"{title} sMAPE: {smape:.2f}%\")\n",
    "    \n",
    "    # Create a DataFrame with results for time-based analysis\n",
    "    results_df = pd.DataFrame({\n",
    "        'timestamp': ride_df['timestamp'].values,\n",
    "        'actual': actual_values,\n",
    "        'predicted': predictions,\n",
    "    })\n",
    "    \n",
    "    # Add time components\n",
    "    results_df['hour'] = results_df['timestamp'].dt.hour\n",
    "    results_df['day_of_week'] = results_df['timestamp'].dt.dayofweek\n",
    "    results_df['month'] = results_df['timestamp'].dt.month\n",
    "    \n",
    "    # Calculate errors\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = np.abs(results_df['error'])\n",
    "    results_df['pct_error'] = abs_pct_errors * 100\n",
    "    \n",
    "    # Create metrics dictionary\n",
    "    metrics = {\n",
    "        \"mae\": mae,\n",
    "        \"rmse\": rmse,\n",
    "        \"smape\": smape\n",
    "    }\n",
    "    \n",
    "    return metrics, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9287c7",
   "metadata": {},
   "source": [
    "## Baseline Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "796017da",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class MeanBaselineModel:\n",
    "    \"\"\"A simple baseline model that predicts the mean value of the training data.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.mean_value = None\n",
    "        \n",
    "    def fit(self, train_data):\n",
    "        \"\"\"Fit the model by calculating the mean of the training data\"\"\"\n",
    "        self.mean_value = train_data['wait_time'].mean()\n",
    "        return self\n",
    "        \n",
    "    def predict(self, future_df):\n",
    "        \"\"\"Predict using the mean value for all future points\"\"\"\n",
    "        predictions = pd.DataFrame({'timestamp': future_df['timestamp']})\n",
    "        predictions['yhat'] = self.mean_value\n",
    "        return predictions\n",
    "\n",
    "class TimeOfDayBaselineModel:\n",
    "    \"\"\"A baseline model that uses patterns at different times of day.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.time_of_day_means = None\n",
    "        self.global_mean = None\n",
    "        \n",
    "    def fit(self, train_data):\n",
    "        \"\"\"Fit the model by calculating mean values for each time of day\"\"\"\n",
    "        # Calculate mean for each time of day\n",
    "        self.time_of_day_means = train_data.groupby('time_key')['wait_time'].mean().to_dict()\n",
    "        self.global_mean = train_data['wait_time'].mean()  # Fallback value\n",
    "        return self\n",
    "        \n",
    "    def predict(self, future_df):\n",
    "        \"\"\"Predict using time-of-day pattern\"\"\"\n",
    "        predictions = pd.DataFrame({'timestamp': future_df['timestamp']})\n",
    "        \n",
    "        # Extract hour and minute from prediction dates\n",
    "        predictions['hour'] = predictions['timestamp'].dt.hour\n",
    "        predictions['minute'] = predictions['timestamp'].dt.minute\n",
    "        predictions['time_key'] = predictions['hour'] * 60 + predictions['minute']\n",
    "        \n",
    "        # Assign predictions based on time of day\n",
    "        predictions['yhat'] = predictions['time_key'].map(\n",
    "            lambda x: self.time_of_day_means.get(x, self.global_mean))\n",
    "        \n",
    "        return predictions[['timestamp', 'yhat']]\n",
    "\n",
    "class DayAndTimeBaselineModel:\n",
    "    \"\"\"A model that combines day of week patterns with time of day patterns.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.day_time_means = None\n",
    "        self.time_means = None\n",
    "        self.global_mean = None\n",
    "        \n",
    "    def fit(self, train_data):\n",
    "        \"\"\"Fit the model by calculating mean values for each day+time combination\"\"\"\n",
    "        # Calculate mean for each day and time combination\n",
    "        train_data['day_time_key'] = (train_data['day_of_week'] * 24 * 60 + \n",
    "                                      train_data['time_key'])\n",
    "        \n",
    "        self.day_time_means = train_data.groupby('day_time_key')['wait_time'].mean().to_dict()\n",
    "        self.time_means = train_data.groupby('time_key')['wait_time'].mean().to_dict()\n",
    "        self.global_mean = train_data['wait_time'].mean()\n",
    "        self.std_dev = train_data['wait_time'].std()\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, future_df):\n",
    "        \"\"\"Predict using day-of-week and time-of-day patterns\"\"\"\n",
    "        predictions = pd.DataFrame({'timestamp': future_df['timestamp']})\n",
    "        \n",
    "        # Extract day of week, hour and minute\n",
    "        predictions['day_of_week'] = predictions['timestamp'].dt.dayofweek\n",
    "        predictions['hour'] = predictions['timestamp'].dt.hour\n",
    "        predictions['minute'] = predictions['timestamp'].dt.minute\n",
    "        predictions['time_key'] = predictions['hour'] * 60 + predictions['minute']\n",
    "        predictions['day_time_key'] = (predictions['day_of_week'] * 24 * 60 + \n",
    "                                      predictions['time_key'])\n",
    "        \n",
    "        # First try to find day+time combination\n",
    "        predictions['yhat'] = predictions['day_time_key'].map(\n",
    "            lambda x: self.day_time_means.get(x, None))\n",
    "        \n",
    "        # If not found, fall back to time of day\n",
    "        mask = predictions['yhat'].isna()\n",
    "        predictions.loc[mask, 'yhat'] = predictions.loc[mask, 'time_key'].map(\n",
    "            lambda x: self.time_means.get(x, self.global_mean))\n",
    "                \n",
    "        return predictions[['timestamp', 'yhat']]\n",
    "\n",
    "class MovingAverageBaselineModel:\n",
    "    \"\"\"This model uses the average of recent observations for predictions.\"\"\"\n",
    "    def __init__(self, window_size=48):  # Default: 1 day (48 30-min intervals)\n",
    "        self.window_size = window_size\n",
    "        self.historical_data = None\n",
    "        self.global_mean = None\n",
    "        self.std_dev = None\n",
    "        \n",
    "    def fit(self, train_data):\n",
    "        \"\"\"Store the training data for later prediction\"\"\"\n",
    "        # Make a copy and reset index to avoid ambiguity issues\n",
    "        self.historical_data = train_data.copy().reset_index(drop=True)\n",
    "        self.global_mean = self.historical_data['wait_time'].mean()\n",
    "        self.std_dev = self.historical_data['wait_time'].std()\n",
    "        return self\n",
    "        \n",
    "    def predict(self, future_df):\n",
    "        \"\"\"Predict using moving average of recent observations\"\"\"\n",
    "        # Create a copy of future_df with reset index\n",
    "        future_copy = future_df.copy().reset_index(drop=True)\n",
    "        predictions = pd.DataFrame({'timestamp': future_copy['timestamp']})\n",
    "        \n",
    "        # Create lists for predictions and confidence intervals\n",
    "        yhat = []\n",
    "        \n",
    "        # Sort historical data by date\n",
    "        sorted_history = self.historical_data.sort_values('timestamp').reset_index(drop=True)\n",
    "        \n",
    "        # For each prediction date, calculate the moving average\n",
    "        for pred_date in predictions['timestamp']:\n",
    "            # Find recent observations (before the prediction date)\n",
    "            recent_data = sorted_history[sorted_history['timestamp'] < pred_date].tail(self.window_size)\n",
    "            \n",
    "            if len(recent_data) > 0:\n",
    "                # Calculate the mean of recent observations\n",
    "                pred_value = recent_data['wait_time'].mean()\n",
    "            else:\n",
    "                # Fallback to global mean if no recent data\n",
    "                pred_value = self.global_mean\n",
    "                \n",
    "            # Store prediction and confidence interval\n",
    "            yhat.append(pred_value)\n",
    "        \n",
    "        # Add predictions to dataframe\n",
    "        predictions['yhat'] = yhat\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "class SeasonalWeeklyBaselineModel:\n",
    "    \"\"\"This model uses data from the same day and time in previous weeks.\"\"\"\n",
    "    def __init__(self, num_weeks=4):\n",
    "        self.num_weeks = num_weeks\n",
    "        self.training_data = None\n",
    "        self.global_mean = None\n",
    "        self.std_dev = None\n",
    "        \n",
    "    def fit(self, train_data):\n",
    "        \"\"\"Store the training data for later prediction\"\"\"\n",
    "        # Make a copy and reset index to avoid ambiguity issues\n",
    "        self.training_data = train_data.copy().reset_index(drop=True)\n",
    "        self.global_mean = self.training_data['wait_time'].mean()\n",
    "        self.std_dev = self.training_data['wait_time'].std()\n",
    "        \n",
    "        # Pre-calculate time features for training data\n",
    "        self.training_data['day_of_week'] = self.training_data['timestamp'].dt.dayofweek\n",
    "        self.training_data['hour'] = self.training_data['timestamp'].dt.hour\n",
    "        self.training_data['minute'] = self.training_data['timestamp'].dt.minute\n",
    "        self.training_data['time_key'] = self.training_data['hour'] * 60 + self.training_data['minute']\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, future_df):\n",
    "        \"\"\"Predict using the same day of week and time of day from previous weeks\"\"\"\n",
    "        # Create a copy of future_df with reset index\n",
    "        future_copy = future_df.copy().reset_index(drop=True)\n",
    "        predictions = pd.DataFrame({'timestamp': future_copy['timestamp']})\n",
    "        \n",
    "        # Extract day of week and time for predictions\n",
    "        predictions['day_of_week'] = predictions['timestamp'].dt.dayofweek\n",
    "        predictions['hour'] = predictions['timestamp'].dt.hour\n",
    "        predictions['minute'] = predictions['timestamp'].dt.minute\n",
    "        predictions['time_key'] = predictions['hour'] * 60 + predictions['minute']\n",
    "        \n",
    "        # Predict for each point based on same day/time from previous weeks\n",
    "        yhat = []\n",
    "        \n",
    "        for _, row in predictions.iterrows():\n",
    "            # Find matching day and time in training data\n",
    "            matches = self.training_data[\n",
    "                (self.training_data['day_of_week'] == row['day_of_week']) & \n",
    "                (self.training_data['time_key'] == row['time_key'])\n",
    "            ].copy().reset_index(drop=True)\n",
    "            \n",
    "            # Sort by date (descending) and take most recent num_weeks\n",
    "            if len(matches) > 0:\n",
    "                matches = matches.sort_values('timestamp', ascending=False).reset_index(drop=True)\n",
    "                matches = matches.head(self.num_weeks)\n",
    "                \n",
    "                # Calculate prediction and confidence interval\n",
    "                pred = matches['wait_time'].mean()\n",
    "                yhat.append(pred)\n",
    "            else:\n",
    "                # Fallback to global mean if no matches\n",
    "                yhat.append(self.global_mean)\n",
    "        \n",
    "        # Add predictions to dataframe\n",
    "        predictions['yhat'] = yhat\n",
    "        \n",
    "        return predictions[['timestamp', 'yhat']]\n",
    "\n",
    "class HolidayAwareBaselineModel:\n",
    "    \"\"\"A model that uses different patterns for holidays and normal days.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.holiday_day_time_means = None\n",
    "        self.normal_day_time_means = None\n",
    "        self.holiday_time_means = None\n",
    "        self.normal_time_means = None\n",
    "        self.holiday_mean = None\n",
    "        self.normal_mean = None\n",
    "        self.global_mean = None\n",
    "        \n",
    "    def fit(self, train_data, holiday_data):\n",
    "        \"\"\"Fit separate models for holidays and normal days\"\"\"\n",
    "        # Mark holiday days\n",
    "        if holiday_data is not None:\n",
    "            holiday_dates = set(pd.to_datetime(holiday_data['timestamp']).dt.date)\n",
    "        else:\n",
    "            holiday_dates = set()\n",
    "            \n",
    "        train_data = train_data.copy()\n",
    "        train_data['is_holiday'] = train_data['timestamp'].dt.date.isin(holiday_dates)\n",
    "        \n",
    "        # Create day-time keys if they don't exist yet\n",
    "        if 'day_time_key' not in train_data.columns:\n",
    "            train_data['day_time_key'] = (train_data['day_of_week'] * 24 * 60 + \n",
    "                                         train_data['time_key'])\n",
    "        \n",
    "        # Calculate means for holiday days\n",
    "        holiday_data_subset = train_data[train_data['is_holiday']]\n",
    "        self.holiday_day_time_means = holiday_data_subset.groupby('day_time_key')['wait_time'].mean().to_dict()\n",
    "        self.holiday_time_means = holiday_data_subset.groupby('time_key')['wait_time'].mean().to_dict()\n",
    "        \n",
    "        # Calculate means for normal days\n",
    "        normal_data = train_data[~train_data['is_holiday']]\n",
    "        self.normal_day_time_means = normal_data.groupby('day_time_key')['wait_time'].mean().to_dict()\n",
    "        self.normal_time_means = normal_data.groupby('time_key')['wait_time'].mean().to_dict()\n",
    "        \n",
    "        # Global means as fallback\n",
    "        self.holiday_mean = holiday_data_subset['wait_time'].mean() if len(holiday_data_subset) > 0 else train_data['wait_time'].mean()\n",
    "        self.normal_mean = normal_data['wait_time'].mean() if len(normal_data) > 0 else train_data['wait_time'].mean()\n",
    "        self.global_mean = train_data['wait_time'].mean()\n",
    "        self.std_dev = train_data['wait_time'].std()\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, future_df, holiday_data):\n",
    "        \"\"\"Predict using different models for holidays and normal days\"\"\"\n",
    "        predictions = pd.DataFrame({'timestamp': future_df['timestamp']})\n",
    "        \n",
    "        # Extract day and time features\n",
    "        predictions['day_of_week'] = predictions['timestamp'].dt.dayofweek\n",
    "        predictions['hour'] = predictions['timestamp'].dt.hour\n",
    "        predictions['minute'] = predictions['timestamp'].dt.minute\n",
    "        predictions['time_key'] = predictions['hour'] * 60 + predictions['minute']\n",
    "        predictions['day_time_key'] = (predictions['day_of_week'] * 24 * 60 + \n",
    "                                      predictions['time_key'])\n",
    "        \n",
    "        # Mark holiday days\n",
    "        if holiday_data is not None:\n",
    "            holiday_dates = set(pd.to_datetime(holiday_data['timestamp']).dt.date)\n",
    "        else:\n",
    "            holiday_dates = set()\n",
    "        predictions['is_holiday'] = predictions['timestamp'].dt.date.isin(holiday_dates)\n",
    "        \n",
    "        # Initialize predictions\n",
    "        predictions['yhat'] = np.nan\n",
    "        \n",
    "        # Predict for holiday days\n",
    "        holiday_mask = predictions['is_holiday']\n",
    "        \n",
    "        # First try day+time for holidays\n",
    "        predictions.loc[holiday_mask, 'yhat'] = predictions.loc[holiday_mask, 'day_time_key'].map(\n",
    "            lambda x: self.holiday_day_time_means.get(x, None))\n",
    "        \n",
    "        # Fall back to time of day for holidays\n",
    "        still_na = holiday_mask & predictions['yhat'].isna()\n",
    "        predictions.loc[still_na, 'yhat'] = predictions.loc[still_na, 'time_key'].map(\n",
    "            lambda x: self.holiday_time_means.get(x, self.holiday_mean))\n",
    "        \n",
    "        # Predict for normal days\n",
    "        normal_mask = ~predictions['is_holiday']\n",
    "        \n",
    "        # First try day+time for normal days\n",
    "        predictions.loc[normal_mask, 'yhat'] = predictions.loc[normal_mask, 'day_time_key'].map(\n",
    "            lambda x: self.normal_day_time_means.get(x, None))\n",
    "        \n",
    "        # Fall back to time of day for normal days\n",
    "        still_na = normal_mask & predictions['yhat'].isna()\n",
    "        predictions.loc[still_na, 'yhat'] = predictions.loc[still_na, 'time_key'].map(\n",
    "            lambda x: self.normal_time_means.get(x, self.normal_mean))\n",
    "        \n",
    "        # Final fallback to global mean\n",
    "        still_na = predictions['yhat'].isna()\n",
    "        predictions.loc[still_na, 'yhat'] = self.global_mean\n",
    "        \n",
    "        return predictions[['timestamp', 'yhat']]\n",
    "\n",
    "class TrueLastWeekModel:\n",
    "    \"\"\"A model that uses the exact value from 7 days before in the same dataset.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.std_dev = None\n",
    "        \n",
    "    def fit(self, train_data):\n",
    "        \"\"\"Store training data\"\"\"\n",
    "        self.train_data = train_data.copy().reset_index(drop=True)\n",
    "        self.train_data_dict = dict(zip(self.train_data['timestamp'], self.train_data['wait_time']))\n",
    "        self.std_dev = self.train_data['wait_time'].std()\n",
    "        self.global_mean = self.train_data['wait_time'].mean()\n",
    "        return self\n",
    "        \n",
    "    def predict(self, future_df, val_data=None):\n",
    "        \"\"\"Predict using values from 7 days before in the same dataset\"\"\"\n",
    "        predictions = pd.DataFrame({'timestamp': future_df['timestamp']})\n",
    "        yhat = []\n",
    "        \n",
    "        # Create value lookup dictionaries\n",
    "        if val_data is not None:\n",
    "            val_data = val_data.copy().reset_index(drop=True)\n",
    "            val_data_dict = dict(zip(val_data['timestamp'], val_data['wait_time']))\n",
    "        else:\n",
    "            val_data_dict = {}\n",
    "        \n",
    "        # For each prediction date\n",
    "        for date in predictions['timestamp']:\n",
    "            last_week = date - pd.Timedelta(days=7)\n",
    "            \n",
    "            # For validation dates, first check in validation data\n",
    "            if val_data is not None and date in val_data_dict:\n",
    "                if last_week in val_data_dict:\n",
    "                    yhat.append(val_data_dict[last_week])\n",
    "                elif last_week in self.train_data_dict:\n",
    "                    yhat.append(self.train_data_dict[last_week])\n",
    "                else:\n",
    "                    # If no exact match, use global mean\n",
    "                    yhat.append(self.global_mean)\n",
    "            # For training dates, check in training data\n",
    "            else:\n",
    "                if last_week in self.train_data_dict:\n",
    "                    yhat.append(self.train_data_dict[last_week])\n",
    "                else:\n",
    "                    # If no exact match, use global mean\n",
    "                    yhat.append(self.global_mean)\n",
    "        \n",
    "        # Add predictions and confidence intervals\n",
    "        predictions['yhat'] = yhat\n",
    "        \n",
    "        return predictions[['timestamp', 'yhat']]\n",
    "\n",
    "class LastYearModel:\n",
    "    \"\"\"A baseline that uses the value from the same day of the week in the previous year.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.historical_data = None\n",
    "        self.std_dev = None\n",
    "        \n",
    "    def fit(self, train_data):\n",
    "        \"\"\"Store the training data indexed by timestamp\"\"\"\n",
    "        self.historical_data = train_data.copy().reset_index(drop=True)\n",
    "        # Create a lookup dictionary for fast access\n",
    "        self.date_to_value = dict(zip(self.historical_data['timestamp'], self.historical_data['wait_time']))\n",
    "        self.std_dev = self.historical_data['wait_time'].std()\n",
    "        self.global_mean = self.historical_data['wait_time'].mean()\n",
    "        return self\n",
    "    \n",
    "    def _get_same_day_previous_year(self, date):\n",
    "        \"\"\"Get the same day of the week from the previous year, handling leap years.\"\"\"\n",
    "        # Start with the same date last year\n",
    "        try:\n",
    "            same_date_last_year = date.replace(year=date.year - 1)\n",
    "        except ValueError:\n",
    "            # Handle Feb 29 in leap years - move to Feb 28\n",
    "            same_date_last_year = date.replace(year=date.year - 1, day=28)\n",
    "        \n",
    "        # Calculate the difference in days of the week\n",
    "        current_weekday = date.weekday()\n",
    "        last_year_weekday = same_date_last_year.weekday()\n",
    "        \n",
    "        # Adjust to get the same day of the week\n",
    "        days_diff = current_weekday - last_year_weekday\n",
    "        target_date = same_date_last_year + pd.Timedelta(days=days_diff)\n",
    "        \n",
    "        return target_date\n",
    "        \n",
    "    def predict(self, future_df):\n",
    "        \"\"\"Predict using the same day of the week from the previous year\"\"\"\n",
    "        predictions = pd.DataFrame({'timestamp': future_df['timestamp']})\n",
    "        yhat = []\n",
    "        \n",
    "        for date in predictions['timestamp']:\n",
    "            # Get the same day of the week from previous year\n",
    "            target_date = self._get_same_day_previous_year(date)\n",
    "            \n",
    "            # If we have data for that exact date, use it\n",
    "            if target_date in self.date_to_value:\n",
    "                yhat.append(self.date_to_value[target_date])\n",
    "            else:\n",
    "                # Look for closest date within a 7-day window (prefer same weekday)\n",
    "                closest_date = None\n",
    "                min_diff = pd.Timedelta(days=7)\n",
    "                \n",
    "                for historical_date in self.date_to_value.keys():\n",
    "                    diff = abs(historical_date - target_date)\n",
    "                    # Prefer dates with the same weekday\n",
    "                    if historical_date.weekday() == date.weekday():\n",
    "                        diff = diff - pd.Timedelta(hours=1)  # Small bias towards same weekday\n",
    "                    \n",
    "                    if diff < min_diff:\n",
    "                        min_diff = diff\n",
    "                        closest_date = historical_date\n",
    "                \n",
    "                if closest_date is not None:\n",
    "                    yhat.append(self.date_to_value[closest_date])\n",
    "                else:\n",
    "                    # Otherwise use global mean\n",
    "                    yhat.append(self.global_mean)\n",
    "                \n",
    "        predictions['yhat'] = yhat\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d540c0c1",
   "metadata": {},
   "source": [
    "## Model Storage and Management Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad347e2e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def save_baseline_results(ride_name, all_metrics, output_dir=\"baseline_models\"):\n",
    "    \"\"\"Save baseline model results for a ride.\"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create ride-specific directory\n",
    "    ride_dir = os.path.join(output_dir, ride_name.replace(\" \", \"_\"))\n",
    "    os.makedirs(ride_dir, exist_ok=True)\n",
    "    \n",
    "    # Save metrics\n",
    "    with open(os.path.join(ride_dir, \"baseline_metrics.json\"), \"w\") as f:\n",
    "        json.dump(all_metrics, f, indent=4)\n",
    "    \n",
    "    print(f\"Baseline results saved to {ride_dir}\")\n",
    "\n",
    "def load_baseline_results(ride_name, output_dir=\"baseline_models\"):\n",
    "    \"\"\"Load baseline model results for a ride.\"\"\"\n",
    "    ride_dir = os.path.join(output_dir, ride_name.replace(\" \", \"_\"))\n",
    "    \n",
    "    # Check if results exist\n",
    "    metrics_path = os.path.join(ride_dir, \"baseline_metrics.json\")\n",
    "    if not os.path.exists(metrics_path):\n",
    "        return None\n",
    "    \n",
    "    # Load metrics\n",
    "    with open(metrics_path, \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def create_checkpoint_file(processed_rides, output_dir=\"baseline_models\"):\n",
    "    \"\"\"Create a checkpoint file to track progress.\"\"\"\n",
    "    checkpoint_path = os.path.join(output_dir, \"checkpoint.json\")\n",
    "    with open(checkpoint_path, \"w\") as f:\n",
    "        json.dump({\"processed_rides\": processed_rides}, f, indent=4)\n",
    "\n",
    "def load_checkpoint_file(output_dir=\"baseline_models\"):\n",
    "    \"\"\"Load checkpoint file to resume processing.\"\"\"\n",
    "    checkpoint_path = os.path.join(output_dir, \"checkpoint.json\")\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        with open(checkpoint_path, \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "        return checkpoint.get(\"processed_rides\", [])\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f213e",
   "metadata": {},
   "source": [
    "## Single Ride Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6659b26",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process_single_ride_baselines(ride_name, train_data, val_data, output_dir=\"baseline_models\"):\n",
    "    \"\"\"Process all baseline models for a single ride.\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing baseline models for ride: {ride_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Filter data for the current ride\n",
    "    ride_train_data = filter_ride_data(train_data, ride_name)\n",
    "    ride_val_data = filter_ride_data(val_data, ride_name)\n",
    "    \n",
    "    print(f\"Training data size: {len(ride_train_data)}\")\n",
    "    print(f\"Validation data size: {len(ride_val_data)}\")\n",
    "    \n",
    "    # Skip if not enough data\n",
    "    if len(ride_train_data) < 100 or len(ride_val_data) < 50:\n",
    "        print(f\"Skipping {ride_name} due to insufficient data\")\n",
    "        return None\n",
    "    \n",
    "    # Add features\n",
    "    ride_train_data = add_features(ride_train_data)\n",
    "    ride_val_data = add_features(ride_val_data)\n",
    "    \n",
    "    # Create holidays dataframe\n",
    "    holidays_df = create_holiday_dataframes(ride_train_data)\n",
    "    \n",
    "    # Create future dataframe for predictions\n",
    "    future = pd.DataFrame({'timestamp': ride_val_data['timestamp'].unique()})\n",
    "    future = future.sort_values('timestamp').reset_index(drop=True)\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    all_metrics = {}\n",
    "    \n",
    "    # Define all baseline models\n",
    "    baseline_models = {\n",
    "        \"Mean Baseline\": MeanBaselineModel(),\n",
    "        \"Time-of-Day Baseline\": TimeOfDayBaselineModel(),\n",
    "        \"Day+Time Baseline\": DayAndTimeBaselineModel(),\n",
    "        \"Moving Average Baseline\": MovingAverageBaselineModel(window_size=48),\n",
    "        \"Seasonal Weekly Baseline\": SeasonalWeeklyBaselineModel(num_weeks=4),\n",
    "        \"Holiday-Aware Baseline\": HolidayAwareBaselineModel(),\n",
    "        \"LastWeek Baseline\": TrueLastWeekModel(),\n",
    "        \"LastYear Baseline\": LastYearModel()\n",
    "    }\n",
    "    \n",
    "    # Get actual values\n",
    "    val_actual = ride_val_data['wait_time'].values\n",
    "    \n",
    "    # Process each baseline model\n",
    "    for model_name, model in baseline_models.items():\n",
    "        try:\n",
    "            print(f\"  Training {model_name}...\")\n",
    "            \n",
    "            # Fit the model\n",
    "            if model_name == \"Holiday-Aware Baseline\":\n",
    "                model.fit(ride_train_data, holidays_df)\n",
    "            else:\n",
    "                model.fit(ride_train_data)\n",
    "            \n",
    "            # Make predictions\n",
    "            if model_name == \"Holiday-Aware Baseline\":\n",
    "                forecast = model.predict(future, holidays_df)\n",
    "            elif model_name == \"LastWeek Baseline\":\n",
    "                forecast = model.predict(future, ride_val_data)\n",
    "            else:\n",
    "                forecast = model.predict(future)\n",
    "            \n",
    "            # Post-process forecast\n",
    "            forecast = post_process_forecast(forecast, ride_val_data)\n",
    "            \n",
    "            # Get predictions\n",
    "            val_predictions = forecast['yhat'].values\n",
    "            \n",
    "            # Evaluate model\n",
    "            metrics, results_df = evaluate_model(\n",
    "                ride_val_data, val_actual, val_predictions, \n",
    "                title=f\"{model_name}\"\n",
    "            )\n",
    "            \n",
    "            # Store metrics\n",
    "            all_metrics[model_name] = metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {model_name}: {str(e)}\")\n",
    "            all_metrics[model_name] = {\"mae\": float('inf'), \"rmse\": float('inf'), \"smape\": float('inf')}\n",
    "    \n",
    "    # Add metadata\n",
    "    all_metrics[\"metadata\"] = {\n",
    "        \"ride_name\": ride_name,\n",
    "        \"train_data_size\": len(ride_train_data),\n",
    "        \"val_data_size\": len(ride_val_data),\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    \n",
    "    # Save results\n",
    "    save_baseline_results(ride_name, all_metrics, output_dir)\n",
    "    \n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401222e2",
   "metadata": {},
   "source": [
    "## All Rides Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20ce768b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process_all_rides_baselines(all_rides, train_data, val_data, \n",
    "                               output_dir=\"baseline_models\", resume=True):\n",
    "    \"\"\"Process baseline models for all rides.\"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get list of already processed rides\n",
    "    processed_rides = []\n",
    "    if resume:\n",
    "        processed_rides = load_checkpoint_file(output_dir)\n",
    "        if processed_rides:\n",
    "            print(f\"Resuming from checkpoint. {len(processed_rides)} rides already processed.\")\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    all_results = {}\n",
    "    \n",
    "    # Process each ride\n",
    "    for i, ride_name in enumerate(tqdm(all_rides, desc=\"Processing rides\")):\n",
    "        if ride_name in processed_rides:\n",
    "            print(f\"Skipping {ride_name} (already processed)\")\n",
    "            # Load metrics for the summary\n",
    "            metrics = load_baseline_results(ride_name, output_dir)\n",
    "            if metrics:\n",
    "                all_results[ride_name] = metrics\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing ride {i+1}/{len(all_rides)}: {ride_name}\")\n",
    "        ride_metrics = process_single_ride_baselines(ride_name, train_data, val_data, \n",
    "                                                    output_dir=output_dir)\n",
    "        \n",
    "        if ride_metrics:\n",
    "            all_results[ride_name] = ride_metrics\n",
    "            processed_rides.append(ride_name)\n",
    "            \n",
    "            # Update checkpoint after each ride\n",
    "            create_checkpoint_file(processed_rides, output_dir)\n",
    "    \n",
    "    # Generate summary report\n",
    "    generate_baseline_summary_report(all_results, output_dir)\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc565fd9",
   "metadata": {},
   "source": [
    "## Summary Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e4a3d1f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_baseline_summary_report(all_results, output_dir=\"baseline_models\"):\n",
    "    \"\"\"Generate a comprehensive summary report of all baseline models across all rides.\"\"\"\n",
    "    \n",
    "    # Create lists to store summary data\n",
    "    summary_data = []\n",
    "    \n",
    "    # Extract data from results\n",
    "    for ride_name, ride_results in all_results.items():\n",
    "        if not ride_results or \"metadata\" not in ride_results:\n",
    "            continue\n",
    "        \n",
    "        # Base ride info\n",
    "        metadata = ride_results[\"metadata\"]\n",
    "        base_info = {\n",
    "            \"ride_name\": ride_name,\n",
    "            \"train_data_size\": metadata.get(\"train_data_size\", 0),\n",
    "            \"val_data_size\": metadata.get(\"val_data_size\", 0)\n",
    "        }\n",
    "        \n",
    "        # Add metrics for each baseline model\n",
    "        for model_name, metrics in ride_results.items():\n",
    "            if model_name == \"metadata\":\n",
    "                continue\n",
    "                \n",
    "            row = base_info.copy()\n",
    "            row[\"model_name\"] = model_name\n",
    "            row[\"mae\"] = metrics.get(\"mae\", float('inf'))\n",
    "            row[\"rmse\"] = metrics.get(\"rmse\", float('inf'))\n",
    "            row[\"smape\"] = metrics.get(\"smape\", float('inf'))\n",
    "            \n",
    "            summary_data.append(row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    if len(summary_df) == 0:\n",
    "        print(\"No results to summarize.\")\n",
    "        return None\n",
    "    \n",
    "    # Save detailed summary\n",
    "    detailed_summary_path = os.path.join(output_dir, \"detailed_baseline_summary.csv\")\n",
    "    summary_df.to_csv(detailed_summary_path, index=False)\n",
    "    \n",
    "    # Create model comparison summary\n",
    "    model_summary = summary_df.groupby('model_name').agg({\n",
    "        'mae': ['mean', 'std', 'median'],\n",
    "        'rmse': ['mean', 'std', 'median'],\n",
    "        'smape': ['mean', 'std', 'median']\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    model_summary.columns = ['_'.join(col).strip() for col in model_summary.columns.values]\n",
    "    model_summary = model_summary.reset_index()\n",
    "    \n",
    "    # Save model comparison summary\n",
    "    model_summary_path = os.path.join(output_dir, \"model_comparison_summary.csv\")\n",
    "    model_summary.to_csv(model_summary_path, index=False)\n",
    "    \n",
    "    # Create ride-wise best model summary\n",
    "    ride_best = summary_df.loc[summary_df.groupby('ride_name')['mae'].idxmin()]\n",
    "    ride_best_summary = ride_best[['ride_name', 'model_name', 'mae', 'rmse', 'smape']].copy()\n",
    "    ride_best_summary = ride_best_summary.sort_values('mae')\n",
    "    \n",
    "    # Save ride-wise best model summary\n",
    "    ride_best_path = os.path.join(output_dir, \"best_model_per_ride.csv\")\n",
    "    ride_best_summary.to_csv(ride_best_path, index=False)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BASELINE MODELS SUMMARY:\")\n",
    "    print(f\"Total rides processed: {summary_df['ride_name'].nunique()}\")\n",
    "    print(f\"Total model evaluations: {len(summary_df)}\")\n",
    "    print(\"\\nModel Performance (Average MAE):\")\n",
    "    print(model_summary[['model_name', 'mae_mean']].sort_values('mae_mean'))\n",
    "    print(f\"\\nDetailed summary saved to: {detailed_summary_path}\")\n",
    "    print(f\"Model comparison saved to: {model_summary_path}\")\n",
    "    print(f\"Best models per ride saved to: {ride_best_path}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_baseline_visualizations(summary_df, model_summary, ride_best_summary, output_dir)\n",
    "    \n",
    "    return summary_df, model_summary, ride_best_summary\n",
    "\n",
    "def create_baseline_visualizations(summary_df, model_summary, ride_best_summary, output_dir):\n",
    "    \"\"\"Create visualizations for baseline model results.\"\"\"\n",
    "    \n",
    "    # 1. Model comparison boxplot\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    summary_df.boxplot(column='mae', by='model_name', ax=plt.gca())\n",
    "    plt.title('MAE Distribution by Baseline Model')\n",
    "    plt.xlabel('Baseline Model')\n",
    "    plt.ylabel('Mean Absolute Error (minutes)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"model_comparison_boxplot.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Average performance bar chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    model_avg = model_summary.sort_values('mae_mean')\n",
    "    plt.bar(model_avg['model_name'], model_avg['mae_mean'])\n",
    "    plt.title('Average MAE by Baseline Model')\n",
    "    plt.xlabel('Baseline Model')\n",
    "    plt.ylabel('Average MAE (minutes)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"average_mae_by_model.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Best model distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    best_model_counts = ride_best_summary['model_name'].value_counts()\n",
    "    plt.bar(best_model_counts.index, best_model_counts.values)\n",
    "    plt.title('Frequency of Best Performing Model by Ride')\n",
    "    plt.xlabel('Baseline Model')\n",
    "    plt.ylabel('Number of Rides Where Model is Best')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"best_model_frequency.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Performance heatmap\n",
    "    pivot_df = summary_df.pivot(index='ride_name', columns='model_name', values='mae')\n",
    "    plt.figure(figsize=(15, 20))\n",
    "    plt.imshow(pivot_df.values, cmap='YlOrRd', aspect='auto')\n",
    "    plt.colorbar(label='MAE (minutes)')\n",
    "    plt.xticks(range(len(pivot_df.columns)), pivot_df.columns, rotation=45)\n",
    "    plt.yticks(range(len(pivot_df.index)), pivot_df.index)\n",
    "    plt.title('MAE Heatmap: Models vs Rides')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"mae_heatmap.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Visualizations saved to output directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa8477b",
   "metadata": {},
   "source": [
    "## Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27af236d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded data with 7834739 rows\n",
      "No missing values found in the dataset.\n",
      "Train data size: 297362\n",
      "Validation data size: 61851\n",
      "Test data size: 55699\n",
      "Found 31 rides in the dataset:\n",
      "1. alpine express enzian\n",
      "2. arena of football  be part of it\n",
      "3. arthur\n",
      "4. atlantica supersplash\n",
      "5. atlantis adventure\n",
      "6. baaa express\n",
      "7. blue fire megacoaster\n",
      "8. castello dei medici\n",
      "9. dancing dingie\n",
      "10. euromir\n",
      "11. eurosat  cancan coaster\n",
      "12. eurotower\n",
      "13. fjordrafting\n",
      "14. jim button  journey through morrowland\n",
      "15. josefinas magical imperial journey\n",
      "16. kolumbusjolle\n",
      "17. madame freudenreich curiosits\n",
      "18. matterhornblitz\n",
      "19. old mac donalds tractor fun\n",
      "20. pegasus\n",
      "21. poppy towers\n",
      "22. poseidon\n",
      "23. silver star\n",
      "24. swiss bob run\n",
      "25. tirol log flume\n",
      "26. vienna wave swing  glckspilz\n",
      "27. vindjammer\n",
      "28. voletarium\n",
      "29. volo da vinci\n",
      "30. voltron nevera powered by rimac\n",
      "31. whale adventures  northern lights\n",
      "\n",
      "============================================================\n",
      "STARTING BASELINE MODEL PROCESSING FOR ALL RIDES\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:   0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ride 1/31: alpine express enzian\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: alpine express enzian\n",
      "==================================================\n",
      "Training data size: 10302\n",
      "Validation data size: 2019\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 7.87 minutes\n",
      "Mean Baseline RMSE: 9.64 minutes\n",
      "Mean Baseline sMAPE: 22.56%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 6.77 minutes\n",
      "Time-of-Day Baseline RMSE: 8.27 minutes\n",
      "Time-of-Day Baseline sMAPE: 24.18%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 6.04 minutes\n",
      "Day+Time Baseline RMSE: 7.48 minutes\n",
      "Day+Time Baseline sMAPE: 22.39%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 7.04 minutes\n",
      "Moving Average Baseline RMSE: 8.79 minutes\n",
      "Moving Average Baseline sMAPE: 22.90%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 7.99 minutes\n",
      "Seasonal Weekly Baseline RMSE: 10.59 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 39.46%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 5.86 minutes\n",
      "Holiday-Aware Baseline RMSE: 7.27 minutes\n",
      "Holiday-Aware Baseline sMAPE: 21.90%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 2.66 minutes\n",
      "LastWeek Baseline RMSE: 6.38 minutes\n",
      "LastWeek Baseline sMAPE: 7.28%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:   3%|         | 1/31 [00:05<02:31,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 9.06 minutes\n",
      "LastYear Baseline RMSE: 12.09 minutes\n",
      "LastYear Baseline sMAPE: 29.08%\n",
      "Baseline results saved to ../models/baseline_models/alpine_express_enzian\n",
      "\n",
      "Processing ride 2/31: arena of football  be part of it\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: arena of football  be part of it\n",
      "==================================================\n",
      "Training data size: 9612\n",
      "Validation data size: 2052\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 2.57 minutes\n",
      "Mean Baseline RMSE: 2.73 minutes\n",
      "Mean Baseline sMAPE: 32.88%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 2.50 minutes\n",
      "Time-of-Day Baseline RMSE: 2.76 minutes\n",
      "Time-of-Day Baseline sMAPE: 34.45%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 2.47 minutes\n",
      "Day+Time Baseline RMSE: 2.74 minutes\n",
      "Day+Time Baseline sMAPE: 33.24%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 1.90 minutes\n",
      "Moving Average Baseline RMSE: 2.18 minutes\n",
      "Moving Average Baseline sMAPE: 19.23%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 2.09 minutes\n",
      "Seasonal Weekly Baseline RMSE: 2.99 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 14.13%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 2.48 minutes\n",
      "Holiday-Aware Baseline RMSE: 2.76 minutes\n",
      "Holiday-Aware Baseline sMAPE: 33.60%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 0.71 minutes\n",
      "LastWeek Baseline RMSE: 1.99 minutes\n",
      "LastWeek Baseline sMAPE: 2.33%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:   6%|         | 2/31 [00:25<06:49, 14.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 4.30 minutes\n",
      "LastYear Baseline RMSE: 4.82 minutes\n",
      "LastYear Baseline sMAPE: 3.55%\n",
      "Baseline results saved to ../models/baseline_models/arena_of_football__be_part_of_it\n",
      "\n",
      "Processing ride 3/31: arthur\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: arthur\n",
      "==================================================\n",
      "Training data size: 10298\n",
      "Validation data size: 2067\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 11.02 minutes\n",
      "Mean Baseline RMSE: 14.69 minutes\n",
      "Mean Baseline sMAPE: 18.44%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 9.12 minutes\n",
      "Time-of-Day Baseline RMSE: 12.58 minutes\n",
      "Time-of-Day Baseline sMAPE: 18.38%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 8.60 minutes\n",
      "Day+Time Baseline RMSE: 12.03 minutes\n",
      "Day+Time Baseline sMAPE: 17.56%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 13.87 minutes\n",
      "Moving Average Baseline RMSE: 17.32 minutes\n",
      "Moving Average Baseline sMAPE: 21.26%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 11.15 minutes\n",
      "Seasonal Weekly Baseline RMSE: 14.87 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 21.07%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 8.58 minutes\n",
      "Holiday-Aware Baseline RMSE: 12.01 minutes\n",
      "Holiday-Aware Baseline sMAPE: 17.64%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 8.53 minutes\n",
      "LastWeek Baseline RMSE: 13.01 minutes\n",
      "LastWeek Baseline sMAPE: 15.45%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  10%|         | 3/31 [00:32<05:01, 10.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 10.75 minutes\n",
      "LastYear Baseline RMSE: 15.56 minutes\n",
      "LastYear Baseline sMAPE: 19.43%\n",
      "Baseline results saved to ../models/baseline_models/arthur\n",
      "\n",
      "Processing ride 4/31: atlantica supersplash\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: atlantica supersplash\n",
      "==================================================\n",
      "Training data size: 9825\n",
      "Validation data size: 2065\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 11.95 minutes\n",
      "Mean Baseline RMSE: 14.23 minutes\n",
      "Mean Baseline sMAPE: 31.59%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 9.69 minutes\n",
      "Time-of-Day Baseline RMSE: 12.66 minutes\n",
      "Time-of-Day Baseline sMAPE: 30.69%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 9.43 minutes\n",
      "Day+Time Baseline RMSE: 12.49 minutes\n",
      "Day+Time Baseline sMAPE: 29.63%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 12.87 minutes\n",
      "Moving Average Baseline RMSE: 14.69 minutes\n",
      "Moving Average Baseline sMAPE: 30.40%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 13.15 minutes\n",
      "Seasonal Weekly Baseline RMSE: 18.31 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 40.43%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 9.39 minutes\n",
      "Holiday-Aware Baseline RMSE: 12.49 minutes\n",
      "Holiday-Aware Baseline sMAPE: 29.67%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 7.47 minutes\n",
      "LastWeek Baseline RMSE: 12.02 minutes\n",
      "LastWeek Baseline sMAPE: 21.73%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  13%|        | 4/31 [00:38<03:56,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 10.18 minutes\n",
      "LastYear Baseline RMSE: 14.52 minutes\n",
      "LastYear Baseline sMAPE: 31.26%\n",
      "Baseline results saved to ../models/baseline_models/atlantica_supersplash\n",
      "\n",
      "Processing ride 5/31: atlantis adventure\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: atlantis adventure\n",
      "==================================================\n",
      "Training data size: 10289\n",
      "Validation data size: 2066\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 2.45 minutes\n",
      "Mean Baseline RMSE: 2.97 minutes\n",
      "Mean Baseline sMAPE: 53.25%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 2.18 minutes\n",
      "Time-of-Day Baseline RMSE: 2.81 minutes\n",
      "Time-of-Day Baseline sMAPE: 44.66%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 2.08 minutes\n",
      "Day+Time Baseline RMSE: 2.75 minutes\n",
      "Day+Time Baseline sMAPE: 42.85%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 2.94 minutes\n",
      "Moving Average Baseline RMSE: 3.18 minutes\n",
      "Moving Average Baseline sMAPE: 31.30%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 2.17 minutes\n",
      "Seasonal Weekly Baseline RMSE: 3.34 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 33.03%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 2.04 minutes\n",
      "Holiday-Aware Baseline RMSE: 2.76 minutes\n",
      "Holiday-Aware Baseline sMAPE: 44.46%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 1.79 minutes\n",
      "LastWeek Baseline RMSE: 3.30 minutes\n",
      "LastWeek Baseline sMAPE: 10.75%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  16%|        | 5/31 [00:43<03:16,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 1.98 minutes\n",
      "LastYear Baseline RMSE: 3.59 minutes\n",
      "LastYear Baseline sMAPE: 12.06%\n",
      "Baseline results saved to ../models/baseline_models/atlantis_adventure\n",
      "\n",
      "Processing ride 6/31: baaa express\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: baaa express\n",
      "==================================================\n",
      "Training data size: 10291\n",
      "Validation data size: 2067\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 3.80 minutes\n",
      "Mean Baseline RMSE: 6.19 minutes\n",
      "Mean Baseline sMAPE: 17.08%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 4.40 minutes\n",
      "Time-of-Day Baseline RMSE: 6.03 minutes\n",
      "Time-of-Day Baseline sMAPE: 31.81%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 4.26 minutes\n",
      "Day+Time Baseline RMSE: 5.97 minutes\n",
      "Day+Time Baseline sMAPE: 31.14%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 4.99 minutes\n",
      "Moving Average Baseline RMSE: 6.08 minutes\n",
      "Moving Average Baseline sMAPE: 24.52%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 4.85 minutes\n",
      "Seasonal Weekly Baseline RMSE: 6.84 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 37.58%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 4.24 minutes\n",
      "Holiday-Aware Baseline RMSE: 6.02 minutes\n",
      "Holiday-Aware Baseline sMAPE: 31.52%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 3.71 minutes\n",
      "LastWeek Baseline RMSE: 6.36 minutes\n",
      "LastWeek Baseline sMAPE: 14.50%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  19%|        | 6/31 [00:49<02:53,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 6.09 minutes\n",
      "LastYear Baseline RMSE: 8.74 minutes\n",
      "LastYear Baseline sMAPE: 24.82%\n",
      "Baseline results saved to ../models/baseline_models/baaa_express\n",
      "\n",
      "Processing ride 7/31: blue fire megacoaster\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: blue fire megacoaster\n",
      "==================================================\n",
      "Training data size: 10288\n",
      "Validation data size: 2067\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 13.29 minutes\n",
      "Mean Baseline RMSE: 17.47 minutes\n",
      "Mean Baseline sMAPE: 24.98%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 12.39 minutes\n",
      "Time-of-Day Baseline RMSE: 16.65 minutes\n",
      "Time-of-Day Baseline sMAPE: 23.17%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 11.76 minutes\n",
      "Day+Time Baseline RMSE: 15.76 minutes\n",
      "Day+Time Baseline sMAPE: 22.41%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 13.34 minutes\n",
      "Moving Average Baseline RMSE: 17.84 minutes\n",
      "Moving Average Baseline sMAPE: 25.29%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 16.41 minutes\n",
      "Seasonal Weekly Baseline RMSE: 22.45 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 34.75%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 11.78 minutes\n",
      "Holiday-Aware Baseline RMSE: 15.79 minutes\n",
      "Holiday-Aware Baseline sMAPE: 22.53%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 11.02 minutes\n",
      "LastWeek Baseline RMSE: 16.49 minutes\n",
      "LastWeek Baseline sMAPE: 19.07%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  23%|       | 7/31 [00:55<02:42,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 11.10 minutes\n",
      "LastYear Baseline RMSE: 16.56 minutes\n",
      "LastYear Baseline sMAPE: 21.24%\n",
      "Baseline results saved to ../models/baseline_models/blue_fire_megacoaster\n",
      "\n",
      "Processing ride 8/31: castello dei medici\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: castello dei medici\n",
      "==================================================\n",
      "Training data size: 10193\n",
      "Validation data size: 2066\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 2.45 minutes\n",
      "Mean Baseline RMSE: 2.60 minutes\n",
      "Mean Baseline sMAPE: 45.68%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 2.44 minutes\n",
      "Time-of-Day Baseline RMSE: 2.61 minutes\n",
      "Time-of-Day Baseline sMAPE: 45.73%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 2.37 minutes\n",
      "Day+Time Baseline RMSE: 2.56 minutes\n",
      "Day+Time Baseline sMAPE: 44.62%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 2.91 minutes\n",
      "Moving Average Baseline RMSE: 3.83 minutes\n",
      "Moving Average Baseline sMAPE: 0.56%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 2.55 minutes\n",
      "Seasonal Weekly Baseline RMSE: 3.09 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 15.25%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 2.35 minutes\n",
      "Holiday-Aware Baseline RMSE: 2.56 minutes\n",
      "Holiday-Aware Baseline sMAPE: 45.85%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 1.55 minutes\n",
      "LastWeek Baseline RMSE: 2.83 minutes\n",
      "LastWeek Baseline sMAPE: 1.03%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  26%|       | 8/31 [01:02<02:36,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 2.70 minutes\n",
      "LastYear Baseline RMSE: 3.73 minutes\n",
      "LastYear Baseline sMAPE: 2.41%\n",
      "Baseline results saved to ../models/baseline_models/castello_dei_medici\n",
      "\n",
      "Processing ride 9/31: dancing dingie\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: dancing dingie\n",
      "==================================================\n",
      "Training data size: 10292\n",
      "Validation data size: 2066\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 2.98 minutes\n",
      "Mean Baseline RMSE: 3.87 minutes\n",
      "Mean Baseline sMAPE: 30.73%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 2.80 minutes\n",
      "Time-of-Day Baseline RMSE: 3.85 minutes\n",
      "Time-of-Day Baseline sMAPE: 33.68%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 2.75 minutes\n",
      "Day+Time Baseline RMSE: 3.85 minutes\n",
      "Day+Time Baseline sMAPE: 35.07%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 2.51 minutes\n",
      "Moving Average Baseline RMSE: 3.67 minutes\n",
      "Moving Average Baseline sMAPE: 14.83%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 3.06 minutes\n",
      "Seasonal Weekly Baseline RMSE: 4.25 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 35.85%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 2.80 minutes\n",
      "Holiday-Aware Baseline RMSE: 3.91 minutes\n",
      "Holiday-Aware Baseline sMAPE: 37.38%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 2.46 minutes\n",
      "LastWeek Baseline RMSE: 4.41 minutes\n",
      "LastWeek Baseline sMAPE: 8.50%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  29%|       | 9/31 [01:08<02:23,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 3.70 minutes\n",
      "LastYear Baseline RMSE: 5.81 minutes\n",
      "LastYear Baseline sMAPE: 14.66%\n",
      "Baseline results saved to ../models/baseline_models/dancing_dingie\n",
      "\n",
      "Processing ride 10/31: euromir\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: euromir\n",
      "==================================================\n",
      "Training data size: 10289\n",
      "Validation data size: 2049\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 12.15 minutes\n",
      "Mean Baseline RMSE: 15.21 minutes\n",
      "Mean Baseline sMAPE: 25.79%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 9.62 minutes\n",
      "Time-of-Day Baseline RMSE: 13.25 minutes\n",
      "Time-of-Day Baseline sMAPE: 23.07%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 9.10 minutes\n",
      "Day+Time Baseline RMSE: 12.64 minutes\n",
      "Day+Time Baseline sMAPE: 21.97%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 12.08 minutes\n",
      "Moving Average Baseline RMSE: 14.94 minutes\n",
      "Moving Average Baseline sMAPE: 24.21%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 11.77 minutes\n",
      "Seasonal Weekly Baseline RMSE: 16.98 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 28.47%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 9.14 minutes\n",
      "Holiday-Aware Baseline RMSE: 12.71 minutes\n",
      "Holiday-Aware Baseline sMAPE: 22.22%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 8.17 minutes\n",
      "LastWeek Baseline RMSE: 12.78 minutes\n",
      "LastWeek Baseline sMAPE: 20.39%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  32%|      | 10/31 [01:13<02:07,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 8.93 minutes\n",
      "LastYear Baseline RMSE: 14.01 minutes\n",
      "LastYear Baseline sMAPE: 22.73%\n",
      "Baseline results saved to ../models/baseline_models/euromir\n",
      "\n",
      "Processing ride 11/31: eurosat  cancan coaster\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: eurosat  cancan coaster\n",
      "==================================================\n",
      "Training data size: 8650\n",
      "Validation data size: 2067\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 11.67 minutes\n",
      "Mean Baseline RMSE: 13.98 minutes\n",
      "Mean Baseline sMAPE: 23.88%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 9.19 minutes\n",
      "Time-of-Day Baseline RMSE: 11.98 minutes\n",
      "Time-of-Day Baseline sMAPE: 19.07%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 8.41 minutes\n",
      "Day+Time Baseline RMSE: 11.21 minutes\n",
      "Day+Time Baseline sMAPE: 17.93%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 11.70 minutes\n",
      "Moving Average Baseline RMSE: 14.11 minutes\n",
      "Moving Average Baseline sMAPE: 23.78%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 11.23 minutes\n",
      "Seasonal Weekly Baseline RMSE: 15.08 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 24.86%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 8.40 minutes\n",
      "Holiday-Aware Baseline RMSE: 11.20 minutes\n",
      "Holiday-Aware Baseline sMAPE: 17.94%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 7.69 minutes\n",
      "LastWeek Baseline RMSE: 11.21 minutes\n",
      "LastWeek Baseline sMAPE: 15.33%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  35%|      | 11/31 [01:18<01:54,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 8.60 minutes\n",
      "LastYear Baseline RMSE: 12.17 minutes\n",
      "LastYear Baseline sMAPE: 17.16%\n",
      "Baseline results saved to ../models/baseline_models/eurosat__cancan_coaster\n",
      "\n",
      "Processing ride 12/31: eurotower\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: eurotower\n",
      "==================================================\n",
      "Training data size: 10308\n",
      "Validation data size: 2067\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 3.61 minutes\n",
      "Mean Baseline RMSE: 5.34 minutes\n",
      "Mean Baseline sMAPE: 20.51%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 3.29 minutes\n",
      "Time-of-Day Baseline RMSE: 5.02 minutes\n",
      "Time-of-Day Baseline sMAPE: 18.88%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 3.26 minutes\n",
      "Day+Time Baseline RMSE: 4.98 minutes\n",
      "Day+Time Baseline sMAPE: 18.66%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 3.84 minutes\n",
      "Moving Average Baseline RMSE: 5.28 minutes\n",
      "Moving Average Baseline sMAPE: 21.99%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 3.33 minutes\n",
      "Seasonal Weekly Baseline RMSE: 5.78 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 17.39%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 3.24 minutes\n",
      "Holiday-Aware Baseline RMSE: 4.99 minutes\n",
      "Holiday-Aware Baseline sMAPE: 18.43%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 3.20 minutes\n",
      "LastWeek Baseline RMSE: 5.91 minutes\n",
      "LastWeek Baseline sMAPE: 14.85%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  39%|      | 12/31 [01:24<01:49,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 3.10 minutes\n",
      "LastYear Baseline RMSE: 5.78 minutes\n",
      "LastYear Baseline sMAPE: 14.17%\n",
      "Baseline results saved to ../models/baseline_models/eurotower\n",
      "\n",
      "Processing ride 13/31: fjordrafting\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: fjordrafting\n",
      "==================================================\n",
      "Training data size: 9808\n",
      "Validation data size: 2066\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 13.55 minutes\n",
      "Mean Baseline RMSE: 15.77 minutes\n",
      "Mean Baseline sMAPE: 33.07%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 11.53 minutes\n",
      "Time-of-Day Baseline RMSE: 14.54 minutes\n",
      "Time-of-Day Baseline sMAPE: 32.66%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 11.15 minutes\n",
      "Day+Time Baseline RMSE: 14.21 minutes\n",
      "Day+Time Baseline sMAPE: 31.75%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 11.92 minutes\n",
      "Moving Average Baseline RMSE: 16.00 minutes\n",
      "Moving Average Baseline sMAPE: 34.96%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 11.96 minutes\n",
      "Seasonal Weekly Baseline RMSE: 17.79 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 38.81%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 11.10 minutes\n",
      "Holiday-Aware Baseline RMSE: 14.17 minutes\n",
      "Holiday-Aware Baseline sMAPE: 31.76%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 8.52 minutes\n",
      "LastWeek Baseline RMSE: 13.56 minutes\n",
      "LastWeek Baseline sMAPE: 23.93%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  42%|     | 13/31 [01:30<01:45,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 9.68 minutes\n",
      "LastYear Baseline RMSE: 14.46 minutes\n",
      "LastYear Baseline sMAPE: 29.66%\n",
      "Baseline results saved to ../models/baseline_models/fjordrafting\n",
      "\n",
      "Processing ride 14/31: jim button  journey through morrowland\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: jim button  journey through morrowland\n",
      "==================================================\n",
      "Training data size: 8597\n",
      "Validation data size: 2065\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 2.84 minutes\n",
      "Mean Baseline RMSE: 3.08 minutes\n",
      "Mean Baseline sMAPE: 34.86%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 2.60 minutes\n",
      "Time-of-Day Baseline RMSE: 2.98 minutes\n",
      "Time-of-Day Baseline sMAPE: 32.70%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 2.49 minutes\n",
      "Day+Time Baseline RMSE: 2.94 minutes\n",
      "Day+Time Baseline sMAPE: 30.81%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 2.41 minutes\n",
      "Moving Average Baseline RMSE: 2.88 minutes\n",
      "Moving Average Baseline sMAPE: 51.60%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 1.90 minutes\n",
      "Seasonal Weekly Baseline RMSE: 3.11 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 35.91%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 2.44 minutes\n",
      "Holiday-Aware Baseline RMSE: 2.91 minutes\n",
      "Holiday-Aware Baseline sMAPE: 31.97%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 1.88 minutes\n",
      "LastWeek Baseline RMSE: 3.45 minutes\n",
      "LastWeek Baseline sMAPE: 8.92%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  45%|     | 14/31 [01:37<01:46,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 1.94 minutes\n",
      "LastYear Baseline RMSE: 3.37 minutes\n",
      "LastYear Baseline sMAPE: 9.33%\n",
      "Baseline results saved to ../models/baseline_models/jim_button__journey_through_morrowland\n",
      "\n",
      "Processing ride 15/31: josefinas magical imperial journey\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: josefinas magical imperial journey\n",
      "==================================================\n",
      "Training data size: 10266\n",
      "Validation data size: 2067\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 4.09 minutes\n",
      "Mean Baseline RMSE: 5.23 minutes\n",
      "Mean Baseline sMAPE: 41.62%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 3.59 minutes\n",
      "Time-of-Day Baseline RMSE: 4.96 minutes\n",
      "Time-of-Day Baseline sMAPE: 38.17%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 3.45 minutes\n",
      "Day+Time Baseline RMSE: 4.74 minutes\n",
      "Day+Time Baseline sMAPE: 39.01%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 4.56 minutes\n",
      "Moving Average Baseline RMSE: 5.44 minutes\n",
      "Moving Average Baseline sMAPE: 19.71%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 3.46 minutes\n",
      "Seasonal Weekly Baseline RMSE: 5.07 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 43.59%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 3.44 minutes\n",
      "Holiday-Aware Baseline RMSE: 4.77 minutes\n",
      "Holiday-Aware Baseline sMAPE: 40.95%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 3.49 minutes\n",
      "LastWeek Baseline RMSE: 5.78 minutes\n",
      "LastWeek Baseline sMAPE: 19.92%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  48%|     | 15/31 [01:43<01:40,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 4.49 minutes\n",
      "LastYear Baseline RMSE: 7.00 minutes\n",
      "LastYear Baseline sMAPE: 27.29%\n",
      "Baseline results saved to ../models/baseline_models/josefinas_magical_imperial_journey\n",
      "\n",
      "Processing ride 16/31: kolumbusjolle\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: kolumbusjolle\n",
      "==================================================\n",
      "Training data size: 10300\n",
      "Validation data size: 2067\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 2.53 minutes\n",
      "Mean Baseline RMSE: 2.63 minutes\n",
      "Mean Baseline sMAPE: 32.86%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 2.50 minutes\n",
      "Time-of-Day Baseline RMSE: 2.66 minutes\n",
      "Time-of-Day Baseline sMAPE: 33.47%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 2.50 minutes\n",
      "Day+Time Baseline RMSE: 2.67 minutes\n",
      "Day+Time Baseline sMAPE: 33.62%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 0.70 minutes\n",
      "Moving Average Baseline RMSE: 1.49 minutes\n",
      "Moving Average Baseline sMAPE: 3.71%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 1.32 minutes\n",
      "Seasonal Weekly Baseline RMSE: 2.02 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 14.03%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 2.55 minutes\n",
      "Holiday-Aware Baseline RMSE: 2.72 minutes\n",
      "Holiday-Aware Baseline sMAPE: 34.72%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 0.73 minutes\n",
      "LastWeek Baseline RMSE: 1.99 minutes\n",
      "LastWeek Baseline sMAPE: 1.91%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  52%|    | 16/31 [01:49<01:33,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 1.80 minutes\n",
      "LastYear Baseline RMSE: 3.05 minutes\n",
      "LastYear Baseline sMAPE: 1.98%\n",
      "Baseline results saved to ../models/baseline_models/kolumbusjolle\n",
      "\n",
      "Processing ride 17/31: madame freudenreich curiosits\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: madame freudenreich curiosits\n",
      "==================================================\n",
      "Training data size: 8643\n",
      "Validation data size: 2066\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 0.51 minutes\n",
      "Mean Baseline RMSE: 0.67 minutes\n",
      "Mean Baseline sMAPE: 83.00%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 0.47 minutes\n",
      "Time-of-Day Baseline RMSE: 0.65 minutes\n",
      "Time-of-Day Baseline sMAPE: 84.12%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 0.47 minutes\n",
      "Day+Time Baseline RMSE: 0.67 minutes\n",
      "Day+Time Baseline sMAPE: 83.81%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 0.16 minutes\n",
      "Moving Average Baseline RMSE: 0.54 minutes\n",
      "Moving Average Baseline sMAPE: 95.92%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 0.15 minutes\n",
      "Seasonal Weekly Baseline RMSE: 0.62 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 60.00%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 0.47 minutes\n",
      "Holiday-Aware Baseline RMSE: 0.67 minutes\n",
      "Holiday-Aware Baseline sMAPE: 83.32%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 0.13 minutes\n",
      "LastWeek Baseline RMSE: 0.77 minutes\n",
      "LastWeek Baseline sMAPE: 0.00%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  55%|    | 17/31 [01:55<01:22,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 0.07 minutes\n",
      "LastYear Baseline RMSE: 0.60 minutes\n",
      "LastYear Baseline sMAPE: 0.00%\n",
      "Baseline results saved to ../models/baseline_models/madame_freudenreich_curiosits\n",
      "\n",
      "Processing ride 18/31: matterhornblitz\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: matterhornblitz\n",
      "==================================================\n",
      "Training data size: 10299\n",
      "Validation data size: 2065\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 12.61 minutes\n",
      "Mean Baseline RMSE: 15.29 minutes\n",
      "Mean Baseline sMAPE: 20.42%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 9.03 minutes\n",
      "Time-of-Day Baseline RMSE: 12.38 minutes\n",
      "Time-of-Day Baseline sMAPE: 17.04%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 8.63 minutes\n",
      "Day+Time Baseline RMSE: 11.93 minutes\n",
      "Day+Time Baseline sMAPE: 16.39%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 12.63 minutes\n",
      "Moving Average Baseline RMSE: 15.31 minutes\n",
      "Moving Average Baseline sMAPE: 20.59%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 12.56 minutes\n",
      "Seasonal Weekly Baseline RMSE: 17.83 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 25.08%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 8.67 minutes\n",
      "Holiday-Aware Baseline RMSE: 11.94 minutes\n",
      "Holiday-Aware Baseline sMAPE: 16.61%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 7.42 minutes\n",
      "LastWeek Baseline RMSE: 11.54 minutes\n",
      "LastWeek Baseline sMAPE: 15.52%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  58%|    | 18/31 [02:00<01:15,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 7.85 minutes\n",
      "LastYear Baseline RMSE: 11.94 minutes\n",
      "LastYear Baseline sMAPE: 16.96%\n",
      "Baseline results saved to ../models/baseline_models/matterhornblitz\n",
      "\n",
      "Processing ride 19/31: old mac donalds tractor fun\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: old mac donalds tractor fun\n",
      "==================================================\n",
      "Training data size: 10292\n",
      "Validation data size: 2065\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 2.13 minutes\n",
      "Mean Baseline RMSE: 2.45 minutes\n",
      "Mean Baseline sMAPE: 52.18%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 1.94 minutes\n",
      "Time-of-Day Baseline RMSE: 2.41 minutes\n",
      "Time-of-Day Baseline sMAPE: 48.83%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 1.86 minutes\n",
      "Day+Time Baseline RMSE: 2.37 minutes\n",
      "Day+Time Baseline sMAPE: 46.71%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 2.63 minutes\n",
      "Moving Average Baseline RMSE: 2.77 minutes\n",
      "Moving Average Baseline sMAPE: 37.12%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 1.64 minutes\n",
      "Seasonal Weekly Baseline RMSE: 2.42 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 44.44%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 1.80 minutes\n",
      "Holiday-Aware Baseline RMSE: 2.35 minutes\n",
      "Holiday-Aware Baseline sMAPE: 48.01%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 1.48 minutes\n",
      "LastWeek Baseline RMSE: 3.02 minutes\n",
      "LastWeek Baseline sMAPE: 8.68%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  61%|   | 19/31 [02:07<01:12,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 1.93 minutes\n",
      "LastYear Baseline RMSE: 3.41 minutes\n",
      "LastYear Baseline sMAPE: 11.03%\n",
      "Baseline results saved to ../models/baseline_models/old_mac_donalds_tractor_fun\n",
      "\n",
      "Processing ride 20/31: pegasus\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: pegasus\n",
      "==================================================\n",
      "Training data size: 10299\n",
      "Validation data size: 2067\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 6.87 minutes\n",
      "Mean Baseline RMSE: 8.49 minutes\n",
      "Mean Baseline sMAPE: 25.67%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 5.53 minutes\n",
      "Time-of-Day Baseline RMSE: 7.55 minutes\n",
      "Time-of-Day Baseline sMAPE: 22.90%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 5.46 minutes\n",
      "Day+Time Baseline RMSE: 7.48 minutes\n",
      "Day+Time Baseline sMAPE: 22.95%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 6.72 minutes\n",
      "Moving Average Baseline RMSE: 8.43 minutes\n",
      "Moving Average Baseline sMAPE: 26.08%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 6.84 minutes\n",
      "Seasonal Weekly Baseline RMSE: 10.23 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 34.72%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 5.40 minutes\n",
      "Holiday-Aware Baseline RMSE: 7.44 minutes\n",
      "Holiday-Aware Baseline sMAPE: 22.75%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 5.31 minutes\n",
      "LastWeek Baseline RMSE: 8.20 minutes\n",
      "LastWeek Baseline sMAPE: 22.93%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  65%|   | 20/31 [02:12<01:04,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 5.59 minutes\n",
      "LastYear Baseline RMSE: 8.54 minutes\n",
      "LastYear Baseline sMAPE: 24.87%\n",
      "Baseline results saved to ../models/baseline_models/pegasus\n",
      "\n",
      "Processing ride 21/31: poppy towers\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: poppy towers\n",
      "==================================================\n",
      "Training data size: 10276\n",
      "Validation data size: 2065\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 2.46 minutes\n",
      "Mean Baseline RMSE: 2.87 minutes\n",
      "Mean Baseline sMAPE: 27.06%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 2.45 minutes\n",
      "Time-of-Day Baseline RMSE: 2.94 minutes\n",
      "Time-of-Day Baseline sMAPE: 29.31%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 2.44 minutes\n",
      "Day+Time Baseline RMSE: 2.94 minutes\n",
      "Day+Time Baseline sMAPE: 29.65%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 1.16 minutes\n",
      "Moving Average Baseline RMSE: 2.16 minutes\n",
      "Moving Average Baseline sMAPE: 6.94%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 1.96 minutes\n",
      "Seasonal Weekly Baseline RMSE: 2.82 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 19.82%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 2.49 minutes\n",
      "Holiday-Aware Baseline RMSE: 2.98 minutes\n",
      "Holiday-Aware Baseline sMAPE: 30.63%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 1.24 minutes\n",
      "LastWeek Baseline RMSE: 2.76 minutes\n",
      "LastWeek Baseline sMAPE: 4.91%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  68%|   | 21/31 [02:17<00:56,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 2.16 minutes\n",
      "LastYear Baseline RMSE: 3.42 minutes\n",
      "LastYear Baseline sMAPE: 5.57%\n",
      "Baseline results saved to ../models/baseline_models/poppy_towers\n",
      "\n",
      "Processing ride 22/31: poseidon\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: poseidon\n",
      "==================================================\n",
      "Training data size: 9832\n",
      "Validation data size: 2064\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 15.90 minutes\n",
      "Mean Baseline RMSE: 18.20 minutes\n",
      "Mean Baseline sMAPE: 31.77%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 13.56 minutes\n",
      "Time-of-Day Baseline RMSE: 16.88 minutes\n",
      "Time-of-Day Baseline sMAPE: 28.46%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 13.11 minutes\n",
      "Day+Time Baseline RMSE: 16.50 minutes\n",
      "Day+Time Baseline sMAPE: 27.64%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 15.17 minutes\n",
      "Moving Average Baseline RMSE: 21.94 minutes\n",
      "Moving Average Baseline sMAPE: 71.21%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 15.37 minutes\n",
      "Seasonal Weekly Baseline RMSE: 23.35 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 72.73%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 13.06 minutes\n",
      "Holiday-Aware Baseline RMSE: 16.48 minutes\n",
      "Holiday-Aware Baseline sMAPE: 27.94%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 9.93 minutes\n",
      "LastWeek Baseline RMSE: 15.62 minutes\n",
      "LastWeek Baseline sMAPE: 24.61%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  71%|   | 22/31 [02:23<00:51,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 10.45 minutes\n",
      "LastYear Baseline RMSE: 16.64 minutes\n",
      "LastYear Baseline sMAPE: 26.24%\n",
      "Baseline results saved to ../models/baseline_models/poseidon\n",
      "\n",
      "Processing ride 23/31: silver star\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: silver star\n",
      "==================================================\n",
      "Training data size: 10244\n",
      "Validation data size: 2064\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 10.89 minutes\n",
      "Mean Baseline RMSE: 13.65 minutes\n",
      "Mean Baseline sMAPE: 25.21%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 9.46 minutes\n",
      "Time-of-Day Baseline RMSE: 12.32 minutes\n",
      "Time-of-Day Baseline sMAPE: 21.51%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 8.55 minutes\n",
      "Day+Time Baseline RMSE: 11.39 minutes\n",
      "Day+Time Baseline sMAPE: 20.08%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 11.43 minutes\n",
      "Moving Average Baseline RMSE: 13.69 minutes\n",
      "Moving Average Baseline sMAPE: 25.81%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 11.31 minutes\n",
      "Seasonal Weekly Baseline RMSE: 15.31 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 29.20%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 8.56 minutes\n",
      "Holiday-Aware Baseline RMSE: 11.44 minutes\n",
      "Holiday-Aware Baseline sMAPE: 20.21%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 8.45 minutes\n",
      "LastWeek Baseline RMSE: 12.31 minutes\n",
      "LastWeek Baseline sMAPE: 19.53%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  74%|  | 23/31 [02:29<00:44,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 9.02 minutes\n",
      "LastYear Baseline RMSE: 13.02 minutes\n",
      "LastYear Baseline sMAPE: 21.15%\n",
      "Baseline results saved to ../models/baseline_models/silver_star\n",
      "\n",
      "Processing ride 24/31: swiss bob run\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: swiss bob run\n",
      "==================================================\n",
      "Training data size: 10293\n",
      "Validation data size: 2066\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 12.48 minutes\n",
      "Mean Baseline RMSE: 14.64 minutes\n",
      "Mean Baseline sMAPE: 22.39%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 9.64 minutes\n",
      "Time-of-Day Baseline RMSE: 12.42 minutes\n",
      "Time-of-Day Baseline sMAPE: 19.77%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 9.32 minutes\n",
      "Day+Time Baseline RMSE: 12.10 minutes\n",
      "Day+Time Baseline sMAPE: 19.30%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 12.36 minutes\n",
      "Moving Average Baseline RMSE: 14.53 minutes\n",
      "Moving Average Baseline sMAPE: 21.63%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 13.37 minutes\n",
      "Seasonal Weekly Baseline RMSE: 17.99 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 30.18%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 9.40 minutes\n",
      "Holiday-Aware Baseline RMSE: 12.16 minutes\n",
      "Holiday-Aware Baseline sMAPE: 19.63%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 7.11 minutes\n",
      "LastWeek Baseline RMSE: 10.80 minutes\n",
      "LastWeek Baseline sMAPE: 15.93%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  77%|  | 24/31 [02:34<00:38,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 7.60 minutes\n",
      "LastYear Baseline RMSE: 11.41 minutes\n",
      "LastYear Baseline sMAPE: 17.15%\n",
      "Baseline results saved to ../models/baseline_models/swiss_bob_run\n",
      "\n",
      "Processing ride 25/31: tirol log flume\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: tirol log flume\n",
      "==================================================\n",
      "Training data size: 9849\n",
      "Validation data size: 2019\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 8.90 minutes\n",
      "Mean Baseline RMSE: 11.50 minutes\n",
      "Mean Baseline sMAPE: 28.99%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 6.89 minutes\n",
      "Time-of-Day Baseline RMSE: 10.11 minutes\n",
      "Time-of-Day Baseline sMAPE: 26.88%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 6.51 minutes\n",
      "Day+Time Baseline RMSE: 9.26 minutes\n",
      "Day+Time Baseline sMAPE: 25.60%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 11.32 minutes\n",
      "Moving Average Baseline RMSE: 15.95 minutes\n",
      "Moving Average Baseline sMAPE: 0.00%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 11.32 minutes\n",
      "Seasonal Weekly Baseline RMSE: 15.95 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 0.00%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 6.46 minutes\n",
      "Holiday-Aware Baseline RMSE: 9.25 minutes\n",
      "Holiday-Aware Baseline sMAPE: 25.36%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 1.94 minutes\n",
      "LastWeek Baseline RMSE: 5.46 minutes\n",
      "LastWeek Baseline sMAPE: 4.30%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  81%|  | 25/31 [02:40<00:34,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 9.49 minutes\n",
      "LastYear Baseline RMSE: 13.66 minutes\n",
      "LastYear Baseline sMAPE: 30.33%\n",
      "Baseline results saved to ../models/baseline_models/tirol_log_flume\n",
      "\n",
      "Processing ride 26/31: vienna wave swing  glckspilz\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: vienna wave swing  glckspilz\n",
      "==================================================\n",
      "Training data size: 8416\n",
      "Validation data size: 2067\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 2.20 minutes\n",
      "Mean Baseline RMSE: 2.57 minutes\n",
      "Mean Baseline sMAPE: 23.35%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 2.20 minutes\n",
      "Time-of-Day Baseline RMSE: 2.64 minutes\n",
      "Time-of-Day Baseline sMAPE: 25.04%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 2.16 minutes\n",
      "Day+Time Baseline RMSE: 2.62 minutes\n",
      "Day+Time Baseline sMAPE: 25.09%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 0.91 minutes\n",
      "Moving Average Baseline RMSE: 1.96 minutes\n",
      "Moving Average Baseline sMAPE: 4.41%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 1.49 minutes\n",
      "Seasonal Weekly Baseline RMSE: 2.30 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 13.53%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 2.22 minutes\n",
      "Holiday-Aware Baseline RMSE: 2.65 minutes\n",
      "Holiday-Aware Baseline sMAPE: 26.00%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 0.95 minutes\n",
      "LastWeek Baseline RMSE: 2.21 minutes\n",
      "LastWeek Baseline sMAPE: 3.71%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  84%| | 26/31 [02:45<00:27,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 2.13 minutes\n",
      "LastYear Baseline RMSE: 3.38 minutes\n",
      "LastYear Baseline sMAPE: 6.10%\n",
      "Baseline results saved to ../models/baseline_models/vienna_wave_swing__glckspilz\n",
      "\n",
      "Processing ride 27/31: vindjammer\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: vindjammer\n",
      "==================================================\n",
      "Training data size: 10258\n",
      "Validation data size: 2064\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 2.82 minutes\n",
      "Mean Baseline RMSE: 3.50 minutes\n",
      "Mean Baseline sMAPE: 29.33%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 2.76 minutes\n",
      "Time-of-Day Baseline RMSE: 3.50 minutes\n",
      "Time-of-Day Baseline sMAPE: 31.29%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 2.72 minutes\n",
      "Day+Time Baseline RMSE: 3.43 minutes\n",
      "Day+Time Baseline sMAPE: 31.83%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 2.47 minutes\n",
      "Moving Average Baseline RMSE: 3.27 minutes\n",
      "Moving Average Baseline sMAPE: 21.02%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 2.52 minutes\n",
      "Seasonal Weekly Baseline RMSE: 3.54 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 23.58%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 2.77 minutes\n",
      "Holiday-Aware Baseline RMSE: 3.46 minutes\n",
      "Holiday-Aware Baseline sMAPE: 32.93%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 1.70 minutes\n",
      "LastWeek Baseline RMSE: 3.43 minutes\n",
      "LastWeek Baseline sMAPE: 6.07%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  87%| | 27/31 [02:50<00:21,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 2.56 minutes\n",
      "LastYear Baseline RMSE: 3.97 minutes\n",
      "LastYear Baseline sMAPE: 8.28%\n",
      "Baseline results saved to ../models/baseline_models/vindjammer\n",
      "\n",
      "Processing ride 28/31: voletarium\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: voletarium\n",
      "==================================================\n",
      "Training data size: 8430\n",
      "Validation data size: 2067\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 14.25 minutes\n",
      "Mean Baseline RMSE: 16.78 minutes\n",
      "Mean Baseline sMAPE: 35.47%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 11.02 minutes\n",
      "Time-of-Day Baseline RMSE: 13.40 minutes\n",
      "Time-of-Day Baseline sMAPE: 30.09%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 10.35 minutes\n",
      "Day+Time Baseline RMSE: 12.93 minutes\n",
      "Day+Time Baseline sMAPE: 28.57%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 14.74 minutes\n",
      "Moving Average Baseline RMSE: 17.23 minutes\n",
      "Moving Average Baseline sMAPE: 35.66%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 10.36 minutes\n",
      "Seasonal Weekly Baseline RMSE: 13.51 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 27.80%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 10.26 minutes\n",
      "Holiday-Aware Baseline RMSE: 12.93 minutes\n",
      "Holiday-Aware Baseline sMAPE: 28.33%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 10.11 minutes\n",
      "LastWeek Baseline RMSE: 14.68 minutes\n",
      "LastWeek Baseline sMAPE: 24.82%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  90%| | 28/31 [02:55<00:15,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 10.27 minutes\n",
      "LastYear Baseline RMSE: 14.78 minutes\n",
      "LastYear Baseline sMAPE: 26.03%\n",
      "Baseline results saved to ../models/baseline_models/voletarium\n",
      "\n",
      "Processing ride 29/31: volo da vinci\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: volo da vinci\n",
      "==================================================\n",
      "Training data size: 10309\n",
      "Validation data size: 2066\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 6.34 minutes\n",
      "Mean Baseline RMSE: 7.68 minutes\n",
      "Mean Baseline sMAPE: 22.79%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 6.12 minutes\n",
      "Time-of-Day Baseline RMSE: 7.38 minutes\n",
      "Time-of-Day Baseline sMAPE: 23.65%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 5.84 minutes\n",
      "Day+Time Baseline RMSE: 7.16 minutes\n",
      "Day+Time Baseline sMAPE: 22.77%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 6.36 minutes\n",
      "Moving Average Baseline RMSE: 7.65 minutes\n",
      "Moving Average Baseline sMAPE: 21.32%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 6.72 minutes\n",
      "Seasonal Weekly Baseline RMSE: 8.56 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 27.30%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 5.86 minutes\n",
      "Holiday-Aware Baseline RMSE: 7.20 minutes\n",
      "Holiday-Aware Baseline sMAPE: 23.13%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 5.19 minutes\n",
      "LastWeek Baseline RMSE: 7.39 minutes\n",
      "LastWeek Baseline sMAPE: 19.16%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  94%|| 29/31 [03:00<00:10,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 5.57 minutes\n",
      "LastYear Baseline RMSE: 7.64 minutes\n",
      "LastYear Baseline sMAPE: 19.35%\n",
      "Baseline results saved to ../models/baseline_models/volo_da_vinci\n",
      "\n",
      "Processing ride 30/31: voltron nevera powered by rimac\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: voltron nevera powered by rimac\n",
      "==================================================\n",
      "Training data size: 0\n",
      "Validation data size: 0\n",
      "Skipping voltron nevera powered by rimac due to insufficient data\n",
      "\n",
      "Processing ride 31/31: whale adventures  northern lights\n",
      "\n",
      "==================================================\n",
      "Processing baseline models for ride: whale adventures  northern lights\n",
      "==================================================\n",
      "Training data size: 10314\n",
      "Validation data size: 2063\n",
      "  Training Mean Baseline...\n",
      "\n",
      "Mean Baseline MAE: 1.52 minutes\n",
      "Mean Baseline RMSE: 2.31 minutes\n",
      "Mean Baseline sMAPE: 70.81%\n",
      "  Training Time-of-Day Baseline...\n",
      "\n",
      "Time-of-Day Baseline MAE: 1.39 minutes\n",
      "Time-of-Day Baseline RMSE: 2.24 minutes\n",
      "Time-of-Day Baseline sMAPE: 61.33%\n",
      "  Training Day+Time Baseline...\n",
      "\n",
      "Day+Time Baseline MAE: 1.38 minutes\n",
      "Day+Time Baseline RMSE: 2.24 minutes\n",
      "Day+Time Baseline sMAPE: 60.73%\n",
      "  Training Moving Average Baseline...\n",
      "\n",
      "Moving Average Baseline MAE: 1.64 minutes\n",
      "Moving Average Baseline RMSE: 2.33 minutes\n",
      "Moving Average Baseline sMAPE: 67.05%\n",
      "  Training Seasonal Weekly Baseline...\n",
      "\n",
      "Seasonal Weekly Baseline MAE: 1.00 minutes\n",
      "Seasonal Weekly Baseline RMSE: 2.38 minutes\n",
      "Seasonal Weekly Baseline sMAPE: 56.37%\n",
      "  Training Holiday-Aware Baseline...\n",
      "\n",
      "Holiday-Aware Baseline MAE: 1.38 minutes\n",
      "Holiday-Aware Baseline RMSE: 2.24 minutes\n",
      "Holiday-Aware Baseline sMAPE: 60.83%\n",
      "  Training LastWeek Baseline...\n",
      "\n",
      "LastWeek Baseline MAE: 1.05 minutes\n",
      "LastWeek Baseline RMSE: 2.72 minutes\n",
      "LastWeek Baseline sMAPE: 16.17%\n",
      "  Training LastYear Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides: 100%|| 31/31 [03:05<00:00,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LastYear Baseline MAE: 1.11 minutes\n",
      "LastYear Baseline RMSE: 2.59 minutes\n",
      "LastYear Baseline sMAPE: 12.26%\n",
      "Baseline results saved to ../models/baseline_models/whale_adventures__northern_lights\n",
      "\n",
      "================================================================================\n",
      "BASELINE MODELS SUMMARY:\n",
      "Total rides processed: 30\n",
      "Total model evaluations: 240\n",
      "\n",
      "Model Performance (Average MAE):\n",
      "                 model_name  mae_mean\n",
      "2         LastWeek Baseline      4.52\n",
      "1    Holiday-Aware Baseline      5.62\n",
      "0         Day+Time Baseline      5.63\n",
      "3         LastYear Baseline      5.81\n",
      "7      Time-of-Day Baseline      5.90\n",
      "6  Seasonal Weekly Baseline      6.83\n",
      "4             Mean Baseline      6.96\n",
      "5   Moving Average Baseline      6.98\n",
      "\n",
      "Detailed summary saved to: ../models/baseline_models/detailed_baseline_summary.csv\n",
      "Model comparison saved to: ../models/baseline_models/model_comparison_summary.csv\n",
      "Best models per ride saved to: ../models/baseline_models/best_model_per_ride.csv\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizations saved to output directory.\n",
      "\n",
      "============================================================\n",
      "BASELINE MODEL PROCESSING COMPLETED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Loading data...\")\n",
    "data = load_data(\"../data/processed/ep/final_cleaned_processed_wait_times.parquet\")\n",
    "print(f\"Loaded data with {len(data)} rows\")\n",
    "\n",
    "check_for_missing_values(data)\n",
    "\n",
    "data = filter_to_operating_hours(data)\n",
    "\n",
    "# Define time periods for splitting\n",
    "train_years, val_year, test_year = list(range(2017, 2023)), 2023, 2024\n",
    "\n",
    "# Split the data\n",
    "train_data, val_data, test_data = split_data(data, train_years, val_year, test_year)\n",
    "\n",
    "# Get all rides in the dataset\n",
    "all_rides = get_all_rides(data)\n",
    "print(f\"Found {len(all_rides)} rides in the dataset:\")\n",
    "for i, ride in enumerate(all_rides):\n",
    "    print(f\"{i+1}. {ride}\")\n",
    "\n",
    "# Set output directory for baseline models and results\n",
    "output_dir = \"../models/baseline_models/\"\n",
    "\n",
    "# Process all rides with baseline models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING BASELINE MODEL PROCESSING FOR ALL RIDES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = process_all_rides_baselines(\n",
    "    all_rides=all_rides,\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    output_dir=output_dir,\n",
    "    resume=True  # Resume from checkpoint if available\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE MODEL PROCESSING COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bdf915",
   "metadata": {},
   "source": [
    "## Analysis Functions for Loaded Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbda7932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BASELINE MODELS ANALYSIS\n",
      "============================================================\n",
      "\n",
      "1. Overall Model Performance (sorted by average MAE):\n",
      "                 model_name  mae_mean  mae_std\n",
      "2         LastWeek Baseline      4.52     3.43\n",
      "1    Holiday-Aware Baseline      5.62     3.63\n",
      "0         Day+Time Baseline      5.63     3.64\n",
      "3         LastYear Baseline      5.81     3.55\n",
      "7      Time-of-Day Baseline      5.90     3.86\n",
      "6  Seasonal Weekly Baseline      6.83     5.11\n",
      "4             Mean Baseline      6.96     4.86\n",
      "5   Moving Average Baseline      6.98     5.14\n",
      "\n",
      "2. Best performing model distribution:\n",
      "model_name\n",
      "LastWeek Baseline           23\n",
      "Moving Average Baseline      3\n",
      "LastYear Baseline            2\n",
      "Seasonal Weekly Baseline     1\n",
      "Holiday-Aware Baseline       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "3. Top 10 rides with lowest MAE:\n",
      "                           ride_name                model_name       mae\n",
      "0      madame freudenreich curiosits         LastYear Baseline  0.072604\n",
      "1                      kolumbusjolle   Moving Average Baseline  0.702860\n",
      "2   arena of football  be part of it         LastWeek Baseline  0.714049\n",
      "3       vienna wave swing  glckspilz   Moving Average Baseline  0.911647\n",
      "4  whale adventures  northern lights  Seasonal Weekly Baseline  0.996122\n",
      "5                       poppy towers   Moving Average Baseline  1.162429\n",
      "6        old mac donalds tractor fun         LastWeek Baseline  1.483490\n",
      "7                castello dei medici         LastWeek Baseline  1.551188\n",
      "8                         vindjammer         LastWeek Baseline  1.695793\n",
      "9                 atlantis adventure         LastWeek Baseline  1.794465\n",
      "\n",
      "4. Worst 10 rides with highest MAE:\n",
      "                  ride_name         model_name        mae\n",
      "20          matterhornblitz  LastWeek Baseline   7.421017\n",
      "21    atlantica supersplash  LastWeek Baseline   7.468462\n",
      "22  eurosat  cancan coaster  LastWeek Baseline   7.686511\n",
      "23                  euromir  LastWeek Baseline   8.174602\n",
      "24              silver star  LastWeek Baseline   8.454386\n",
      "25             fjordrafting  LastWeek Baseline   8.521588\n",
      "26                   arthur  LastWeek Baseline   8.528912\n",
      "27                 poseidon  LastWeek Baseline   9.930897\n",
      "28               voletarium  LastWeek Baseline  10.107170\n",
      "29    blue fire megacoaster  LastWeek Baseline  11.022413\n"
     ]
    }
   ],
   "source": [
    "def analyze_baseline_results(output_dir=\"../models/baseline_models/\"):\n",
    "    \"\"\"Load and analyze saved baseline model results.\"\"\"\n",
    "    \n",
    "    # Check if summary files exist\n",
    "    summary_path = os.path.join(output_dir, \"model_comparison_summary.csv\")\n",
    "    if not os.path.exists(summary_path):\n",
    "        print(\"Summary files not found. Run the processing pipeline first.\")\n",
    "        return None\n",
    "    \n",
    "    # Load summary data\n",
    "    model_summary = pd.read_csv(summary_path)\n",
    "    detailed_summary = pd.read_csv(os.path.join(output_dir, \"detailed_baseline_summary.csv\"))\n",
    "    best_per_ride = pd.read_csv(os.path.join(output_dir, \"best_model_per_ride.csv\"))\n",
    "    \n",
    "    # Display key insights\n",
    "    print(\"=\"*60)\n",
    "    print(\"BASELINE MODELS ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n1. Overall Model Performance (sorted by average MAE):\")\n",
    "    print(model_summary[['model_name', 'mae_mean', 'mae_std']].sort_values('mae_mean'))\n",
    "    \n",
    "    print(\"\\n2. Best performing model distribution:\")\n",
    "    best_counts = best_per_ride['model_name'].value_counts()\n",
    "    print(best_counts)\n",
    "    \n",
    "    print(\"\\n3. Top 10 rides with lowest MAE:\")\n",
    "    print(best_per_ride.head(10)[['ride_name', 'model_name', 'mae']])\n",
    "    \n",
    "    print(\"\\n4. Worst 10 rides with highest MAE:\")\n",
    "    print(best_per_ride.tail(10)[['ride_name', 'model_name', 'mae']])\n",
    "    \n",
    "    return {\n",
    "        'model_summary': model_summary,\n",
    "        'detailed_summary': detailed_summary,\n",
    "        'best_per_ride': best_per_ride\n",
    "    }\n",
    "\n",
    "results = analyze_baseline_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab5c2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>mae_mean</th>\n",
       "      <th>mae_std</th>\n",
       "      <th>mae_median</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>rmse_median</th>\n",
       "      <th>smape_mean</th>\n",
       "      <th>smape_std</th>\n",
       "      <th>smape_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day+Time Baseline</td>\n",
       "      <td>5.63</td>\n",
       "      <td>3.64</td>\n",
       "      <td>4.86</td>\n",
       "      <td>7.40</td>\n",
       "      <td>4.82</td>\n",
       "      <td>6.56</td>\n",
       "      <td>31.13</td>\n",
       "      <td>14.09</td>\n",
       "      <td>29.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Holiday-Aware Baseline</td>\n",
       "      <td>5.62</td>\n",
       "      <td>3.63</td>\n",
       "      <td>4.82</td>\n",
       "      <td>7.41</td>\n",
       "      <td>4.82</td>\n",
       "      <td>6.61</td>\n",
       "      <td>31.61</td>\n",
       "      <td>14.23</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3.43</td>\n",
       "      <td>3.35</td>\n",
       "      <td>7.41</td>\n",
       "      <td>4.81</td>\n",
       "      <td>6.13</td>\n",
       "      <td>13.07</td>\n",
       "      <td>7.76</td>\n",
       "      <td>15.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LastYear Baseline</td>\n",
       "      <td>5.81</td>\n",
       "      <td>3.55</td>\n",
       "      <td>5.58</td>\n",
       "      <td>8.68</td>\n",
       "      <td>5.07</td>\n",
       "      <td>8.09</td>\n",
       "      <td>16.87</td>\n",
       "      <td>9.38</td>\n",
       "      <td>17.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mean Baseline</td>\n",
       "      <td>6.96</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.22</td>\n",
       "      <td>8.54</td>\n",
       "      <td>5.88</td>\n",
       "      <td>6.94</td>\n",
       "      <td>32.94</td>\n",
       "      <td>15.01</td>\n",
       "      <td>29.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Moving Average Baseline</td>\n",
       "      <td>6.98</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.85</td>\n",
       "      <td>6.48</td>\n",
       "      <td>6.87</td>\n",
       "      <td>27.50</td>\n",
       "      <td>20.81</td>\n",
       "      <td>23.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Seasonal Weekly Baseline</td>\n",
       "      <td>6.83</td>\n",
       "      <td>5.11</td>\n",
       "      <td>5.78</td>\n",
       "      <td>9.65</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.70</td>\n",
       "      <td>31.31</td>\n",
       "      <td>15.05</td>\n",
       "      <td>29.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Time-of-Day Baseline</td>\n",
       "      <td>5.90</td>\n",
       "      <td>3.86</td>\n",
       "      <td>4.97</td>\n",
       "      <td>7.68</td>\n",
       "      <td>5.05</td>\n",
       "      <td>6.71</td>\n",
       "      <td>31.83</td>\n",
       "      <td>14.07</td>\n",
       "      <td>29.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_name  mae_mean  mae_std  mae_median  rmse_mean  \\\n",
       "0         Day+Time Baseline      5.63     3.64        4.86       7.40   \n",
       "1    Holiday-Aware Baseline      5.62     3.63        4.82       7.41   \n",
       "2         LastWeek Baseline      4.52     3.43        3.35       7.41   \n",
       "3         LastYear Baseline      5.81     3.55        5.58       8.68   \n",
       "4             Mean Baseline      6.96     4.86        5.22       8.54   \n",
       "5   Moving Average Baseline      6.98     5.14        5.67       8.85   \n",
       "6  Seasonal Weekly Baseline      6.83     5.11        5.78       9.65   \n",
       "7      Time-of-Day Baseline      5.90     3.86        4.97       7.68   \n",
       "\n",
       "   rmse_std  rmse_median  smape_mean  smape_std  smape_median  \n",
       "0      4.82         6.56       31.13      14.09         29.10  \n",
       "1      4.82         6.61       31.61      14.23         29.00  \n",
       "2      4.81         6.13       13.07       7.76         15.09  \n",
       "3      5.07         8.09       16.87       9.38         17.15  \n",
       "4      5.88         6.94       32.94      15.01         29.16  \n",
       "5      6.48         6.87       27.50      20.81         23.34  \n",
       "6      7.08         7.70       31.31      15.05         29.69  \n",
       "7      5.05         6.71       31.83      14.07         29.70  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"model_summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afac3449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_name</th>\n",
       "      <th>train_data_size</th>\n",
       "      <th>val_data_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>smape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpine express enzian</td>\n",
       "      <td>10302</td>\n",
       "      <td>2019</td>\n",
       "      <td>Mean Baseline</td>\n",
       "      <td>7.867062</td>\n",
       "      <td>9.636920</td>\n",
       "      <td>22.562017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpine express enzian</td>\n",
       "      <td>10302</td>\n",
       "      <td>2019</td>\n",
       "      <td>Time-of-Day Baseline</td>\n",
       "      <td>6.768024</td>\n",
       "      <td>8.271249</td>\n",
       "      <td>24.178457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpine express enzian</td>\n",
       "      <td>10302</td>\n",
       "      <td>2019</td>\n",
       "      <td>Day+Time Baseline</td>\n",
       "      <td>6.042877</td>\n",
       "      <td>7.480032</td>\n",
       "      <td>22.385837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpine express enzian</td>\n",
       "      <td>10302</td>\n",
       "      <td>2019</td>\n",
       "      <td>Moving Average Baseline</td>\n",
       "      <td>7.044948</td>\n",
       "      <td>8.790591</td>\n",
       "      <td>22.896676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpine express enzian</td>\n",
       "      <td>10302</td>\n",
       "      <td>2019</td>\n",
       "      <td>Seasonal Weekly Baseline</td>\n",
       "      <td>7.989723</td>\n",
       "      <td>10.585238</td>\n",
       "      <td>39.458133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>whale adventures  northern lights</td>\n",
       "      <td>10314</td>\n",
       "      <td>2063</td>\n",
       "      <td>Moving Average Baseline</td>\n",
       "      <td>1.638239</td>\n",
       "      <td>2.332535</td>\n",
       "      <td>67.045061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>whale adventures  northern lights</td>\n",
       "      <td>10314</td>\n",
       "      <td>2063</td>\n",
       "      <td>Seasonal Weekly Baseline</td>\n",
       "      <td>0.996122</td>\n",
       "      <td>2.378914</td>\n",
       "      <td>56.369556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>whale adventures  northern lights</td>\n",
       "      <td>10314</td>\n",
       "      <td>2063</td>\n",
       "      <td>Holiday-Aware Baseline</td>\n",
       "      <td>1.375083</td>\n",
       "      <td>2.243407</td>\n",
       "      <td>60.826685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>whale adventures  northern lights</td>\n",
       "      <td>10314</td>\n",
       "      <td>2063</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>1.048697</td>\n",
       "      <td>2.717328</td>\n",
       "      <td>16.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>whale adventures  northern lights</td>\n",
       "      <td>10314</td>\n",
       "      <td>2063</td>\n",
       "      <td>LastYear Baseline</td>\n",
       "      <td>1.107610</td>\n",
       "      <td>2.593384</td>\n",
       "      <td>12.261905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ride_name  train_data_size  val_data_size  \\\n",
       "0                alpine express enzian            10302           2019   \n",
       "1                alpine express enzian            10302           2019   \n",
       "2                alpine express enzian            10302           2019   \n",
       "3                alpine express enzian            10302           2019   \n",
       "4                alpine express enzian            10302           2019   \n",
       "..                                 ...              ...            ...   \n",
       "235  whale adventures  northern lights            10314           2063   \n",
       "236  whale adventures  northern lights            10314           2063   \n",
       "237  whale adventures  northern lights            10314           2063   \n",
       "238  whale adventures  northern lights            10314           2063   \n",
       "239  whale adventures  northern lights            10314           2063   \n",
       "\n",
       "                   model_name       mae       rmse      smape  \n",
       "0               Mean Baseline  7.867062   9.636920  22.562017  \n",
       "1        Time-of-Day Baseline  6.768024   8.271249  24.178457  \n",
       "2           Day+Time Baseline  6.042877   7.480032  22.385837  \n",
       "3     Moving Average Baseline  7.044948   8.790591  22.896676  \n",
       "4    Seasonal Weekly Baseline  7.989723  10.585238  39.458133  \n",
       "..                        ...       ...        ...        ...  \n",
       "235   Moving Average Baseline  1.638239   2.332535  67.045061  \n",
       "236  Seasonal Weekly Baseline  0.996122   2.378914  56.369556  \n",
       "237    Holiday-Aware Baseline  1.375083   2.243407  60.826685  \n",
       "238         LastWeek Baseline  1.048697   2.717328  16.170213  \n",
       "239         LastYear Baseline  1.107610   2.593384  12.261905  \n",
       "\n",
       "[240 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"detailed_summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb54e5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>smape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>madame freudenreich curiosits</td>\n",
       "      <td>LastYear Baseline</td>\n",
       "      <td>0.072604</td>\n",
       "      <td>0.602512</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kolumbusjolle</td>\n",
       "      <td>Moving Average Baseline</td>\n",
       "      <td>0.702860</td>\n",
       "      <td>1.489051</td>\n",
       "      <td>3.714653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arena of football  be part of it</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>0.714049</td>\n",
       "      <td>1.987732</td>\n",
       "      <td>2.332204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vienna wave swing  glckspilz</td>\n",
       "      <td>Moving Average Baseline</td>\n",
       "      <td>0.911647</td>\n",
       "      <td>1.959635</td>\n",
       "      <td>4.412949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whale adventures  northern lights</td>\n",
       "      <td>Seasonal Weekly Baseline</td>\n",
       "      <td>0.996122</td>\n",
       "      <td>2.378914</td>\n",
       "      <td>56.369556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>poppy towers</td>\n",
       "      <td>Moving Average Baseline</td>\n",
       "      <td>1.162429</td>\n",
       "      <td>2.158024</td>\n",
       "      <td>6.936781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>old mac donalds tractor fun</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>1.483490</td>\n",
       "      <td>3.020140</td>\n",
       "      <td>8.683799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>castello dei medici</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>1.551188</td>\n",
       "      <td>2.828388</td>\n",
       "      <td>1.034564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vindjammer</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>1.695793</td>\n",
       "      <td>3.427279</td>\n",
       "      <td>6.069146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>atlantis adventure</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>1.794465</td>\n",
       "      <td>3.304260</td>\n",
       "      <td>10.750283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jim button  journey through morrowland</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>1.879691</td>\n",
       "      <td>3.450883</td>\n",
       "      <td>8.924530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tirol log flume</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>1.935640</td>\n",
       "      <td>5.463286</td>\n",
       "      <td>4.295027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dancing dingie</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>2.455020</td>\n",
       "      <td>4.408388</td>\n",
       "      <td>8.503253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>alpine express enzian</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>2.660019</td>\n",
       "      <td>6.382971</td>\n",
       "      <td>7.275423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>eurotower</td>\n",
       "      <td>LastYear Baseline</td>\n",
       "      <td>3.101113</td>\n",
       "      <td>5.781876</td>\n",
       "      <td>14.174970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>josefinas magical imperial journey</td>\n",
       "      <td>Holiday-Aware Baseline</td>\n",
       "      <td>3.440890</td>\n",
       "      <td>4.765308</td>\n",
       "      <td>40.945473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>baaa express</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>3.710682</td>\n",
       "      <td>6.359577</td>\n",
       "      <td>14.495640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>volo da vinci</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>5.189675</td>\n",
       "      <td>7.393998</td>\n",
       "      <td>19.155885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pegasus</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>5.308803</td>\n",
       "      <td>8.202069</td>\n",
       "      <td>22.928094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>swiss bob run</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>7.105277</td>\n",
       "      <td>10.804232</td>\n",
       "      <td>15.931000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>matterhornblitz</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>7.421017</td>\n",
       "      <td>11.535588</td>\n",
       "      <td>15.522619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>atlantica supersplash</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>7.468462</td>\n",
       "      <td>12.017917</td>\n",
       "      <td>21.727551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>eurosat  cancan coaster</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>7.686511</td>\n",
       "      <td>11.210157</td>\n",
       "      <td>15.326384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>euromir</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>8.174602</td>\n",
       "      <td>12.775466</td>\n",
       "      <td>20.386492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>silver star</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>8.454386</td>\n",
       "      <td>12.310763</td>\n",
       "      <td>19.532994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fjordrafting</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>8.521588</td>\n",
       "      <td>13.555908</td>\n",
       "      <td>23.927618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>arthur</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>8.528912</td>\n",
       "      <td>13.013774</td>\n",
       "      <td>15.451195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>poseidon</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>9.930897</td>\n",
       "      <td>15.616555</td>\n",
       "      <td>24.605274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>voletarium</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>10.107170</td>\n",
       "      <td>14.675015</td>\n",
       "      <td>24.820470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>blue fire megacoaster</td>\n",
       "      <td>LastWeek Baseline</td>\n",
       "      <td>11.022413</td>\n",
       "      <td>16.485329</td>\n",
       "      <td>19.074729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ride_name                model_name  \\\n",
       "0            madame freudenreich curiosits         LastYear Baseline   \n",
       "1                            kolumbusjolle   Moving Average Baseline   \n",
       "2         arena of football  be part of it         LastWeek Baseline   \n",
       "3             vienna wave swing  glckspilz   Moving Average Baseline   \n",
       "4        whale adventures  northern lights  Seasonal Weekly Baseline   \n",
       "5                             poppy towers   Moving Average Baseline   \n",
       "6              old mac donalds tractor fun         LastWeek Baseline   \n",
       "7                      castello dei medici         LastWeek Baseline   \n",
       "8                               vindjammer         LastWeek Baseline   \n",
       "9                       atlantis adventure         LastWeek Baseline   \n",
       "10  jim button  journey through morrowland         LastWeek Baseline   \n",
       "11                         tirol log flume         LastWeek Baseline   \n",
       "12                          dancing dingie         LastWeek Baseline   \n",
       "13                   alpine express enzian         LastWeek Baseline   \n",
       "14                               eurotower         LastYear Baseline   \n",
       "15      josefinas magical imperial journey    Holiday-Aware Baseline   \n",
       "16                            baaa express         LastWeek Baseline   \n",
       "17                           volo da vinci         LastWeek Baseline   \n",
       "18                                 pegasus         LastWeek Baseline   \n",
       "19                           swiss bob run         LastWeek Baseline   \n",
       "20                         matterhornblitz         LastWeek Baseline   \n",
       "21                   atlantica supersplash         LastWeek Baseline   \n",
       "22                 eurosat  cancan coaster         LastWeek Baseline   \n",
       "23                                 euromir         LastWeek Baseline   \n",
       "24                             silver star         LastWeek Baseline   \n",
       "25                            fjordrafting         LastWeek Baseline   \n",
       "26                                  arthur         LastWeek Baseline   \n",
       "27                                poseidon         LastWeek Baseline   \n",
       "28                              voletarium         LastWeek Baseline   \n",
       "29                   blue fire megacoaster         LastWeek Baseline   \n",
       "\n",
       "          mae       rmse      smape  \n",
       "0    0.072604   0.602512   0.000000  \n",
       "1    0.702860   1.489051   3.714653  \n",
       "2    0.714049   1.987732   2.332204  \n",
       "3    0.911647   1.959635   4.412949  \n",
       "4    0.996122   2.378914  56.369556  \n",
       "5    1.162429   2.158024   6.936781  \n",
       "6    1.483490   3.020140   8.683799  \n",
       "7    1.551188   2.828388   1.034564  \n",
       "8    1.695793   3.427279   6.069146  \n",
       "9    1.794465   3.304260  10.750283  \n",
       "10   1.879691   3.450883   8.924530  \n",
       "11   1.935640   5.463286   4.295027  \n",
       "12   2.455020   4.408388   8.503253  \n",
       "13   2.660019   6.382971   7.275423  \n",
       "14   3.101113   5.781876  14.174970  \n",
       "15   3.440890   4.765308  40.945473  \n",
       "16   3.710682   6.359577  14.495640  \n",
       "17   5.189675   7.393998  19.155885  \n",
       "18   5.308803   8.202069  22.928094  \n",
       "19   7.105277  10.804232  15.931000  \n",
       "20   7.421017  11.535588  15.522619  \n",
       "21   7.468462  12.017917  21.727551  \n",
       "22   7.686511  11.210157  15.326384  \n",
       "23   8.174602  12.775466  20.386492  \n",
       "24   8.454386  12.310763  19.532994  \n",
       "25   8.521588  13.555908  23.927618  \n",
       "26   8.528912  13.013774  15.451195  \n",
       "27   9.930897  15.616555  24.605274  \n",
       "28  10.107170  14.675015  24.820470  \n",
       "29  11.022413  16.485329  19.074729  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"best_per_ride\"]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "dspro2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
