{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3df1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from datetime import date\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== DATA LOADING AND PREPROCESSING ==============\n",
    "\n",
    "def load_and_preprocess_data(file_path, ride_name):\n",
    "    \"\"\"Load and preprocess ride data.\"\"\"\n",
    "    # Load data\n",
    "    full_data = pd.read_parquet(file_path)\n",
    "    ride_data = full_data[full_data[\"ride_name\"] == ride_name].copy()\n",
    "    \n",
    "    # Convert closed column to int\n",
    "    if \"closed\" in ride_data.columns:\n",
    "        ride_data[\"closed\"] = ride_data[\"closed\"].astype(int)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    ride_data = ride_data.drop_duplicates(subset=['timestamp'])\n",
    "    \n",
    "    # Remove NaN wait times\n",
    "    ride_data = ride_data.dropna(subset=['wait_time'])\n",
    "    \n",
    "    # Resample to 30min intervals\n",
    "    ride_data = ride_data.set_index(\"timestamp\").resample(\"30min\").ffill().reset_index()\n",
    "    \n",
    "    # Filter to months after March\n",
    "    ride_data = ride_data[ride_data[\"timestamp\"].dt.month > 3]\n",
    "    \n",
    "    # Add date column\n",
    "    ride_data['date'] = ride_data['timestamp'].dt.date\n",
    "    \n",
    "    return ride_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_operating_data(ride_data):\n",
    "    \"\"\"Remove closed days and filter to operating hours.\"\"\"\n",
    "    # Remove fully closed days\n",
    "    daily_closure = ride_data.groupby('date')[\"closed\"].mean()\n",
    "    fully_closed_days = daily_closure[daily_closure == 1].index\n",
    "    ride_data = ride_data[~ride_data['date'].isin(fully_closed_days)]\n",
    "    \n",
    "    # Remove zero wait days\n",
    "    daily_wait = ride_data.groupby('date')[\"wait_time\"].mean()\n",
    "    zero_wait_days = daily_wait[daily_wait < 1].index\n",
    "    ride_data = ride_data[~ride_data['date'].isin(zero_wait_days)]\n",
    "    \n",
    "    # Filter to operating hours (when wait_time > 0)\n",
    "    ride_data = ride_data[ride_data['wait_time'] > 0]\n",
    "    \n",
    "    return ride_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== FEATURE ENGINEERING ==============\n",
    "\n",
    "def create_time_features(df):\n",
    "    \"\"\"Create time-based features.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Basic time features\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day_of_month'] = df['timestamp'].dt.day\n",
    "    df['week_of_year'] = df['timestamp'].dt.isocalendar().week\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Cyclical encoding\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    \n",
    "    # Time of day bins\n",
    "    df['time_of_day'] = pd.cut(df['hour'], \n",
    "                               bins=[0, 12, 17, 24], \n",
    "                               labels=['morning', 'afternoon', 'evening'])\n",
    "    \n",
    "    # Hour bins (more granular)\n",
    "    df['hour_bin'] = pd.cut(df['hour'], \n",
    "                            bins=[0, 9, 12, 15, 18, 24], \n",
    "                            labels=['early_morning', 'late_morning', 'early_afternoon', \n",
    "                                   'late_afternoon', 'evening'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862dacf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_features(df):\n",
    "    \"\"\"Create weather features if available.\"\"\"\n",
    "    if 'temperature' in df.columns:\n",
    "        df['temp_squared'] = df['temperature'] ** 2\n",
    "        df['temp_comfortable'] = ((df['temperature'] >= 15) & (df['temperature'] <= 25)).astype(int)\n",
    "        # Temperature deviation from ideal (22°C)\n",
    "        df['temp_deviation'] = np.abs(df['temperature'] - 22)\n",
    "    \n",
    "    if 'rain' in df.columns:\n",
    "        df['has_rain'] = (df['rain'] > 0).astype(int)\n",
    "        df['rain_intensity'] = pd.cut(df['rain'], \n",
    "                                      bins=[-0.1, 0, 1, 5, 100], \n",
    "                                      labels=['none', 'light', 'moderate', 'heavy'])\n",
    "    \n",
    "    if 'wind' in df.columns:\n",
    "        df['wind_squared'] = df['wind'] ** 2\n",
    "        df['high_wind'] = (df['wind'] > 15).astype(int)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890fe0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== ATTENDANCE MODEL ENSEMBLE ==============\n",
    "\n",
    "def calculate_daily_attendance(train_data):\n",
    "    \"\"\"Calculate daily attendance metrics from training data only.\"\"\"\n",
    "    daily_metrics = train_data.groupby('date').agg({\n",
    "        'wait_time': ['mean', 'max', 'std', 'median'],\n",
    "        'timestamp': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    daily_metrics.columns = ['date', 'daily_avg_wait', 'daily_max_wait', \n",
    "                           'daily_std_wait', 'daily_median_wait', 'hourly_samples']\n",
    "    \n",
    "    # Create multiple attendance scores\n",
    "    daily_metrics['attendance_score_avg'] = daily_metrics['daily_avg_wait'].rank(pct=True) * 100\n",
    "    daily_metrics['attendance_score_max'] = daily_metrics['daily_max_wait'].rank(pct=True) * 100\n",
    "    daily_metrics['attendance_score_median'] = daily_metrics['daily_median_wait'].rank(pct=True) * 100\n",
    "    \n",
    "    # Combined attendance score\n",
    "    daily_metrics['attendance_score'] = (\n",
    "        daily_metrics['attendance_score_avg'] * 0.5 +\n",
    "        daily_metrics['attendance_score_max'] * 0.3 +\n",
    "        daily_metrics['attendance_score_median'] * 0.2\n",
    "    )\n",
    "    \n",
    "    return daily_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attendance_ensemble(train_data):\n",
    "    \"\"\"Train ensemble model to predict daily attendance.\"\"\"\n",
    "    # Calculate daily attendance for training data\n",
    "    daily_attendance = calculate_daily_attendance(train_data)\n",
    "    \n",
    "    # Add calendar features\n",
    "    daily_attendance['day_of_week'] = pd.to_datetime(daily_attendance['date']).dt.dayofweek\n",
    "    daily_attendance['month'] = pd.to_datetime(daily_attendance['date']).dt.month\n",
    "    daily_attendance['day_of_month'] = pd.to_datetime(daily_attendance['date']).dt.day\n",
    "    daily_attendance['is_weekend'] = (daily_attendance['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Add cyclical features\n",
    "    daily_attendance['dow_sin'] = np.sin(2 * np.pi * daily_attendance['day_of_week'] / 7)\n",
    "    daily_attendance['dow_cos'] = np.cos(2 * np.pi * daily_attendance['day_of_week'] / 7)\n",
    "    daily_attendance['month_sin'] = np.sin(2 * np.pi * daily_attendance['month'] / 12)\n",
    "    daily_attendance['month_cos'] = np.cos(2 * np.pi * daily_attendance['month'] / 12)\n",
    "    \n",
    "    # Features and target\n",
    "    features = ['day_of_week', 'month', 'day_of_month', 'is_weekend',\n",
    "               'dow_sin', 'dow_cos', 'month_sin', 'month_cos']\n",
    "    target = 'attendance_score'\n",
    "    \n",
    "    X = daily_attendance[features]\n",
    "    y = daily_attendance[target]\n",
    "    \n",
    "    # Create ensemble of models\n",
    "    models = [\n",
    "        ('ridge', Ridge(alpha=1.0)),\n",
    "        ('rf', RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)),\n",
    "        ('gb', GradientBoostingRegressor(n_estimators=50, max_depth=3, random_state=42))\n",
    "    ]\n",
    "    \n",
    "    ensemble = VotingRegressor(estimators=models)\n",
    "    ensemble.fit(X, y)\n",
    "    \n",
    "    return ensemble, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b94f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_daily_attendance(dates, attendance_model, features):\n",
    "    \"\"\"Predict attendance for given dates.\"\"\"\n",
    "    # Create feature dataframe\n",
    "    date_df = pd.DataFrame({'date': dates})\n",
    "    date_df['day_of_week'] = pd.to_datetime(date_df['date']).dt.dayofweek\n",
    "    date_df['month'] = pd.to_datetime(date_df['date']).dt.month\n",
    "    date_df['day_of_month'] = pd.to_datetime(date_df['date']).dt.day\n",
    "    date_df['is_weekend'] = (date_df['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Add cyclical features\n",
    "    date_df['dow_sin'] = np.sin(2 * np.pi * date_df['day_of_week'] / 7)\n",
    "    date_df['dow_cos'] = np.cos(2 * np.pi * date_df['day_of_week'] / 7)\n",
    "    date_df['month_sin'] = np.sin(2 * np.pi * date_df['month'] / 12)\n",
    "    date_df['month_cos'] = np.cos(2 * np.pi * date_df['month'] / 12)\n",
    "    \n",
    "    # Predict\n",
    "    date_df['attendance_score'] = attendance_model.predict(date_df[features])\n",
    "    \n",
    "    # Clip to valid range\n",
    "    date_df['attendance_score'] = date_df['attendance_score'].clip(0, 100)\n",
    "    \n",
    "    return date_df[['date', 'attendance_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== VISUALIZATION FUNCTIONS ==============\n",
    "\n",
    "def visualize_results(y_test, y_pred, test_data, title_suffix=\"\"):\n",
    "    \"\"\"Visualize the prediction results with comprehensive analysis.\"\"\"\n",
    "    # Ensure predictions are non-negative\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results_df = pd.DataFrame({\n",
    "        'Actual': y_test,\n",
    "        'Predicted': y_pred,\n",
    "        'Error': y_pred - y_test,\n",
    "        'Timestamp': test_data['timestamp'].values\n",
    "    })\n",
    "\n",
    "    # Main scatter plot and time series\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "    # Scatter plot\n",
    "    axes[0].scatter(results_df['Actual'], results_df['Predicted'], alpha=0.5)\n",
    "    max_val = max(results_df['Actual'].max(), results_df['Predicted'].max())\n",
    "    axes[0].plot([0, max_val], [0, max_val], 'r--')\n",
    "    axes[0].set_xlabel('Actual Wait Time (minutes)')\n",
    "    axes[0].set_ylabel('Predicted Wait Time (minutes)')\n",
    "    axes[0].set_title(f'Actual vs Predicted Wait Times - {title_suffix}')\n",
    "    axes[0].grid(True, linestyle=':')\n",
    "\n",
    "    # Add metrics\n",
    "    mae = mean_absolute_error(results_df['Actual'], results_df['Predicted'])\n",
    "    rmse = np.sqrt(mean_squared_error(results_df['Actual'], results_df['Predicted']))\n",
    "    r2 = r2_score(results_df['Actual'], results_df['Predicted'])\n",
    "    \n",
    "    metrics_text = f\"MAE: {mae:.2f}\\nRMSE: {rmse:.2f}\\nR²: {r2:.4f}\"\n",
    "    axes[0].text(0.05, 0.95, metrics_text, transform=axes[0].transAxes, \n",
    "                 verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "\n",
    "    # Time series plot\n",
    "    results_df = results_df.sort_values('Timestamp')\n",
    "    axes[1].plot(results_df['Timestamp'], results_df['Actual'], label='Actual', alpha=0.7)\n",
    "    axes[1].plot(results_df['Timestamp'], results_df['Predicted'], label='Predicted', alpha=0.7)\n",
    "    axes[1].set_xlabel('Date')\n",
    "    axes[1].set_ylabel('Wait Time (minutes)')\n",
    "    axes[1].set_title(f'Actual vs Predicted Wait Times Over Time - {title_suffix}')\n",
    "    axes[1].grid(True, linestyle=':')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Error analysis by wait time range\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create wait time bins\n",
    "    bins = [0, 10, 20, 30, 40, 50, 60, np.inf]\n",
    "    labels = ['0-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60+']\n",
    "    \n",
    "    results_df['wait_bin'] = pd.cut(results_df['Actual'], bins=bins, labels=labels)\n",
    "    \n",
    "    # Calculate metrics for each bin\n",
    "    bin_metrics = results_df.groupby('wait_bin').agg({\n",
    "        'Error': ['mean', 'std'],\n",
    "        'Actual': 'count'\n",
    "    })\n",
    "    \n",
    "    bin_metrics.columns = ['Mean Error', 'Std Error', 'Count']\n",
    "    bin_metrics['Abs Mean Error'] = results_df.groupby('wait_bin')['Error'].apply(lambda x: np.abs(x).mean())\n",
    "    \n",
    "    # Plot mean absolute error by wait time range\n",
    "    plt.bar(bin_metrics.index, bin_metrics['Abs Mean Error'], alpha=0.7)\n",
    "    plt.xlabel('Actual Wait Time Range (minutes)')\n",
    "    plt.ylabel('Mean Absolute Error (minutes)')\n",
    "    plt.title(f'Error by Wait Time Range - {title_suffix}')\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, count in enumerate(bin_metrics['Count']):\n",
    "        plt.text(i, bin_metrics['Abs Mean Error'].iloc[i] + 0.5, f\"n={count}\", \n",
    "                 ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Hour of day analysis\n",
    "    if 'hour' not in test_data.columns:\n",
    "        test_data['hour'] = test_data['timestamp'].dt.hour\n",
    "    \n",
    "    results_df['hour'] = test_data['hour'].values\n",
    "    hourly_abs_errors = results_df.groupby('hour').apply(lambda x: np.abs(x['Error']).mean())\n",
    "\n",
    "    # Plot hourly MAE\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    hourly_abs_errors.plot(kind='bar')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Mean Absolute Error (minutes)')\n",
    "    plt.title(f'Mean Absolute Error by Hour of Day - {title_suffix}')\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Day of week analysis\n",
    "    if 'day_of_week' not in test_data.columns:\n",
    "        test_data['day_of_week'] = test_data['timestamp'].dt.dayofweek\n",
    "    \n",
    "    results_df['day'] = test_data['day_of_week'].values\n",
    "    daily_abs_errors = results_df.groupby('day').apply(lambda x: np.abs(x['Error']).mean())\n",
    "\n",
    "    # Plot daily MAE\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    daily_abs_errors.plot(kind='bar')\n",
    "    plt.xlabel('Day of Week')\n",
    "    plt.ylabel('Mean Absolute Error (minutes)')\n",
    "    plt.title(f'Mean Absolute Error by Day of Week - {title_suffix}')\n",
    "    plt.xticks(range(len(days)), days)\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4911fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_future_predictions(predictions_df, ride_name):\n",
    "    \"\"\"Create heatmap visualization for future predictions.\"\"\"\n",
    "    # Create pivot table for heatmap\n",
    "    pivot_table = predictions_df.pivot_table(\n",
    "        index='date',\n",
    "        columns='hour',\n",
    "        values='predicted_wait'\n",
    "    )\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(\n",
    "        pivot_table, \n",
    "        annot=True, \n",
    "        fmt='.1f', \n",
    "        cmap='YlOrRd',\n",
    "        linewidths=.5\n",
    "    )\n",
    "    plt.title(f'Predicted Wait Times for {ride_name.title()}')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Date')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a2f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== WAIT TIME MODEL ENSEMBLE ==============\n",
    "\n",
    "def prepare_model_features(df, attendance_predictions=None):\n",
    "    \"\"\"Prepare features for wait time model.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Merge attendance predictions if provided\n",
    "    if attendance_predictions is not None:\n",
    "        df = df.merge(attendance_predictions, on='date', how='left')\n",
    "        # Fill missing attendance with median\n",
    "        df['attendance_score'] = df['attendance_score'].fillna(50)\n",
    "    \n",
    "    # Define features\n",
    "    categorical_features = ['time_of_day', 'hour_bin']\n",
    "    numerical_features = [\n",
    "        'hour', 'is_weekend', 'hour_sin', 'hour_cos', \n",
    "        'month_sin', 'month_cos', 'dow_sin', 'dow_cos',\n",
    "        'day_of_month', 'week_of_year'\n",
    "    ]\n",
    "    \n",
    "    # Add attendance if available\n",
    "    if 'attendance_score' in df.columns:\n",
    "        numerical_features.append('attendance_score')\n",
    "        # Create interaction features\n",
    "        df['attendance_hour'] = df['attendance_score'] * df['hour'] / 100\n",
    "        df['attendance_weekend'] = df['attendance_score'] * df['is_weekend']\n",
    "        numerical_features.extend(['attendance_hour', 'attendance_weekend'])\n",
    "    \n",
    "    # Add weather features if available\n",
    "    if 'temperature' in df.columns:\n",
    "        numerical_features.extend(['temperature', 'temp_squared', 'temp_comfortable', 'temp_deviation'])\n",
    "    if 'has_rain' in df.columns:\n",
    "        numerical_features.append('has_rain')\n",
    "        categorical_features.append('rain_intensity')\n",
    "    if 'wind' in df.columns:\n",
    "        numerical_features.extend(['wind', 'wind_squared', 'high_wind'])\n",
    "    \n",
    "    # Handle missing values\n",
    "    for col in numerical_features:\n",
    "        if col in df.columns and df[col].isna().any():\n",
    "            print(f\"   Filling {df[col].isna().sum()} NaN values in '{col}'\")\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        if col in df.columns and df[col].isna().any():\n",
    "            print(f\"   Filling {df[col].isna().sum()} NaN values in '{col}'\")\n",
    "            df[col] = df[col].fillna(df[col].mode()[0] if len(df[col].mode()) > 0 else 'unknown')\n",
    "    \n",
    "    return df, categorical_features, numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e5241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ensemble_models(categorical_features, numerical_features):\n",
    "    \"\"\"Build ensemble of models for wait time prediction.\"\"\"\n",
    "    # Common preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features),\n",
    "            ('num', StandardScaler(), numerical_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Individual models\n",
    "    models = []\n",
    "    \n",
    "    # Linear models\n",
    "    ridge_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', Ridge(alpha=1.0))\n",
    "    ])\n",
    "    models.append(('ridge', ridge_pipeline))\n",
    "    \n",
    "    elastic_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42))\n",
    "    ])\n",
    "    models.append(('elastic', elastic_pipeline))\n",
    "    \n",
    "    # Tree-based models\n",
    "    rf_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators=100, \n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    models.append(('rf', rf_pipeline))\n",
    "    \n",
    "    gb_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', GradientBoostingRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    models.append(('gb', gb_pipeline))\n",
    "    \n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064b2790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== MAIN PIPELINE ==============\n",
    "\n",
    "def train_ensemble_with_attendance(file_path, ride_name, test_year=2023):\n",
    "    \"\"\"Main pipeline for ensemble model with attendance prediction.\"\"\"\n",
    "    print(f\"=== Training Ensemble Model with Attendance for {ride_name} ===\")\n",
    "    \n",
    "    # Step 1: Load and preprocess data\n",
    "    print(\"\\n1. Loading and preprocessing data...\")\n",
    "    ride_data = load_and_preprocess_data(file_path, ride_name)\n",
    "    ride_data = filter_operating_data(ride_data)\n",
    "    print(f\"   Total data shape: {ride_data.shape}\")\n",
    "    \n",
    "    # Step 2: Create features\n",
    "    print(\"\\n2. Creating features...\")\n",
    "    ride_data = create_time_features(ride_data)\n",
    "    ride_data = create_weather_features(ride_data)\n",
    "    \n",
    "    # Step 3: Train/test split (BEFORE any model training)\n",
    "    print(f\"\\n3. Splitting data (test year: {test_year})...\")\n",
    "    train_mask = ride_data['timestamp'].dt.year < test_year\n",
    "    test_mask = ride_data['timestamp'].dt.year == test_year\n",
    "    \n",
    "    train_data = ride_data[train_mask].copy()\n",
    "    test_data = ride_data[test_mask].copy()\n",
    "    print(f\"   Train data: {len(train_data)} samples\")\n",
    "    print(f\"   Test data: {len(test_data)} samples\")\n",
    "    \n",
    "    # Step 4: Train attendance ensemble (on training data only)\n",
    "    print(\"\\n4. Training attendance ensemble...\")\n",
    "    attendance_model, attendance_features = train_attendance_ensemble(train_data)\n",
    "    \n",
    "    # Step 5: Predict attendance for train and test sets\n",
    "    print(\"\\n5. Predicting attendance...\")\n",
    "    train_dates = train_data['date'].unique()\n",
    "    test_dates = test_data['date'].unique()\n",
    "    \n",
    "    train_attendance = predict_daily_attendance(train_dates, attendance_model, attendance_features)\n",
    "    test_attendance = predict_daily_attendance(test_dates, attendance_model, attendance_features)\n",
    "    \n",
    "    # Step 6: Prepare features for wait time model\n",
    "    print(\"\\n6. Preparing features for wait time model...\")\n",
    "    train_data, cat_features, num_features = prepare_model_features(train_data, train_attendance)\n",
    "    test_data, _, _ = prepare_model_features(test_data, test_attendance)\n",
    "    \n",
    "    # Step 7: Train individual models\n",
    "    print(\"\\n7. Training individual models...\")\n",
    "    models = build_ensemble_models(cat_features, num_features)\n",
    "    \n",
    "    X_train = train_data[cat_features + num_features]\n",
    "    y_train = train_data['wait_time']\n",
    "    X_test = test_data[cat_features + num_features]\n",
    "    y_test = test_data['wait_time']\n",
    "    \n",
    "    # Train and evaluate individual models\n",
    "    individual_predictions = {}\n",
    "    individual_metrics = {}\n",
    "    \n",
    "    for name, model in models:\n",
    "        print(f\"   Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = np.maximum(y_pred, 0)  # Ensure non-negative\n",
    "        \n",
    "        individual_predictions[name] = y_pred\n",
    "        \n",
    "        # Metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        individual_metrics[name] = {'mae': mae, 'rmse': rmse, 'r2': r2}\n",
    "        print(f\"      MAE: {mae:.2f}, RMSE: {rmse:.2f}, R²: {r2:.4f}\")\n",
    "    \n",
    "    # Step 8: Create ensemble predictions\n",
    "    print(\"\\n8. Creating ensemble predictions...\")\n",
    "    \n",
    "    # Simple average ensemble\n",
    "    ensemble_pred = np.mean(list(individual_predictions.values()), axis=0)\n",
    "    \n",
    "    # Weighted ensemble (based on individual R² scores)\n",
    "    weights = np.array([individual_metrics[name]['r2'] for name in individual_predictions.keys()])\n",
    "    weights = weights / weights.sum()  # Normalize\n",
    "    \n",
    "    weighted_ensemble_pred = np.average(\n",
    "        list(individual_predictions.values()), \n",
    "        axis=0, \n",
    "        weights=weights\n",
    "    )\n",
    "    \n",
    "    # Evaluate ensemble\n",
    "    ensemble_mae = mean_absolute_error(y_test, ensemble_pred)\n",
    "    ensemble_rmse = np.sqrt(mean_squared_error(y_test, ensemble_pred))\n",
    "    ensemble_r2 = r2_score(y_test, ensemble_pred)\n",
    "    \n",
    "    weighted_mae = mean_absolute_error(y_test, weighted_ensemble_pred)\n",
    "    weighted_rmse = np.sqrt(mean_squared_error(y_test, weighted_ensemble_pred))\n",
    "    weighted_r2 = r2_score(y_test, weighted_ensemble_pred)\n",
    "    \n",
    "    print(f\"\\nEnsemble Results:\")\n",
    "    print(f\"   Simple Average - MAE: {ensemble_mae:.2f}, RMSE: {ensemble_rmse:.2f}, R²: {ensemble_r2:.4f}\")\n",
    "    print(f\"   Weighted Average - MAE: {weighted_mae:.2f}, RMSE: {weighted_rmse:.2f}, R²: {weighted_r2:.4f}\")\n",
    "    \n",
    "    # Use the better ensemble\n",
    "    if weighted_mae < ensemble_mae:\n",
    "        final_pred = weighted_ensemble_pred\n",
    "        final_type = \"Weighted\"\n",
    "    else:\n",
    "        final_pred = ensemble_pred\n",
    "        final_type = \"Simple\"\n",
    "    \n",
    "    # Evaluate by wait time range\n",
    "    print(f\"\\nMAE by Wait Time Range ({final_type} Ensemble):\")\n",
    "    for min_wait, max_wait in [(0, 10), (10, 30), (30, 60), (60, np.inf)]:\n",
    "        mask = (y_test >= min_wait) & (y_test < max_wait)\n",
    "        if mask.sum() > 0:\n",
    "            range_mae = mean_absolute_error(y_test[mask], final_pred[mask])\n",
    "            print(f\"   {min_wait}-{max_wait if max_wait != np.inf else '∞'} min: {range_mae:.2f} (n={mask.sum()})\")\n",
    "    \n",
    "    # Plot results\n",
    "    print(\"\\n9. Visualizing results...\")\n",
    "    \n",
    "    # Visualize final ensemble predictions\n",
    "    visualize_results(y_test, final_pred, test_data, \n",
    "                     title_suffix=f\"{final_type} Ensemble - {ride_name}\")\n",
    "    \n",
    "    # Additional plots for model comparison\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Individual model comparison\n",
    "    plt.subplot(1, 3, 1)\n",
    "    model_names = list(individual_metrics.keys()) + [f'{final_type} Ensemble']\n",
    "    mae_values = [individual_metrics[name]['mae'] for name in individual_metrics.keys()] + [mae]\n",
    "    bars = plt.bar(model_names, mae_values)\n",
    "    # Color the best model differently\n",
    "    best_idx = mae_values.index(min(mae_values))\n",
    "    bars[best_idx].set_color('green')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('Model Comparison - MAE')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # R² comparison\n",
    "    plt.subplot(1, 3, 2)\n",
    "    r2_values = [individual_metrics[name]['r2'] for name in individual_metrics.keys()] + [r2]\n",
    "    bars = plt.bar(model_names, r2_values)\n",
    "    best_idx = r2_values.index(max(r2_values))\n",
    "    bars[best_idx].set_color('green')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('R²')\n",
    "    plt.title('Model Comparison - R²')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Feature importance from Random Forest\n",
    "    plt.subplot(1, 3, 3)\n",
    "    rf_model = models[2][1]  # Random Forest is the 3rd model\n",
    "    preprocessor = rf_model.named_steps['preprocessor']\n",
    "    regressor = rf_model.named_steps['regressor']\n",
    "    \n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = []\n",
    "    for name, transformer, features in preprocessor.transformers_:\n",
    "        if name == 'cat':\n",
    "            # Get one-hot encoded names\n",
    "            encoded_names = preprocessor.named_transformers_['cat'].get_feature_names_out(features)\n",
    "            feature_names.extend(encoded_names)\n",
    "        else:\n",
    "            feature_names.extend(features)\n",
    "    \n",
    "    # Get importances\n",
    "    importances = regressor.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1][:10]  # Top 10\n",
    "    \n",
    "    plt.barh(range(10), importances[indices])\n",
    "    plt.yticks(range(10), [feature_names[i] for i in indices])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 10 Feature Importances (RF)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'models': dict(models),\n",
    "        'attendance_model': attendance_model,\n",
    "        'attendance_features': attendance_features,\n",
    "        'cat_features': cat_features,\n",
    "        'num_features': num_features,\n",
    "        'ensemble_weights': weights if final_type == \"Weighted\" else None,\n",
    "        'metrics': {\n",
    "            'individual': individual_metrics,\n",
    "            'ensemble': {\n",
    "                'mae': mae, \n",
    "                'rmse': rmse, \n",
    "                'r2': r2,\n",
    "                'type': final_type\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37b857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== PREDICTION FUNCTION ==============\n",
    "\n",
    "def predict_future_wait_times(models_dict, future_dates, future_hours):\n",
    "    \"\"\"Predict wait times for future dates and hours.\"\"\"\n",
    "    # Predict attendance for future dates\n",
    "    attendance_predictions = predict_daily_attendance(\n",
    "        future_dates, \n",
    "        models_dict['attendance_model'], \n",
    "        models_dict['attendance_features']\n",
    "    )\n",
    "    \n",
    "    # Create future data\n",
    "    future_data = []\n",
    "    for date in future_dates:\n",
    "        for hour in future_hours:\n",
    "            future_data.append({\n",
    "                'timestamp': pd.Timestamp.combine(date, pd.Timestamp(f\"{hour}:00:00\").time()),\n",
    "                'date': date,\n",
    "                'hour': hour\n",
    "            })\n",
    "    \n",
    "    future_df = pd.DataFrame(future_data)\n",
    "    \n",
    "    # Add features\n",
    "    future_df = create_time_features(future_df)\n",
    "    \n",
    "    # Add default weather (can be modified if forecast available)\n",
    "    future_df['temperature'] = 20\n",
    "    future_df['rain'] = 0\n",
    "    future_df['wind'] = 5\n",
    "    \n",
    "    future_df = create_weather_features(future_df)\n",
    "    future_df, _, _ = prepare_model_features(future_df, attendance_predictions)\n",
    "    \n",
    "    # Predict with each model\n",
    "    X_future = future_df[models_dict['cat_features'] + models_dict['num_features']]\n",
    "    predictions = {}\n",
    "    \n",
    "    for name, model in models_dict['models'].items():\n",
    "        pred = model.predict(X_future)\n",
    "        predictions[name] = np.maximum(pred, 0)\n",
    "    \n",
    "    # Ensemble prediction\n",
    "    if models_dict['ensemble_weights'] is not None:\n",
    "        ensemble_pred = np.average(list(predictions.values()), axis=0, weights=models_dict['ensemble_weights'])\n",
    "    else:\n",
    "        ensemble_pred = np.mean(list(predictions.values()), axis=0)\n",
    "    \n",
    "    future_df['predicted_wait'] = ensemble_pred\n",
    "    \n",
    "    return future_df[['timestamp', 'date', 'hour', 'predicted_wait']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== EXAMPLE USAGE ==============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    data_path = \"../data/processed/ep/merged_with_holidays.parquet\"\n",
    "    ride_name = \"silver star\"\n",
    "    test_year = 2023\n",
    "    \n",
    "    # Train model\n",
    "    results = train_ensemble_with_attendance(data_path, ride_name, test_year)\n",
    "    \n",
    "    print(\"\\nEnsemble model training completed!\")\n",
    "    \n",
    "    # Demo: Predict future wait times\n",
    "    print(\"\\n=== PREDICTING FUTURE WAIT TIMES ===\")\n",
    "    \n",
    "    # Define future dates (7 days)\n",
    "    future_dates = [date(2025, 5, 15 + i) for i in range(7)]\n",
    "    future_hours = list(range(10, 20))  # 10am to 7pm\n",
    "    \n",
    "    print(\"Future dates for prediction:\")\n",
    "    for d in future_dates:\n",
    "        print(f\"  - {d}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    future_predictions = predict_future_wait_times(results, future_dates, future_hours)\n",
    "    \n",
    "    print(f\"\\nGenerated {len(future_predictions)} predictions\")\n",
    "    print(future_predictions.head(10))\n",
    "    \n",
    "    # Visualize future predictions\n",
    "    visualize_future_predictions(future_predictions, ride_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
