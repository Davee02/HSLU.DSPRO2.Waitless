{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edac6fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d298272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== DATA LOADING AND PREPROCESSING ==============\n",
    "\n",
    "def load_and_preprocess_data(file_path, ride_name):\n",
    "    \"\"\"Load and preprocess ride data.\"\"\"\n",
    "    # Load data\n",
    "    full_data = pd.read_parquet(file_path)\n",
    "    ride_data = full_data[full_data[\"ride_name\"] == ride_name].copy()\n",
    "    \n",
    "    # Convert closed column to int\n",
    "    if \"closed\" in ride_data.columns:\n",
    "        ride_data[\"closed\"] = ride_data[\"closed\"].astype(int)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    ride_data = ride_data.drop_duplicates(subset=['timestamp'])\n",
    "    \n",
    "    # Remove NaN wait times\n",
    "    ride_data = ride_data.dropna(subset=['wait_time'])\n",
    "    \n",
    "    # Resample to 30min intervals\n",
    "    ride_data = ride_data.set_index(\"timestamp\").resample(\"30min\").ffill().reset_index()\n",
    "    \n",
    "    # Filter to months after March\n",
    "    ride_data = ride_data[ride_data[\"timestamp\"].dt.month > 3]\n",
    "    \n",
    "    # Add date column\n",
    "    ride_data['date'] = ride_data['timestamp'].dt.date\n",
    "    \n",
    "    return ride_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cfa231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_operating_data(ride_data):\n",
    "    \"\"\"Remove closed days and filter to operating hours.\"\"\"\n",
    "    # Remove fully closed days\n",
    "    daily_closure = ride_data.groupby('date')[\"closed\"].mean()\n",
    "    fully_closed_days = daily_closure[daily_closure == 1].index\n",
    "    ride_data = ride_data[~ride_data['date'].isin(fully_closed_days)]\n",
    "    \n",
    "    # Remove zero wait days\n",
    "    daily_wait = ride_data.groupby('date')[\"wait_time\"].mean()\n",
    "    zero_wait_days = daily_wait[daily_wait < 1].index\n",
    "    ride_data = ride_data[~ride_data['date'].isin(zero_wait_days)]\n",
    "    \n",
    "    # Filter to operating hours (when wait_time > 0)\n",
    "    ride_data = ride_data[ride_data['wait_time'] > 0]\n",
    "    \n",
    "    return ride_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5bd599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== FEATURE ENGINEERING ==============\n",
    "\n",
    "def create_time_features(df):\n",
    "    \"\"\"Create time-based features.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Basic time features\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Cyclical encoding\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    \n",
    "    # Time of day bins\n",
    "    df['time_of_day'] = pd.cut(df['hour'], \n",
    "                               bins=[0, 12, 17, 24], \n",
    "                               labels=['morning', 'afternoon', 'evening'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2b8af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_features(df):\n",
    "    \"\"\"Create weather features if available.\"\"\"\n",
    "    if 'temperature' in df.columns:\n",
    "        df['temp_squared'] = df['temperature'] ** 2\n",
    "        df['temp_comfortable'] = ((df['temperature'] >= 15) & (df['temperature'] <= 25)).astype(int)\n",
    "    \n",
    "    if 'rain' in df.columns:\n",
    "        df['has_rain'] = (df['rain'] > 0).astype(int)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a228f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== ATTENDANCE MODEL ==============\n",
    "\n",
    "def calculate_daily_attendance(train_data):\n",
    "    \"\"\"Calculate daily attendance metrics from training data only.\"\"\"\n",
    "    daily_metrics = train_data.groupby('date').agg({\n",
    "        'wait_time': ['mean', 'max', 'std']\n",
    "    }).reset_index()\n",
    "    \n",
    "    daily_metrics.columns = ['date', 'daily_avg_wait', 'daily_max_wait', 'daily_std_wait']\n",
    "    \n",
    "    # Create attendance score (percentile-based)\n",
    "    daily_metrics['attendance_score'] = daily_metrics['daily_avg_wait'].rank(pct=True) * 100\n",
    "    \n",
    "    return daily_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02928a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_attendance_model(train_data):\n",
    "    \"\"\"Train model to predict daily attendance.\"\"\"\n",
    "    # Calculate daily attendance for training data\n",
    "    daily_attendance = calculate_daily_attendance(train_data)\n",
    "    \n",
    "    # Add calendar features\n",
    "    daily_attendance['day_of_week'] = pd.to_datetime(daily_attendance['date']).dt.dayofweek\n",
    "    daily_attendance['month'] = pd.to_datetime(daily_attendance['date']).dt.month\n",
    "    daily_attendance['is_weekend'] = (daily_attendance['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Features and target\n",
    "    features = ['day_of_week', 'month', 'is_weekend']\n",
    "    target = 'attendance_score'\n",
    "    \n",
    "    X = daily_attendance[features]\n",
    "    y = daily_attendance[target]\n",
    "    \n",
    "    # Simple Ridge regression\n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d15abc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_daily_attendance(dates, attendance_model, features):\n",
    "    \"\"\"Predict attendance for given dates.\"\"\"\n",
    "    # Create feature dataframe\n",
    "    date_df = pd.DataFrame({'date': dates})\n",
    "    date_df['day_of_week'] = pd.to_datetime(date_df['date']).dt.dayofweek\n",
    "    date_df['month'] = pd.to_datetime(date_df['date']).dt.month\n",
    "    date_df['is_weekend'] = (date_df['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Predict\n",
    "    date_df['attendance_score'] = attendance_model.predict(date_df[features])\n",
    "    \n",
    "    # Clip to valid range\n",
    "    date_df['attendance_score'] = date_df['attendance_score'].clip(0, 100)\n",
    "    \n",
    "    return date_df[['date', 'attendance_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9d1599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== WAIT TIME MODEL ENSEMBLE ==============\n",
    "\n",
    "def prepare_model_features(df, attendance_predictions=None):\n",
    "    \"\"\"Prepare features for wait time model.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Merge attendance predictions if provided\n",
    "    if attendance_predictions is not None:\n",
    "        df = df.merge(attendance_predictions, on='date', how='left')\n",
    "        # Fill missing attendance with median\n",
    "        df['attendance_score'] = df['attendance_score'].fillna(50)\n",
    "    \n",
    "    # Define features\n",
    "    categorical_features = ['time_of_day', 'hour_bin']\n",
    "    numerical_features = [\n",
    "        'hour', 'is_weekend', 'hour_sin', 'hour_cos', \n",
    "        'month_sin', 'month_cos', 'dow_sin', 'dow_cos',\n",
    "        'day_of_month', 'week_of_year'\n",
    "    ]\n",
    "    \n",
    "    # Add attendance if available\n",
    "    if 'attendance_score' in df.columns:\n",
    "        numerical_features.append('attendance_score')\n",
    "        # Create interaction features\n",
    "        df['attendance_hour'] = df['attendance_score'] * df['hour'] / 100\n",
    "        df['attendance_weekend'] = df['attendance_score'] * df['is_weekend']\n",
    "        numerical_features.extend(['attendance_hour', 'attendance_weekend'])\n",
    "    \n",
    "    # Add weather features if available\n",
    "    if 'temperature' in df.columns:\n",
    "        numerical_features.extend(['temperature', 'temp_squared', 'temp_comfortable', 'temp_deviation'])\n",
    "    if 'has_rain' in df.columns:\n",
    "        numerical_features.append('has_rain')\n",
    "        categorical_features.append('rain_intensity')\n",
    "    if 'wind' in df.columns:\n",
    "        numerical_features.extend(['wind', 'wind_squared', 'high_wind'])\n",
    "    \n",
    "    # Handle missing values\n",
    "    for col in numerical_features:\n",
    "        if col in df.columns and df[col].isna().any():\n",
    "            print(f\"   Filling {df[col].isna().sum()} NaN values in '{col}'\")\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        if col in df.columns and df[col].isna().any():\n",
    "            print(f\"   Filling {df[col].isna().sum()} NaN values in '{col}'\")\n",
    "            df[col] = df[col].fillna(df[col].mode()[0] if len(df[col].mode()) > 0 else 'unknown')\n",
    "    \n",
    "    return df, categorical_features, numerical_features\n",
    "\n",
    "\n",
    "def build_wait_time_model(categorical_features, numerical_features):\n",
    "    \"\"\"Build pipeline for wait time prediction.\"\"\"\n",
    "    # Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features),\n",
    "            ('num', StandardScaler(), numerical_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Pipeline\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', Ridge(alpha=1.0))\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f13b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== MAIN PIPELINE ==============\n",
    "\n",
    "def train_linear_model_with_attendance(file_path, ride_name, test_year=2023):\n",
    "    \"\"\"Main pipeline for linear model with attendance prediction.\"\"\"\n",
    "    print(f\"=== Training Linear Model with Attendance for {ride_name} ===\")\n",
    "    \n",
    "    # Step 1: Load and preprocess data\n",
    "    print(\"\\n1. Loading and preprocessing data...\")\n",
    "    ride_data = load_and_preprocess_data(file_path, ride_name)\n",
    "    ride_data = filter_operating_data(ride_data)\n",
    "    print(f\"   Total data shape: {ride_data.shape}\")\n",
    "    \n",
    "    # Step 2: Create features\n",
    "    print(\"\\n2. Creating features...\")\n",
    "    ride_data = create_time_features(ride_data)\n",
    "    ride_data = create_weather_features(ride_data)\n",
    "    \n",
    "    # Step 3: Train/test split (BEFORE any model training)\n",
    "    print(f\"\\n3. Splitting data (test year: {test_year})...\")\n",
    "    train_mask = ride_data['timestamp'].dt.year < test_year\n",
    "    test_mask = ride_data['timestamp'].dt.year == test_year\n",
    "    \n",
    "    train_data = ride_data[train_mask].copy()\n",
    "    test_data = ride_data[test_mask].copy()\n",
    "    print(f\"   Train data: {len(train_data)} samples\")\n",
    "    print(f\"   Test data: {len(test_data)} samples\")\n",
    "    \n",
    "    # Step 4: Train attendance model (on training data only)\n",
    "    print(\"\\n4. Training attendance model...\")\n",
    "    attendance_model, attendance_features = train_attendance_model(train_data)\n",
    "    \n",
    "    # Step 5: Predict attendance for train and test sets\n",
    "    print(\"\\n5. Predicting attendance...\")\n",
    "    train_dates = train_data['date'].unique()\n",
    "    test_dates = test_data['date'].unique()\n",
    "    \n",
    "    train_attendance = predict_daily_attendance(train_dates, attendance_model, attendance_features)\n",
    "    test_attendance = predict_daily_attendance(test_dates, attendance_model, attendance_features)\n",
    "    \n",
    "    # Step 6: Prepare features for wait time model\n",
    "    print(\"\\n6. Preparing features for wait time model...\")\n",
    "    train_data, cat_features, num_features = prepare_model_features(train_data, train_attendance)\n",
    "    test_data, _, _ = prepare_model_features(test_data, test_attendance)\n",
    "    \n",
    "    # Step 7: Train wait time model\n",
    "    print(\"\\n7. Training wait time model...\")\n",
    "    wait_model = build_wait_time_model(cat_features, num_features)\n",
    "    \n",
    "    X_train = train_data[cat_features + num_features]\n",
    "    y_train = train_data['wait_time']\n",
    "    \n",
    "    wait_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Step 8: Evaluate on test set\n",
    "    print(\"\\n8. Evaluating model...\")\n",
    "    X_test = test_data[cat_features + num_features]\n",
    "    y_test = test_data['wait_time']\n",
    "    \n",
    "    y_pred = wait_model.predict(X_test)\n",
    "    y_pred = np.maximum(y_pred, 0)  # Ensure non-negative\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\nTest Set Metrics:\")\n",
    "    print(f\"   MAE: {mae:.2f} minutes\")\n",
    "    print(f\"   RMSE: {rmse:.2f} minutes\")\n",
    "    print(f\"   R²: {r2:.4f}\")\n",
    "    \n",
    "    # Evaluate by wait time range\n",
    "    print(f\"\\nMAE by Wait Time Range:\")\n",
    "    for min_wait, max_wait in [(0, 10), (10, 30), (30, 60), (60, np.inf)]:\n",
    "        mask = (y_test >= min_wait) & (y_test < max_wait)\n",
    "        if mask.sum() > 0:\n",
    "            range_mae = mean_absolute_error(y_test[mask], y_pred[mask])\n",
    "            print(f\"   {min_wait}-{max_wait if max_wait != np.inf else '∞'} min: {range_mae:.2f} (n={mask.sum()})\")\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([0, max(y_test)], [0, max(y_test)], 'r--')\n",
    "    plt.xlabel('Actual Wait Time')\n",
    "    plt.ylabel('Predicted Wait Time')\n",
    "    plt.title(f'Linear Model with Attendance - {ride_name}')\n",
    "    plt.text(0.05, 0.95, f'MAE: {mae:.1f}\\nRMSE: {rmse:.1f}\\nR²: {r2:.3f}', \n",
    "             transform=plt.gca().transAxes, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    residuals = y_pred - y_test\n",
    "    plt.scatter(y_test, residuals, alpha=0.5)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Actual Wait Time')\n",
    "    plt.ylabel('Residual')\n",
    "    plt.title('Residual Plot')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'wait_model': wait_model,\n",
    "        'attendance_model': attendance_model,\n",
    "        'attendance_features': attendance_features,\n",
    "        'cat_features': cat_features,\n",
    "        'num_features': num_features,\n",
    "        'metrics': {'mae': mae, 'rmse': rmse, 'r2': r2}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c2ff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training Linear Model with Attendance for silver star ===\n",
      "\n",
      "1. Loading and preprocessing data...\n",
      "   Total data shape: (33053, 11)\n",
      "\n",
      "2. Creating features...\n",
      "\n",
      "3. Splitting data (test year: 2023)...\n",
      "   Train data: 23988 samples\n",
      "   Test data: 4673 samples\n",
      "\n",
      "4. Training attendance model...\n",
      "\n",
      "5. Predicting attendance...\n",
      "\n",
      "6. Preparing features for wait time model...\n",
      "   Filling 42 NaN values in 'temperature'\n",
      "   Filling 42 NaN values in 'temp_squared'\n",
      "   Filling 278 NaN values in 'wind'\n",
      "   Filling 4 NaN values in 'time_of_day'\n",
      "\n",
      "7. Training wait time model...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['hour_bin', 'rain_intensity', 'dow_sin', 'dow_cos', 'day_of_month', 'week_of_year', 'temp_deviation', 'wind_squared', 'high_wind'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m test_year \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2023\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_linear_model_with_attendance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mride_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_year\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel training completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 49\u001b[0m, in \u001b[0;36mtrain_linear_model_with_attendance\u001b[1;34m(file_path, ride_name, test_year)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m7. Training wait time model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m wait_model \u001b[38;5;241m=\u001b[39m build_wait_time_model(cat_features, num_features)\n\u001b[1;32m---> 49\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     50\u001b[0m y_train \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwait_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     52\u001b[0m wait_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\Nevin\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Nevin\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nevin\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['hour_bin', 'rain_intensity', 'dow_sin', 'dow_cos', 'day_of_month', 'week_of_year', 'temp_deviation', 'wind_squared', 'high_wind'] not in index\""
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "data_path = \"../data/processed/ep/merged_with_holidays.parquet\"\n",
    "ride_name = \"silver star\"\n",
    "test_year = 2023\n",
    "    \n",
    "# Train model\n",
    "results = train_linear_model_with_attendance(data_path, ride_name, test_year)\n",
    "    \n",
    "print(\"\\nModel training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af2cefb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
