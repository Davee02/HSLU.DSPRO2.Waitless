{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca70e08",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85188db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e2a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_timestamp(df):\n",
    "    \"\"\"Extract temporal components from timestamp\"\"\"\n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    df['day'] = df['datetime'].dt.day\n",
    "    df['weekday'] = df['datetime'].dt.weekday  # Monday=0, Sunday=6\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['minute'] = df['datetime'].dt.minute\n",
    "\n",
    "    df['is_weekend'] = df['weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "    df['part_of_day'] = df['hour'].apply(lambda x: \n",
    "                                        'morning' if 6 <= x < 12 else\n",
    "                                        'afternoon' if 12 <= x < 17 else\n",
    "                                        'evening' if 17 <= x < 20 else\n",
    "                                        'night')\n",
    "    \n",
    "    df['season'] = df['month'].apply(lambda x:\n",
    "                                    'winter' if x in [12, 1, 2] else\n",
    "                                    'spring' if x in [3, 4, 5] else\n",
    "                                    'summer' if x in [6, 7, 8] else\n",
    "                                    'fall')\n",
    "    \n",
    "    # Cyclical encoding\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month']/12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month']/12)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24)\n",
    "    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday']/7)\n",
    "    df['weekday_cos'] = np.cos(2 * np.pi * df['weekday']/7)\n",
    "    df['minute_sin'] = np.sin(2 * np.pi * df['minute']/60)\n",
    "    df['minute_cos'] = np.cos(2 * np.pi * df['minute']/60)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def process_boolean_features(df):\n",
    "    \"\"\"Convert boolean features to integers\"\"\"\n",
    "    bool_cols = ['closed', 'is_german_holiday', 'is_swiss_holiday', 'is_french_holiday']\n",
    "    \n",
    "    for col in bool_cols:\n",
    "        if col in df.columns:\n",
    "            if df[col].dtype == bool:\n",
    "                df[col] = df[col].astype(int)\n",
    "            elif df[col].dtype == object:\n",
    "                df[col] = df[col].map({'True': 1, 'False': 0})\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ca3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_theme_park_data_memory_efficient(df, output_file='processed_data.parquet', batch_size=100000, temp_dir='temp_efficient'):\n",
    "    \"\"\"\n",
    "    Memory-efficient implementation that processes the entire dataset for scaling/encoding\n",
    "    but operates in batches to maintain memory efficiency.\n",
    "    Now scales numerical features per ride_name separately.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "    from collections import defaultdict\n",
    "\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    \n",
    "    for f in os.listdir(temp_dir):\n",
    "        if f.endswith('.parquet'):\n",
    "            os.remove(os.path.join(temp_dir, f))\n",
    "    \n",
    "    total_rows = len(df)\n",
    "    print(f\"Total rows to process: {total_rows}\")\n",
    "    \n",
    "    print(\"Phase 1: Calculating statistics for encoding and scaling...\")\n",
    "    \n",
    "    cat_cols = ['ride_name', 'part_of_day', 'season', 'year']\n",
    "    num_cols = ['temperature', 'rain', 'wind']\n",
    "    num_cols = [col for col in num_cols if col in df.columns]\n",
    "    \n",
    "    ride_stats = defaultdict(lambda: {\n",
    "        'count': 0,\n",
    "        'mean': np.zeros(len(num_cols)),\n",
    "        'var': np.zeros(len(num_cols))\n",
    "    })\n",
    "    \n",
    "    cat_values = {col: set() for col in cat_cols}\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        batch = df.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        batch = decompose_timestamp(batch)\n",
    "        batch = process_boolean_features(batch)\n",
    "        \n",
    "        for col in cat_cols:\n",
    "            unique_vals = batch[col].dropna().astype(str).unique()\n",
    "            cat_values[col].update(unique_vals)\n",
    "        \n",
    "        if num_cols:\n",
    "            for ride in batch['ride_name'].unique():\n",
    "                ride_batch = batch[batch['ride_name'] == ride]\n",
    "                \n",
    "                if len(ride_batch) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                ride_batch_count = len(ride_batch)\n",
    "                ride_batch_mean = ride_batch[num_cols].mean().values\n",
    "                ride_batch_var = ride_batch[num_cols].var().values\n",
    "                \n",
    "                # Update running statistics using Welford's algorithm\n",
    "                if ride_stats[ride]['count'] == 0:\n",
    "                    ride_stats[ride]['mean'] = ride_batch_mean\n",
    "                    ride_stats[ride]['var'] = ride_batch_var\n",
    "                    ride_stats[ride]['count'] = ride_batch_count\n",
    "                else:\n",
    "                    delta = ride_batch_mean - ride_stats[ride]['mean']\n",
    "                    mean_new = ride_stats[ride]['mean'] + delta * (ride_batch_count / (ride_stats[ride]['count'] + ride_batch_count))\n",
    "                    delta2 = ride_batch_mean - mean_new\n",
    "                    ride_stats[ride]['var'] = (ride_stats[ride]['var'] * ride_stats[ride]['count'] + \n",
    "                                             ride_batch_var * ride_batch_count + \n",
    "                                             delta * delta2 * ride_stats[ride]['count'] * ride_batch_count / \n",
    "                                             (ride_stats[ride]['count'] + ride_batch_count)) / (ride_stats[ride]['count'] + ride_batch_count)\n",
    "                    ride_stats[ride]['mean'] = mean_new\n",
    "                    ride_stats[ride]['count'] += ride_batch_count\n",
    "        \n",
    "        progress = (end_idx / total_rows) * 100\n",
    "        print(f\"Statistics collection progress: {progress:.2f}%\")\n",
    "        \n",
    "        # Release memory\n",
    "        del batch\n",
    "    \n",
    "    # Create scalers for each ride\n",
    "    ride_scalers = {}\n",
    "    for ride, stats in ride_stats.items():\n",
    "        scaler = StandardScaler()\n",
    "        scaler.mean_ = stats['mean']\n",
    "        scaler.scale_ = np.sqrt(stats['var'])\n",
    "        scaler.var_ = stats['var']\n",
    "        scaler.n_features_in_ = len(num_cols)\n",
    "        scaler.n_samples_seen_ = stats['count']\n",
    "        scaler.feature_names_in_ = np.array(num_cols)\n",
    "        ride_scalers[ride] = scaler\n",
    "    \n",
    "\n",
    "    categories = []\n",
    "    cat_indices = []\n",
    "    start_idx = 0\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        sorted_cats = sorted(list(cat_values[col]))\n",
    "        categories.append(np.array(sorted_cats))\n",
    "        n_cats = len(sorted_cats)\n",
    "        cat_indices.append((start_idx, start_idx + n_cats))\n",
    "        start_idx += n_cats\n",
    "    \n",
    "    encoder = OneHotEncoder(\n",
    "        sparse_output=False,\n",
    "        handle_unknown='ignore',\n",
    "        categories=categories\n",
    "    )\n",
    "    \n",
    "    dummy_data = pd.DataFrame([[categories[i][0] for i in range(len(cat_cols))]], columns=cat_cols)\n",
    "    encoder.fit(dummy_data)\n",
    "    \n",
    "    print(\"Statistics calculated. Starting data transformation...\")\n",
    "    \n",
    "    batch_files = []\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        batch = df.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        batch_num = (start_idx // batch_size) + 1\n",
    "        print(f\"Processing batch {batch_num}: rows {start_idx} to {end_idx}\")\n",
    "        \n",
    "        batch = decompose_timestamp(batch)\n",
    "        \n",
    "        batch = batch.drop(columns=['month', 'day', 'hour', 'minute'], errors='ignore')\n",
    "        batch = process_boolean_features(batch)\n",
    "        \n",
    "        try:\n",
    "            for col in cat_cols:\n",
    "                batch[col] = batch[col].astype(str)\n",
    "                \n",
    "            encoded_cats = encoder.transform(batch[cat_cols])\n",
    "            encoded_df = pd.DataFrame(\n",
    "                encoded_cats,\n",
    "                columns=encoder.get_feature_names_out(cat_cols),\n",
    "                index=batch.index\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error during encoding: {e}\")\n",
    "            print(f\"Unique values: {[batch[col].unique()[:5] for col in cat_cols]}\")\n",
    "            raise\n",
    "\n",
    "        # Scale numerical features per ride_name\n",
    "        if num_cols:\n",
    "            for ride in batch['ride_name'].unique():\n",
    "                ride_mask = batch['ride_name'] == ride\n",
    "                if ride_mask.any() and ride in ride_scalers:\n",
    "                    batch.loc[ride_mask, num_cols] = ride_scalers[ride].transform(batch.loc[ride_mask, num_cols])\n",
    "\n",
    "        batch = pd.concat([batch.drop(cat_cols, axis=1), encoded_df], axis=1)\n",
    "\n",
    "        cols_to_drop = ['timestamp', 'datetime']\n",
    "        batch = batch.drop(columns=[col for col in cols_to_drop if col in batch.columns])\n",
    "        \n",
    "        temp_file = os.path.join(temp_dir, f\"batch_{batch_num}.parquet\")\n",
    "        batch.to_parquet(temp_file, index=False)\n",
    "        batch_files.append(temp_file)\n",
    "        \n",
    "        del batch\n",
    "        del encoded_df\n",
    "        \n",
    "        progress = (end_idx / total_rows) * 100\n",
    "        print(f\"Transformation progress: {progress:.2f}%\")\n",
    "    \n",
    "    print(f\"All batches processed. Creating final output file...\")\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "    \n",
    "    concat_batch_size = 5 \n",
    "    for i in range(0, len(batch_files), concat_batch_size):\n",
    "        batch_group = batch_files[i:i+concat_batch_size]\n",
    "        print(f\"Combining batch files {i+1} to {min(i+concat_batch_size, len(batch_files))}\")\n",
    "        \n",
    "        group_dfs = [pd.read_parquet(file) for file in batch_group]\n",
    "        combined_df = pd.concat(group_dfs, ignore_index=True)\n",
    "        \n",
    "        mode = 'w' if i == 0 else 'a'\n",
    "        combined_df.to_parquet(output_file, index=False, engine='fastparquet', append=(mode=='a'))\n",
    "        \n",
    "        # Clean up\n",
    "        for df_obj in group_dfs:\n",
    "            del df_obj\n",
    "        del combined_df\n",
    "    \n",
    "    print(f\"All data combined and saved to {output_file}\")\n",
    "    \n",
    "    # Clean up temporary files\n",
    "    for file in batch_files:\n",
    "        os.remove(file)\n",
    "    \n",
    "    print(\"Temporary files removed\")\n",
    "    \n",
    "    transformers = {'encoder': encoder, 'scalers': ride_scalers}\n",
    "    return transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eede7841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ride_name', 'timestamp', 'wait_time', 'closed', 'is_german_holiday',\n",
      "       'is_swiss_holiday', 'is_french_holiday', 'date', 'datetime',\n",
      "       'time_bucket', 'day_of_week', 'temperature', 'rain'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_input_dir = \"../data/processed\"\n",
    "input_file = os.path.join(data_input_dir, \"ep\", \"cleaned_wait_times_with_nonoperating.parquet\")\n",
    "ep_df = pd.read_parquet(input_file)\n",
    "print(ep_df.columns.unique())\n",
    "ep_df.drop(columns=['feature_attraction_type', 'feature_category', 'feature_max_height', 'feature_track_length', 'feature_max_speed', 'feature_g_force',\n",
    "       'feature_min_age', 'feature_min_height', 'feature_capacity_per_hour', 'date'], errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0bec018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int32(2017), np.int32(2018), np.int32(2019), np.int32(2020), np.int32(2021), np.int32(2022), np.int32(2023), np.int32(2024)}\n"
     ]
    }
   ],
   "source": [
    "years = ep_df[\"timestamp\"].unique().year\n",
    "print(set(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b551ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data')\n",
    "output_path = data_dir / 'processed' / 'ep' / 'final_cleaned_processed_wait_times.parquet'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "745535a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows to process: 12734224\n",
      "Phase 1: Calculating statistics for encoding and scaling...\n",
      "Statistics collection progress: 7.85%\n",
      "Statistics collection progress: 15.71%\n",
      "Statistics collection progress: 23.56%\n",
      "Statistics collection progress: 31.41%\n",
      "Statistics collection progress: 39.26%\n",
      "Statistics collection progress: 47.12%\n",
      "Statistics collection progress: 54.97%\n",
      "Statistics collection progress: 62.82%\n",
      "Statistics collection progress: 70.68%\n",
      "Statistics collection progress: 78.53%\n",
      "Statistics collection progress: 86.38%\n",
      "Statistics collection progress: 94.23%\n",
      "Statistics collection progress: 100.00%\n",
      "Statistics calculated. Starting data transformation...\n",
      "Processing batch 1: rows 0 to 1000000\n",
      "Transformation progress: 7.85%\n",
      "Processing batch 2: rows 1000000 to 2000000\n",
      "Transformation progress: 15.71%\n",
      "Processing batch 3: rows 2000000 to 3000000\n",
      "Transformation progress: 23.56%\n",
      "Processing batch 4: rows 3000000 to 4000000\n",
      "Transformation progress: 31.41%\n",
      "Processing batch 5: rows 4000000 to 5000000\n",
      "Transformation progress: 39.26%\n",
      "Processing batch 6: rows 5000000 to 6000000\n",
      "Transformation progress: 47.12%\n",
      "Processing batch 7: rows 6000000 to 7000000\n",
      "Transformation progress: 54.97%\n",
      "Processing batch 8: rows 7000000 to 8000000\n",
      "Transformation progress: 62.82%\n",
      "Processing batch 9: rows 8000000 to 9000000\n",
      "Transformation progress: 70.68%\n",
      "Processing batch 10: rows 9000000 to 10000000\n",
      "Transformation progress: 78.53%\n",
      "Processing batch 11: rows 10000000 to 11000000\n",
      "Transformation progress: 86.38%\n",
      "Processing batch 12: rows 11000000 to 12000000\n",
      "Transformation progress: 94.23%\n",
      "Processing batch 13: rows 12000000 to 12734224\n",
      "Transformation progress: 100.00%\n",
      "All batches processed. Creating final output file...\n",
      "Combining batch files 1 to 5\n",
      "Combining batch files 6 to 10\n",
      "Combining batch files 11 to 13\n",
      "All data combined and saved to ../data/processed/ep/final_cleaned_processed_wait_times.parquet\n",
      "Temporary files removed\n"
     ]
    }
   ],
   "source": [
    "# Make sure the directory exists\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "transformers = preprocess_theme_park_data_memory_efficient(ep_df, output_path, batch_size=1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3733f3fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "parquet_file = pq.ParquetFile(output_path)\n",
    "all_columns = parquet_file.schema.names\n",
    "\n",
    "columns_to_read = [col for col in all_columns \n",
    "                   if not (col.startswith(\"feature_attraction_type\") or col.startswith(\"feature_category\") or col.startswith(\"feature\"))]\n",
    "\n",
    "table = pq.read_table(output_path)\n",
    "ep_df_preview = table.slice(0, 1000000).to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a22e287",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ep_df_preview' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mep_df_preview\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ep_df_preview' is not defined"
     ]
    }
   ],
   "source": [
    "len(ep_df_preview.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd727de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['wait_time', 'closed', 'is_german_holiday', 'is_swiss_holiday',\n",
       "       'is_french_holiday', 'time_bucket', 'day_of_week', 'temperature',\n",
       "       'rain', 'weekday', 'is_weekend', 'month_sin', 'month_cos', 'hour_sin',\n",
       "       'hour_cos', 'weekday_sin', 'weekday_cos', 'minute_sin', 'minute_cos',\n",
       "       'ride_name_alpine express enzian',\n",
       "       'ride_name_arena of football  be part of it', 'ride_name_arthur',\n",
       "       'ride_name_atlantica supersplash', 'ride_name_atlantis adventure',\n",
       "       'ride_name_baaa express', 'ride_name_blue fire megacoaster',\n",
       "       'ride_name_castello dei medici', 'ride_name_dancing dingie',\n",
       "       'ride_name_euromir', 'ride_name_eurosat  cancan coaster',\n",
       "       'ride_name_eurotower', 'ride_name_fjordrafting',\n",
       "       'ride_name_jim button  journey through morrowland',\n",
       "       'ride_name_josefinas magical imperial journey',\n",
       "       'ride_name_kolumbusjolle', 'ride_name_madame freudenreich curiosits',\n",
       "       'ride_name_matterhornblitz', 'ride_name_old mac donalds tractor fun',\n",
       "       'ride_name_pegasus', 'ride_name_poppy towers', 'ride_name_poseidon',\n",
       "       'ride_name_silver star', 'ride_name_swiss bob run',\n",
       "       'ride_name_tirol log flume', 'ride_name_vienna wave swing  glckspilz',\n",
       "       'ride_name_vindjammer', 'ride_name_voletarium',\n",
       "       'ride_name_volo da vinci', 'ride_name_voltron nevera powered by rimac',\n",
       "       'ride_name_whale adventures  northern lights', 'part_of_day_afternoon',\n",
       "       'part_of_day_evening', 'part_of_day_morning', 'part_of_day_night',\n",
       "       'season_fall', 'season_spring', 'season_summer', 'season_winter',\n",
       "       'year_2017', 'year_2018', 'year_2019', 'year_2020', 'year_2021',\n",
       "       'year_2022', 'year_2023', 'year_2024'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_df_preview.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e641fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parquet_file = pq.ParquetFile(output_path)\n",
    "all_columns = parquet_file.schema.names\n",
    "\n",
    "columns_to_read = [col for col in all_columns \n",
    "                   if not (col.startswith(\"ride_name\") or col.startswith(\"season\")or col.startswith(\"part\"))]\n",
    "\n",
    "table = pq.read_table(output_path, columns=columns_to_read)\n",
    "ep_df_column_analyze = table.slice(0, 1000000).to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c0d8bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(-1.0), np.float64(-0.8660254037844386), np.float64(-0.8660254037844384), np.float64(-0.5000000000000004), np.float64(-0.4999999999999997), np.float64(-2.4492935982947064e-16), np.float64(1.2246467991473532e-16), np.float64(0.49999999999999994), np.float64(0.8660254037844387)]\n",
      "[np.float64(-1.0), np.float64(-0.8660254037844388), np.float64(-0.8660254037844387), np.float64(-0.5000000000000004), np.float64(-0.4999999999999998), np.float64(-1.8369701987210297e-16), np.float64(0.5000000000000001), np.float64(0.8660254037844384), np.float64(1.0)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(ep_df_column_analyze[\"month_sin\"].unique()))\n",
    "print(sorted(ep_df_column_analyze[\"month_cos\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8e6c014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['wait_time', 'closed', 'is_german_holiday', 'is_swiss_holiday',\n",
       "       'is_french_holiday', 'time_bucket', 'day_of_week', 'temperature',\n",
       "       'rain', 'weekday', 'is_weekend', 'month_sin', 'month_cos', 'hour_sin',\n",
       "       'hour_cos', 'weekday_sin', 'weekday_cos', 'minute_sin', 'minute_cos',\n",
       "       'year_2017', 'year_2018', 'year_2019', 'year_2020', 'year_2021',\n",
       "       'year_2022', 'year_2023', 'year_2024'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_df_column_analyze.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faaf5a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wait_time</th>\n",
       "      <th>closed</th>\n",
       "      <th>is_german_holiday</th>\n",
       "      <th>is_swiss_holiday</th>\n",
       "      <th>is_french_holiday</th>\n",
       "      <th>time_bucket</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rain</th>\n",
       "      <th>weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>minute_sin</th>\n",
       "      <th>minute_cos</th>\n",
       "      <th>year_2017</th>\n",
       "      <th>year_2018</th>\n",
       "      <th>year_2019</th>\n",
       "      <th>year_2020</th>\n",
       "      <th>year_2021</th>\n",
       "      <th>year_2022</th>\n",
       "      <th>year_2023</th>\n",
       "      <th>year_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.177356</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.185032</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.191822</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.197828</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.832769e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.203154</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:25:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.207904</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.212179</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.665539e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:35:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.216083</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.219718</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:45:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.223189</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:50:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.226598</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:55:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.230048</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.233643</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 01:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.237439</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 01:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.241315</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 01:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.245105</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.832769e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 01:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.248640</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 01:25:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.251753</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 01:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.254278</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.665539e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 01:35:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.256048</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    wait_time  closed  is_german_holiday  is_swiss_holiday  is_french_holiday  \\\n",
       "0         0.0       0                  0                 0                  0   \n",
       "1         0.0       0                  0                 0                  0   \n",
       "2         0.0       0                  0                 0                  0   \n",
       "3         0.0       0                  0                 0                  0   \n",
       "4         0.0       0                  0                 0                  0   \n",
       "5         0.0       0                  0                 0                  0   \n",
       "6         0.0       0                  0                 0                  0   \n",
       "7         0.0       0                  0                 0                  0   \n",
       "8         0.0       0                  0                 0                  0   \n",
       "9         0.0       0                  0                 0                  0   \n",
       "10        0.0       0                  0                 0                  0   \n",
       "11        0.0       0                  0                 0                  0   \n",
       "12        0.0       0                  0                 0                  0   \n",
       "13        0.0       0                  0                 0                  0   \n",
       "14        0.0       0                  0                 0                  0   \n",
       "15        0.0       0                  0                 0                  0   \n",
       "16        0.0       0                  0                 0                  0   \n",
       "17        0.0       0                  0                 0                  0   \n",
       "18        0.0       0                  0                 0                  0   \n",
       "19        0.0       0                  0                 0                  0   \n",
       "\n",
       "           time_bucket  day_of_week  temperature      rain  weekday  ...  \\\n",
       "0  2017-05-23 00:00:00            1    -0.177356 -0.217428        1  ...   \n",
       "1  2017-05-23 00:05:00            1    -0.185032 -0.217428        1  ...   \n",
       "2  2017-05-23 00:10:00            1    -0.191822 -0.217428        1  ...   \n",
       "3  2017-05-23 00:15:00            1    -0.197828 -0.217428        1  ...   \n",
       "4  2017-05-23 00:20:00            1    -0.203154 -0.217428        1  ...   \n",
       "5  2017-05-23 00:25:00            1    -0.207904 -0.217428        1  ...   \n",
       "6  2017-05-23 00:30:00            1    -0.212179 -0.217428        1  ...   \n",
       "7  2017-05-23 00:35:00            1    -0.216083 -0.217428        1  ...   \n",
       "8  2017-05-23 00:40:00            1    -0.219718 -0.217428        1  ...   \n",
       "9  2017-05-23 00:45:00            1    -0.223189 -0.217428        1  ...   \n",
       "10 2017-05-23 00:50:00            1    -0.226598 -0.217428        1  ...   \n",
       "11 2017-05-23 00:55:00            1    -0.230048 -0.217428        1  ...   \n",
       "12 2017-05-23 01:00:00            1    -0.233643 -0.217428        1  ...   \n",
       "13 2017-05-23 01:05:00            1    -0.237439 -0.217428        1  ...   \n",
       "14 2017-05-23 01:10:00            1    -0.241315 -0.217428        1  ...   \n",
       "15 2017-05-23 01:15:00            1    -0.245105 -0.217428        1  ...   \n",
       "16 2017-05-23 01:20:00            1    -0.248640 -0.217428        1  ...   \n",
       "17 2017-05-23 01:25:00            1    -0.251753 -0.217428        1  ...   \n",
       "18 2017-05-23 01:30:00            1    -0.254278 -0.217428        1  ...   \n",
       "19 2017-05-23 01:35:00            1    -0.256048 -0.217428        1  ...   \n",
       "\n",
       "      minute_sin    minute_cos  year_2017  year_2018  year_2019  year_2020  \\\n",
       "0   0.000000e+00  1.000000e+00        1.0        0.0        0.0        0.0   \n",
       "1   5.000000e-01  8.660254e-01        1.0        0.0        0.0        0.0   \n",
       "2   8.660254e-01  5.000000e-01        1.0        0.0        0.0        0.0   \n",
       "3   1.000000e+00  2.832769e-16        1.0        0.0        0.0        0.0   \n",
       "4   8.660254e-01 -5.000000e-01        1.0        0.0        0.0        0.0   \n",
       "5   5.000000e-01 -8.660254e-01        1.0        0.0        0.0        0.0   \n",
       "6   5.665539e-16 -1.000000e+00        1.0        0.0        0.0        0.0   \n",
       "7  -5.000000e-01 -8.660254e-01        1.0        0.0        0.0        0.0   \n",
       "8  -8.660254e-01 -5.000000e-01        1.0        0.0        0.0        0.0   \n",
       "9  -1.000000e+00 -1.836970e-16        1.0        0.0        0.0        0.0   \n",
       "10 -8.660254e-01  5.000000e-01        1.0        0.0        0.0        0.0   \n",
       "11 -5.000000e-01  8.660254e-01        1.0        0.0        0.0        0.0   \n",
       "12  0.000000e+00  1.000000e+00        1.0        0.0        0.0        0.0   \n",
       "13  5.000000e-01  8.660254e-01        1.0        0.0        0.0        0.0   \n",
       "14  8.660254e-01  5.000000e-01        1.0        0.0        0.0        0.0   \n",
       "15  1.000000e+00  2.832769e-16        1.0        0.0        0.0        0.0   \n",
       "16  8.660254e-01 -5.000000e-01        1.0        0.0        0.0        0.0   \n",
       "17  5.000000e-01 -8.660254e-01        1.0        0.0        0.0        0.0   \n",
       "18  5.665539e-16 -1.000000e+00        1.0        0.0        0.0        0.0   \n",
       "19 -5.000000e-01 -8.660254e-01        1.0        0.0        0.0        0.0   \n",
       "\n",
       "    year_2021  year_2022  year_2023  year_2024  \n",
       "0         0.0        0.0        0.0        0.0  \n",
       "1         0.0        0.0        0.0        0.0  \n",
       "2         0.0        0.0        0.0        0.0  \n",
       "3         0.0        0.0        0.0        0.0  \n",
       "4         0.0        0.0        0.0        0.0  \n",
       "5         0.0        0.0        0.0        0.0  \n",
       "6         0.0        0.0        0.0        0.0  \n",
       "7         0.0        0.0        0.0        0.0  \n",
       "8         0.0        0.0        0.0        0.0  \n",
       "9         0.0        0.0        0.0        0.0  \n",
       "10        0.0        0.0        0.0        0.0  \n",
       "11        0.0        0.0        0.0        0.0  \n",
       "12        0.0        0.0        0.0        0.0  \n",
       "13        0.0        0.0        0.0        0.0  \n",
       "14        0.0        0.0        0.0        0.0  \n",
       "15        0.0        0.0        0.0        0.0  \n",
       "16        0.0        0.0        0.0        0.0  \n",
       "17        0.0        0.0        0.0        0.0  \n",
       "18        0.0        0.0        0.0        0.0  \n",
       "19        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[20 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_df_column_analyze.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ddd7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n",
      "\n",
      "==== Basic Information ====\n",
      "Data shape: (12734224, 66)\n",
      "\n",
      "==== Check 1: Missing Values ====\n",
      "✓ No missing values found\n",
      "\n",
      "==== Check 2: Feature Ranges ====\n",
      "✓ month_sin is within expected range [-1, 1]\n",
      "✓ month_cos is within expected range [-1, 1]\n",
      "✓ hour_sin is within expected range [-1, 1]\n",
      "✓ hour_cos is within expected range [-1, 1]\n",
      "✓ weekday_sin is within expected range [-1, 1]\n",
      "✓ weekday_cos is within expected range [-1, 1]\n",
      "✓ minute_sin is within expected range [-1, 1]\n",
      "✓ minute_cos is within expected range [-1, 1]\n",
      "✓ ride_name_alpine express enzian contains only 0 and 1 as expected\n",
      "✓ ride_name_arena of football  be part of it contains only 0 and 1 as expected\n",
      "✓ ride_name_arthur contains only 0 and 1 as expected\n",
      "✓ ride_name_atlantica supersplash contains only 0 and 1 as expected\n",
      "✓ ride_name_atlantis adventure contains only 0 and 1 as expected\n",
      "✓ ride_name_baaa express contains only 0 and 1 as expected\n",
      "✓ ride_name_blue fire megacoaster contains only 0 and 1 as expected\n",
      "✓ ride_name_castello dei medici contains only 0 and 1 as expected\n",
      "✓ ride_name_dancing dingie contains only 0 and 1 as expected\n",
      "✓ ride_name_euromir contains only 0 and 1 as expected\n",
      "✓ ride_name_eurosat  cancan coaster contains only 0 and 1 as expected\n",
      "✓ ride_name_eurotower contains only 0 and 1 as expected\n",
      "✓ ride_name_fjordrafting contains only 0 and 1 as expected\n",
      "✓ ride_name_jim button  journey through morrowland contains only 0 and 1 as expected\n",
      "✓ ride_name_josefinas magical imperial journey contains only 0 and 1 as expected\n",
      "✓ ride_name_kolumbusjolle contains only 0 and 1 as expected\n",
      "✓ ride_name_madame freudenreich curiosits contains only 0 and 1 as expected\n",
      "✓ ride_name_matterhornblitz contains only 0 and 1 as expected\n",
      "✓ ride_name_old mac donalds tractor fun contains only 0 and 1 as expected\n",
      "✓ ride_name_pegasus contains only 0 and 1 as expected\n",
      "✓ ride_name_poppy towers contains only 0 and 1 as expected\n",
      "✓ ride_name_poseidon contains only 0 and 1 as expected\n",
      "✓ ride_name_silver star contains only 0 and 1 as expected\n",
      "✓ ride_name_swiss bob run contains only 0 and 1 as expected\n",
      "✓ ride_name_tirol log flume contains only 0 and 1 as expected\n",
      "✓ ride_name_vienna wave swing  glckspilz contains only 0 and 1 as expected\n",
      "✓ ride_name_vindjammer contains only 0 and 1 as expected\n",
      "✓ ride_name_voletarium contains only 0 and 1 as expected\n",
      "✓ ride_name_volo da vinci contains only 0 and 1 as expected\n",
      "✓ ride_name_voltron nevera powered by rimac contains only 0 and 1 as expected\n",
      "✓ ride_name_whale adventures  northern lights contains only 0 and 1 as expected\n",
      "✓ part_of_day_afternoon contains only 0 and 1 as expected\n",
      "✓ part_of_day_evening contains only 0 and 1 as expected\n",
      "✓ part_of_day_morning contains only 0 and 1 as expected\n",
      "✓ part_of_day_night contains only 0 and 1 as expected\n",
      "✓ season_fall contains only 0 and 1 as expected\n",
      "✓ season_spring contains only 0 and 1 as expected\n",
      "✓ season_summer contains only 0 and 1 as expected\n",
      "✓ season_winter contains only 0 and 1 as expected\n",
      "✓ closed contains only 0 and 1 as expected\n",
      "✓ is_german_holiday contains only 0 and 1 as expected\n",
      "✓ is_swiss_holiday contains only 0 and 1 as expected\n",
      "✓ is_french_holiday contains only 0 and 1 as expected\n",
      "✓ is_weekend contains only 0 and 1 as expected\n",
      "\n",
      "==== Check 3: Consistency Checks ====\n",
      "✓ 'weekday' and 'is_weekend' are consistent\n",
      "✓ Each observation has exactly one ride assigned\n",
      "✓ Each observation has exactly one part_of_day assigned\n",
      "✓ Each observation has exactly one season assigned\n",
      "\n",
      "==== Check 4: Scaled Numerical Features ====\n",
      "✓ temperature appears properly scaled (mean ≈ 0, std ≈ 1)\n",
      "✓ rain appears properly scaled (mean ≈ 0, std ≈ 1)\n",
      "\n",
      "==== Check 5: Cyclical Feature Correlations ====\n",
      "Warning: Correlation between month_sin and month_cos is -0.3147, expected near 0\n",
      "✓ hour_sin and hour_cos have low correlation as expected\n",
      "✓ weekday_sin and weekday_cos have low correlation as expected\n",
      "✓ minute_sin and minute_cos have low correlation as expected\n",
      "\n",
      "==== Check 6: Wait Time Distribution ====\n",
      "Wait time min: 0.0, mean: 4.62, max: 90.0\n",
      "Warning: 38984 extreme wait time outliers found\n",
      "Outlier values: [np.float64(60.0), np.float64(65.0), np.float64(70.0), np.float64(75.0), np.float64(80.0), np.float64(85.0), np.float64(90.0)]\n",
      "\n",
      "==== Check 7: Closed Rides and Wait Times ====\n",
      "✓ All closed rides have wait time 0 or NaN as expected\n",
      "\n",
      "==== Check 8: Inspection of Cyclical Features ====\n",
      "Cyclical encodings should form circular patterns when sin/cos components are plotted against each other\n",
      "✓ month cyclical encoding maintains unit circle property\n",
      "✓ hour cyclical encoding maintains unit circle property\n",
      "✓ weekday cyclical encoding maintains unit circle property\n",
      "\n",
      "==== Summary ====\n",
      "Sanity check complete. Review the warnings above if any.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wait_time</th>\n",
       "      <th>closed</th>\n",
       "      <th>is_german_holiday</th>\n",
       "      <th>is_swiss_holiday</th>\n",
       "      <th>is_french_holiday</th>\n",
       "      <th>time_bucket</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rain</th>\n",
       "      <th>weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>season_summer</th>\n",
       "      <th>season_winter</th>\n",
       "      <th>year_2017</th>\n",
       "      <th>year_2018</th>\n",
       "      <th>year_2019</th>\n",
       "      <th>year_2020</th>\n",
       "      <th>year_2021</th>\n",
       "      <th>year_2022</th>\n",
       "      <th>year_2023</th>\n",
       "      <th>year_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.177356</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:05:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.185032</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.191822</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.197828</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-23 00:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.203154</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12734219</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-31 22:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.399964</td>\n",
       "      <td>-0.218333</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12734220</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-31 22:45:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.403878</td>\n",
       "      <td>-0.218333</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12734221</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-31 22:50:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.407228</td>\n",
       "      <td>-0.218333</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12734222</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-31 22:55:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.409951</td>\n",
       "      <td>-0.218333</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12734223</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-31 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.411984</td>\n",
       "      <td>-0.218333</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12734224 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          wait_time  closed  is_german_holiday  is_swiss_holiday  \\\n",
       "0               0.0       0                  0                 0   \n",
       "1               0.0       0                  0                 0   \n",
       "2               0.0       0                  0                 0   \n",
       "3               0.0       0                  0                 0   \n",
       "4               0.0       0                  0                 0   \n",
       "...             ...     ...                ...               ...   \n",
       "12734219        0.0       0                  0                 0   \n",
       "12734220        0.0       0                  0                 0   \n",
       "12734221        0.0       0                  0                 0   \n",
       "12734222        0.0       0                  0                 0   \n",
       "12734223        0.0       0                  0                 0   \n",
       "\n",
       "          is_french_holiday         time_bucket  day_of_week  temperature  \\\n",
       "0                         0 2017-05-23 00:00:00            1    -0.177356   \n",
       "1                         0 2017-05-23 00:05:00            1    -0.185032   \n",
       "2                         0 2017-05-23 00:10:00            1    -0.191822   \n",
       "3                         0 2017-05-23 00:15:00            1    -0.197828   \n",
       "4                         0 2017-05-23 00:20:00            1    -0.203154   \n",
       "...                     ...                 ...          ...          ...   \n",
       "12734219                  0 2024-12-31 22:40:00            1    -2.399964   \n",
       "12734220                  0 2024-12-31 22:45:00            1    -2.403878   \n",
       "12734221                  0 2024-12-31 22:50:00            1    -2.407228   \n",
       "12734222                  0 2024-12-31 22:55:00            1    -2.409951   \n",
       "12734223                  0 2024-12-31 23:00:00            1    -2.411984   \n",
       "\n",
       "              rain  weekday  ...  season_summer  season_winter  year_2017  \\\n",
       "0        -0.217428        1  ...            0.0            0.0        1.0   \n",
       "1        -0.217428        1  ...            0.0            0.0        1.0   \n",
       "2        -0.217428        1  ...            0.0            0.0        1.0   \n",
       "3        -0.217428        1  ...            0.0            0.0        1.0   \n",
       "4        -0.217428        1  ...            0.0            0.0        1.0   \n",
       "...            ...      ...  ...            ...            ...        ...   \n",
       "12734219 -0.218333        1  ...            0.0            1.0        0.0   \n",
       "12734220 -0.218333        1  ...            0.0            1.0        0.0   \n",
       "12734221 -0.218333        1  ...            0.0            1.0        0.0   \n",
       "12734222 -0.218333        1  ...            0.0            1.0        0.0   \n",
       "12734223 -0.218333        1  ...            0.0            1.0        0.0   \n",
       "\n",
       "          year_2018  year_2019  year_2020  year_2021  year_2022  year_2023  \\\n",
       "0               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4               0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "...             ...        ...        ...        ...        ...        ...   \n",
       "12734219        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "12734220        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "12734221        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "12734222        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "12734223        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "          year_2024  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "...             ...  \n",
       "12734219        1.0  \n",
       "12734220        1.0  \n",
       "12734221        1.0  \n",
       "12734222        1.0  \n",
       "12734223        1.0  \n",
       "\n",
       "[12734224 rows x 66 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sanity_check(data_path):\n",
    "    \"\"\"\n",
    "    Perform sanity checks on the processed theme park data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_path : str\n",
    "        Path to the processed parquet file\n",
    "    \"\"\"\n",
    "    print(\"Loading processed data...\")\n",
    "    df = pd.read_parquet(data_path)\n",
    "    \n",
    "    print(f\"\\n==== Basic Information ====\")\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "    \n",
    "    # Check 1: Missing values\n",
    "    print(\"\\n==== Check 1: Missing Values ====\")\n",
    "    missing = df.isna().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(f\"Warning: Missing values found!\")\n",
    "        print(missing[missing > 0])\n",
    "    else:\n",
    "        print(\"✓ No missing values found\")\n",
    "    \n",
    "    # Check 2: Feature ranges\n",
    "    print(\"\\n==== Check 2: Feature Ranges ====\")\n",
    "    \n",
    "    # Cyclical features should be between -1 and 1\n",
    "    cyclical_cols = [col for col in df.columns if col.endswith('_sin') or col.endswith('_cos')]\n",
    "    for col in cyclical_cols:\n",
    "        min_val, max_val = df[col].min(), df[col].max()\n",
    "        if min_val < -1.1 or max_val > 1.1:  # allow small floating point errors\n",
    "            print(f\"Warning: {col} range is [{min_val:.2f}, {max_val:.2f}], expected [-1, 1]\")\n",
    "        else:\n",
    "            print(f\"✓ {col} is within expected range [-1, 1]\")\n",
    "    \n",
    "    # One-hot encoded features should be 0 or 1\n",
    "    one_hot_cols = [\n",
    "        col for col in df.columns if \n",
    "        col.startswith('ride_name_') or \n",
    "        col.startswith('part_of_day_') or\n",
    "        col.startswith('season_')\n",
    "    ]\n",
    "    \n",
    "    for col in one_hot_cols:\n",
    "        unique_vals = df[col].unique()\n",
    "        if not np.all(np.isin(unique_vals, [0, 1])):\n",
    "            print(f\"Warning: {col} contains values other than 0 and 1: {unique_vals}\")\n",
    "        else:\n",
    "            print(f\"✓ {col} contains only 0 and 1 as expected\")\n",
    "    \n",
    "    # Boolean features should be 0 or 1\n",
    "    bool_cols = ['closed', 'is_german_holiday', 'is_swiss_holiday', 'is_french_holiday', 'is_weekend']\n",
    "    bool_cols = [col for col in bool_cols if col in df.columns]\n",
    "    \n",
    "    for col in bool_cols:\n",
    "        unique_vals = df[col].unique()\n",
    "        if not np.all(np.isin(unique_vals, [0, 1])):\n",
    "            print(f\"Warning: {col} contains values other than 0 and 1: {unique_vals}\")\n",
    "        else:\n",
    "            print(f\"✓ {col} contains only 0 and 1 as expected\")\n",
    "    \n",
    "    # Check 3: Consistency checks\n",
    "    print(\"\\n==== Check 3: Consistency Checks ====\")\n",
    "    \n",
    "    # Weekday features should be consistent with is_weekend\n",
    "    if 'weekday' in df.columns and 'is_weekend' in df.columns:\n",
    "        weekend_mask = df['weekday'] >= 5\n",
    "        is_weekend_mask = df['is_weekend'] == 1\n",
    "        \n",
    "        if (weekend_mask != is_weekend_mask).sum() > 0:\n",
    "            print(f\"Warning: 'weekday' and 'is_weekend' are inconsistent in {(weekend_mask != is_weekend_mask).sum()} rows\")\n",
    "        else:\n",
    "            print(\"✓ 'weekday' and 'is_weekend' are consistent\")\n",
    "    \n",
    "    # Ride names should sum to 1 for each row (one ride per observation)\n",
    "    ride_cols = [col for col in df.columns if col.startswith('ride_name_')]\n",
    "    ride_sums = df[ride_cols].sum(axis=1)\n",
    "    \n",
    "    if not np.all(ride_sums == 1):\n",
    "        print(f\"Warning: Some rows have {(ride_sums != 1).sum()} ride assignments that don't sum to 1\")\n",
    "        print(f\"Min: {ride_sums.min()}, Max: {ride_sums.max()}\")\n",
    "    else:\n",
    "        print(\"✓ Each observation has exactly one ride assigned\")\n",
    "    \n",
    "    # Part of day should sum to 1 for each row\n",
    "    part_of_day_cols = [col for col in df.columns if col.startswith('part_of_day_')]\n",
    "    part_of_day_sums = df[part_of_day_cols].sum(axis=1)\n",
    "    \n",
    "    if not np.all(part_of_day_sums == 1):\n",
    "        print(f\"Warning: Some rows have part_of_day assignments that don't sum to 1\")\n",
    "        print(f\"Min: {part_of_day_sums.min()}, Max: {part_of_day_sums.max()}\")\n",
    "    else:\n",
    "        print(\"✓ Each observation has exactly one part_of_day assigned\")\n",
    "    \n",
    "    # Season should sum to 1 for each row\n",
    "    season_cols = [col for col in df.columns if col.startswith('season_')]\n",
    "    season_sums = df[season_cols].sum(axis=1)\n",
    "    \n",
    "    if not np.all(season_sums == 1):\n",
    "        print(f\"Warning: Some rows have season assignments that don't sum to 1\")\n",
    "        print(f\"Min: {season_sums.min()}, Max: {season_sums.max()}\")\n",
    "    else:\n",
    "        print(\"✓ Each observation has exactly one season assigned\")\n",
    "    \n",
    "    # Check 4: Scaled numerical features\n",
    "    print(\"\\n==== Check 4: Scaled Numerical Features ====\")\n",
    "    num_cols = ['temperature', 'rain', 'wind', 'year']\n",
    "    num_cols = [col for col in num_cols if col in df.columns]\n",
    "    \n",
    "    for col in num_cols:\n",
    "        mean, std = df[col].mean(), df[col].std()\n",
    "        if abs(mean) > 0.1 or abs(std - 1) > 0.1:\n",
    "            print(f\"Warning: {col} may not be properly scaled. Mean: {mean:.4f}, Std: {std:.4f}\")\n",
    "        else:\n",
    "            print(f\"✓ {col} appears properly scaled (mean ≈ 0, std ≈ 1)\")\n",
    "    \n",
    "    # Check 5: Correlations between cyclical features\n",
    "    print(\"\\n==== Check 5: Cyclical Feature Correlations ====\")\n",
    "    for base in ['month', 'hour', 'weekday', 'minute']:\n",
    "        sin_col = f'{base}_sin'\n",
    "        cos_col = f'{base}_cos'\n",
    "        \n",
    "        if sin_col in df.columns and cos_col in df.columns:\n",
    "            corr = df[sin_col].corr(df[cos_col])\n",
    "            if abs(corr) > 0.1:\n",
    "                print(f\"Warning: Correlation between {sin_col} and {cos_col} is {corr:.4f}, expected near 0\")\n",
    "            else:\n",
    "                print(f\"✓ {sin_col} and {cos_col} have low correlation as expected\")\n",
    "    \n",
    "    # Check 6: Wait time distribution\n",
    "    if 'wait_time' in df.columns:\n",
    "        print(\"\\n==== Check 6: Wait Time Distribution ====\")\n",
    "        wait_time = df['wait_time']\n",
    "        print(f\"Wait time min: {wait_time.min()}, mean: {wait_time.mean():.2f}, max: {wait_time.max()}\")\n",
    "        \n",
    "        if wait_time.min() < 0:\n",
    "            print(f\"Warning: Negative wait times found: {wait_time[wait_time < 0].count()} values\")\n",
    "        \n",
    "        # Check for extreme outliers (> 5 std from mean)\n",
    "        mean, std = wait_time.mean(), wait_time.std()\n",
    "        outliers = wait_time[(wait_time > mean + 5*std) | (wait_time < mean - 5*std)]\n",
    "        if len(outliers) > 0:\n",
    "            print(f\"Warning: {len(outliers)} extreme wait time outliers found\")\n",
    "            print(f\"Outlier values: {sorted(outliers.unique())}\")\n",
    "        else:\n",
    "            print(\"✓ No extreme outliers in wait times\")\n",
    "    \n",
    "    # Check 7: Closed rides should have wait time 0 or NaN\n",
    "    if 'closed' in df.columns and 'wait_time' in df.columns:\n",
    "        print(\"\\n==== Check 7: Closed Rides and Wait Times ====\")\n",
    "        closed_rides = df[df['closed'] == 1]\n",
    "        if len(closed_rides) > 0:\n",
    "            invalid_waits = closed_rides[(closed_rides['wait_time'] > 0) & (~closed_rides['wait_time'].isna())]\n",
    "            if len(invalid_waits) > 0:\n",
    "                print(f\"Warning: {len(invalid_waits)} closed rides have wait times > 0\")\n",
    "                print(f\"Example: {invalid_waits[['wait_time']].head()}\")\n",
    "            else:\n",
    "                print(\"✓ All closed rides have wait time 0 or NaN as expected\")\n",
    "        else:\n",
    "            print(\"No closed rides in the dataset\")\n",
    "    \n",
    "    # Check 8: inspection of cyclical features\n",
    "    print(\"\\n==== Check 8: Inspection of Cyclical Features ====\")\n",
    "\n",
    "    cyclical_pairs = []\n",
    "    for base in ['month', 'hour', 'weekday']:\n",
    "        if f'{base}_sin' in df.columns and f'{base}_cos' in df.columns:\n",
    "            cyclical_pairs.append((base, f'{base}_sin', f'{base}_cos'))\n",
    "    \n",
    "    print(f\"Cyclical encodings should form circular patterns when sin/cos components are plotted against each other\")\n",
    "    for base, sin_col, cos_col in cyclical_pairs:\n",
    "        circle_check = np.sqrt(df[sin_col]**2 + df[cos_col]**2)\n",
    "        if (abs(circle_check - 1) > 0.1).any():\n",
    "            print(f\"Warning: {base} cyclical encoding doesn't maintain unit circle (sin²+cos²=1)\")\n",
    "            print(f\"Min: {circle_check.min():.4f}, Max: {circle_check.max():.4f}\")\n",
    "        else:\n",
    "            print(f\"✓ {base} cyclical encoding maintains unit circle property\")\n",
    "\n",
    "    print(\"\\n==== Summary ====\")\n",
    "    print(\"Sanity check complete. Review the warnings above if any.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "sanity_check(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af549b5",
   "metadata": {},
   "source": [
    "### Explanation for Warning\n",
    "- Warning: Correlation between month_sin and month_cos is -0.2893, expected near 0\n",
    "    - A perfect -1.0 correlation between sin and cos components typically happens when the values are concentrated at specific points (like only 0, 15, 30, 45 minutes). This is the case in the bucket variant\n",
    "- Warning: Correlation between hour_sin and hour_cos is -0.6495, expected near 0\n",
    "    - This happens because most data points are from 10 AM to 6 PM, this creates a correlation\n",
    "- Warning: Correlation between minute_sin and minute_cos is -1.0000, expected near 0\n",
    "    - Seasonality in the data - the park has have more data points from certain months. Also we dropped 3 months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b3fba5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspro2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
