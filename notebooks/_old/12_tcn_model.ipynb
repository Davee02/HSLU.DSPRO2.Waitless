{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2508ec3f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b078514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from pytorch_tcn import TCN\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a4def4",
   "metadata": {},
   "source": [
    "# Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64199a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926905b7",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482636e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y, seq_length):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.seq_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get sequence of features\n",
    "        X_seq = self.X[idx:idx + self.seq_length]\n",
    "        # Get target value (next value after sequence)\n",
    "        y_value = self.y[idx + self.seq_length]\n",
    "        \n",
    "        return torch.FloatTensor(X_seq), torch.FloatTensor([y_value])\n",
    "    \n",
    "\n",
    "\n",
    "class TCNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout=0.2):\n",
    "        super(TCNModel, self).__init__()\n",
    "        \n",
    "\n",
    "        self.tcn = TCN(\n",
    "            num_inputs=input_size,         \n",
    "            num_channels=[num_channels] * 8,  # (number of filters  in each convolutional layer)\n",
    "            kernel_size=kernel_size,        # (temporal receptive field)\n",
    "            dropout=dropout,                \n",
    "            causal=True,                    # Causal convolutions (dont look into future)\n",
    "            use_skip_connections=True       # Use skip connections for better gradient flow\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.linear = nn.Linear(num_channels, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input shape: [batch_size, seq_len, input_size]\n",
    "        # TCN expects shape: [batch_size, input_size, seq_len]\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # Apply TCN - output will be [batch_size, num_channels, seq_len]\n",
    "        y = self.tcn(x)\n",
    "        \n",
    "        # Get the last time step output and apply the linear layer\n",
    "        y = y[:, :, -1]\n",
    "        \n",
    "        return self.linear(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2fe347",
   "metadata": {},
   "source": [
    "# Helperfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d50bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(df, target_ride=None):\n",
    "    \"\"\"\n",
    "    Preprocess the data for a single ride\n",
    "    \"\"\"\n",
    "    # Drop time_bucket column as not needed\n",
    "    if 'time_bucket' in df.columns:\n",
    "        df = df.drop(columns=['time_bucket'])\n",
    "    \n",
    "    print(f\"Building model for ride: {target_ride}\")\n",
    "    \n",
    "\n",
    "    ride_col = f'ride_name_{target_ride}'\n",
    "    if ride_col in df.columns:\n",
    "        df = df[df[ride_col] == 1].copy()\n",
    "    \n",
    "    ride_cols = [col for col in df.columns if col.startswith('ride_name_')]\n",
    "    df = df.drop(columns=ride_cols)\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Create features for the model\n",
    "    \"\"\"\n",
    "    # The features are everything except wait_time (target)\n",
    "    feature_cols = [col for col in df.columns if col != 'wait_time' and col != \"timestamp\"]\n",
    "    \n",
    "    return df, feature_cols\n",
    "\n",
    "def build_linear_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Build and train a linear regression model\n",
    "    \"\"\"\n",
    "\n",
    "    model = GradientBoostingRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=5,\n",
    "            random_state=42\n",
    "     )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "        \n",
    "    #from sklearn.linear_model import LinearRegression\n",
    "    #model = LinearRegression()\n",
    "    #model.fit(X_train, y_train)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43011db",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb7f6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_wandb(config=None):\n",
    "    run = wandb.init(config=config)\n",
    "    config = wandb.config\n",
    "    \n",
    "    data_path = config.data_path\n",
    "    splits_output_dir = config.splits_output_dir\n",
    "    target_ride = config.target_ride\n",
    "    seq_length = config.seq_length\n",
    "    batch_size = config.batch_size\n",
    "    num_channels = config.num_channels\n",
    "    kernel_size = config.kernel_size\n",
    "    dropout = config.dropout\n",
    "    learning_rate = config.learning_rate\n",
    "    epochs = config.epochs\n",
    "    \n",
    "    # Add scheduler parameters\n",
    "    scheduler_type = config.get('scheduler_type', 'CosineAnnealingLR')  # Default to CosineAnnealingLR\n",
    "    t_max = config.get('t_max', epochs)  # Default to total epochs\n",
    "    eta_min = config.get('eta_min', 1e-6)  # Minimum learning rate\n",
    "    \n",
    "    df = pd.read_parquet(data_path)\n",
    "    \n",
    "    df = preprocess_data(df, target_ride)\n",
    "    \n",
    "    train_indices = pd.read_parquet(os.path.join(splits_output_dir, \"train_indices.parquet\"))\n",
    "    val_indices = pd.read_parquet(os.path.join(splits_output_dir, \"validation_indices.parquet\"))\n",
    "    test_indices = pd.read_parquet(os.path.join(splits_output_dir, \"test_indices.parquet\"))\n",
    "    \n",
    "    ride_name_normalized = target_ride.replace(' ', '_')\n",
    "    train_indices = train_indices[train_indices['ride_name'] == ride_name_normalized]['original_index'].values\n",
    "    val_indices = val_indices[val_indices['ride_name'] == ride_name_normalized]['original_index'].values\n",
    "    test_indices = test_indices[test_indices['ride_name'] == ride_name_normalized]['original_index'].values\n",
    "    \n",
    "    if len(train_indices) == 0 or len(val_indices) == 0 or len(test_indices) == 0:\n",
    "        raise ValueError(f\"No indices found for ride {target_ride}. Check ride name or indices files.\")\n",
    "    \n",
    "    print(f\"Found {len(train_indices)} train, {len(val_indices)} validation, and {len(test_indices)} test samples\")\n",
    "    \n",
    "    df, feature_cols = create_features(df)\n",
    "    \n",
    "    train_df = df.iloc[train_indices].copy()\n",
    "    val_df = df.iloc[val_indices].copy()\n",
    "    test_df = df.iloc[test_indices].copy()\n",
    "        \n",
    "    # Prepare features and target\n",
    "    X_train = train_df[feature_cols].values\n",
    "    y_train = train_df['wait_time'].values\n",
    "    X_val = val_df[feature_cols].values\n",
    "    y_val = val_df['wait_time'].values\n",
    "    X_test = test_df[feature_cols].values\n",
    "    y_test = test_df['wait_time'].values\n",
    "    \n",
    "    linear_model = build_linear_model(X_train, y_train)\n",
    "    \n",
    "    # Get predictions from linear model\n",
    "    y_train_pred_linear = linear_model.predict(X_train)\n",
    "    y_val_pred_linear = linear_model.predict(X_val)\n",
    "    y_test_pred_linear = linear_model.predict(X_test)\n",
    "    \n",
    "    # Calculate residuals (actual - predicted)\n",
    "    train_residuals = y_train - y_train_pred_linear\n",
    "    val_residuals = y_val - y_val_pred_linear\n",
    "    test_residuals = y_test - y_test_pred_linear\n",
    "    \n",
    "    train_dataset = TimeSeriesDataset(X_train, train_residuals, seq_length)\n",
    "    val_dataset = TimeSeriesDataset(X_val, val_residuals, seq_length)\n",
    "    test_dataset = TimeSeriesDataset(X_test, test_residuals, seq_length)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    input_size = X_train.shape[1]  # Number of features\n",
    "    output_size = 1  # Predicting a single value (residual)\n",
    "    \n",
    "    tcn_model = TCNModel(\n",
    "        input_size=input_size,\n",
    "        output_size=output_size,\n",
    "        num_channels=num_channels,\n",
    "        kernel_size=kernel_size,\n",
    "        dropout=dropout\n",
    "    )\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(tcn_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Add the learning rate scheduler\n",
    "    from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "    scheduler = CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=t_max,\n",
    "        eta_min=eta_min\n",
    "    )\n",
    "    \n",
    "    tcn_model.to(device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    best_model = None\n",
    "    patience = config.patience\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        tcn_model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = tcn_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Step the scheduler after each epoch\n",
    "        scheduler.step()\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        \n",
    "        tcn_model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = tcn_model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"epoch\": epoch,\n",
    "            \"learning_rate\": current_lr  # Log the current learning rate\n",
    "        })\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} - Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}, LR: {current_lr:.6f}')\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = tcn_model.state_dict().copy()\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    if best_model is not None:\n",
    "        tcn_model.load_state_dict(best_model)\n",
    "    \n",
    "    # Model evaluation on test set\n",
    "    tcn_model.to(torch.device(\"cpu\"))\n",
    "    tcn_model.eval()\n",
    "    \n",
    "    # Get TCN predictions on test data\n",
    "    all_tcn_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, _) in enumerate(test_loader):\n",
    "            outputs = tcn_model(inputs)\n",
    "            all_tcn_preds.extend(outputs.numpy().flatten())\n",
    "    \n",
    "    # Get the corresponding test data (accounting for sequence length)\n",
    "    y_test_seq_linear = y_test_pred_linear[seq_length:][:len(all_tcn_preds)]\n",
    "    y_test_seq_actual = y_test[seq_length:][:len(all_tcn_preds)]\n",
    "    \n",
    "    test_eval_df = test_df.iloc[seq_length:].reset_index(drop=True).iloc[:len(all_tcn_preds)].copy()\n",
    "    test_eval_df['linear_pred'] = y_test_seq_linear\n",
    "    test_eval_df['tcn_pred'] = all_tcn_preds\n",
    "    test_eval_df['combined_pred'] = y_test_seq_linear + np.array(all_tcn_preds)\n",
    "    \n",
    "    # Filter out rows where closed = 1\n",
    "    if 'closed' in test_eval_df.columns:\n",
    "        print(f\"\\nExcluding {test_eval_df['closed'].sum()} data points where ride is closed from evaluation\")\n",
    "        open_ride_df = test_eval_df[test_eval_df['closed'] == 0]\n",
    "    else:\n",
    "        print(\"Warning: 'closed' column not found in the data. Evaluating on all test data.\")\n",
    "        open_ride_df = test_eval_df\n",
    "    \n",
    "    y_test_open_actual = open_ride_df['wait_time'].values\n",
    "    y_test_open_linear = open_ride_df['linear_pred'].values\n",
    "    y_test_open_combined = open_ride_df['combined_pred'].values\n",
    "\n",
    "    linear_mae = mean_absolute_error(y_test_open_actual, y_test_open_linear)\n",
    "    linear_mse = mean_squared_error(y_test_open_actual, y_test_open_linear)\n",
    "    linear_rmse = np.sqrt(linear_mse)\n",
    "    linear_r2 = r2_score(y_test_open_actual, y_test_open_linear)\n",
    "    \n",
    "    combined_mae = mean_absolute_error(y_test_open_actual, y_test_open_combined)\n",
    "    combined_mse = mean_squared_error(y_test_open_actual, y_test_open_combined)\n",
    "    combined_rmse = np.sqrt(combined_mse)\n",
    "    combined_r2 = r2_score(y_test_open_actual, y_test_open_combined)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"linear_mae\": linear_mae,\n",
    "        \"combined_mae\": combined_mae,\n",
    "        \"combined_rmse\": combined_rmse,\n",
    "        \"combined_r2\": combined_r2,\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "    })\n",
    "    \n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    linear_model_filename = f\"{target_ride.replace(' ', '_')}_linear_model.pkl\"\n",
    "    tcn_model_filename = f\"{target_ride.replace(' ', '_')}_tcn_model.pt\"\n",
    "    \n",
    "    with open(f\"models/{linear_model_filename}\", \"wb\") as f:\n",
    "        pickle.dump(linear_model, f)\n",
    "    \n",
    "    torch.save(tcn_model.state_dict(), f\"models/{tcn_model_filename}\")\n",
    "\n",
    "    linear_artifact = wandb.Artifact(f\"linear_model_{wandb.run.id}\", type=\"model\")\n",
    "    linear_artifact.add_file(f\"models/{linear_model_filename}\")\n",
    "    wandb.log_artifact(linear_artifact)\n",
    "    \n",
    "    tcn_artifact = wandb.Artifact(f\"tcn_model_{wandb.run.id}\", type=\"model\")\n",
    "    tcn_artifact.add_file(f\"models/{tcn_model_filename}\")\n",
    "    wandb.log_artifact(tcn_artifact)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "def setup_wandb_sweep(project_name=\"waitless-hslu-dspro2-fs25\", entity=\"waitless-hslu-dspro2-fs25\"):\n",
    "    sweep_config = {\n",
    "        'method': 'bayes',  # Bayesian optimization\n",
    "        'metric': {\n",
    "            'name': 'combined_mae',  # Metric to optimize\n",
    "            'goal': 'minimize'  # We want to minimize RMSE\n",
    "        },\n",
    "        'parameters': {\n",
    "            'seq_length': {\n",
    "                'values': [24, 48, 96, 192, 384] \n",
    "            },\n",
    "            'batch_size': {\n",
    "                'values': [128, 256, 512, 1048] \n",
    "            },\n",
    "            'num_channels': {\n",
    "                'values': [32, 64, 128, 256] \n",
    "            },\n",
    "            'kernel_size': {\n",
    "                'values': [2, 3, 5, 8] \n",
    "            },\n",
    "            'dropout': {\n",
    "                'values': [0.1, 0.2, 0.3]  \n",
    "            },\n",
    "            'learning_rate': {\n",
    "                'values': [1e-3, 10**-3.5, 1e-4, 10**-4.5, 1e-5]  \n",
    "            },\n",
    "            'epochs': {\n",
    "                'value': 100 \n",
    "            },\n",
    "            'patience': {\n",
    "                'value': 10  \n",
    "            },\n",
    "            'scheduler_type': {\n",
    "                'value': 'CosineAnnealingLR'  \n",
    "            },\n",
    "            't_max': {\n",
    "                'values': [10, 25, 50, 100]  \n",
    "            },\n",
    "            'eta_min': {\n",
    "                'values': [0, 1e-7, 1e-6]  # learning rate will follow a cosine curve from the initial learning rate to eta_min over T_max epochs\n",
    "            },\n",
    "            'data_path': {\n",
    "                'value': '../data/processed/ep/rides/poseidon.parquet' \n",
    "            },\n",
    "            'splits_output_dir': {\n",
    "                'value': '../data/processed/splits' \n",
    "            },\n",
    "            'target_ride': {\n",
    "                'value': 'poseidon' \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    sweep_id = wandb.sweep(sweep_config, project=project_name, entity=entity)\n",
    "    return sweep_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaikotrede\u001b[0m (\u001b[33mmaikotrede-hochschule-luzern\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: cbguxinw\n",
      "Sweep URL: https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/sweeps/cbguxinw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ihxhk0gy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: ../data/processed/ep/rides/poseidon.parquet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teta_min: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_channels: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_type: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_length: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplits_output_dir: ../data/processed/splits\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tt_max: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_ride: poseidon\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaikotrede\u001b[0m (\u001b[33mwaitless-hslu-dspro2-fs25\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/maiko/Documents/HSLU/DSPRO2/HSLU.DSPRO2.Waitless/notebooks/wandb/run-20250525_202041-ihxhk0gy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/runs/ihxhk0gy' target=\"_blank\">snowy-sweep-1</a></strong> to <a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/sweeps/cbguxinw' target=\"_blank\">https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/sweeps/cbguxinw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25' target=\"_blank\">https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/sweeps/cbguxinw' target=\"_blank\">https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/sweeps/cbguxinw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/runs/ihxhk0gy' target=\"_blank\">https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/runs/ihxhk0gy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model for ride: poseidon\n",
      "Found 190333 train, 43138 validation, and 38050 test samples\n",
      "Epoch 1/100 - Train loss: 8.6087, Val loss: 10.0373, LR: 0.000999\n",
      "Epoch 2/100 - Train loss: 7.9839, Val loss: 9.7861, LR: 0.000996\n",
      "Epoch 3/100 - Train loss: 7.5825, Val loss: 9.3961, LR: 0.000991\n",
      "Epoch 4/100 - Train loss: 7.2454, Val loss: 8.8069, LR: 0.000984\n",
      "Epoch 5/100 - Train loss: 6.9013, Val loss: 9.3143, LR: 0.000976\n",
      "Epoch 6/100 - Train loss: 6.7309, Val loss: 9.3118, LR: 0.000965\n",
      "Epoch 7/100 - Train loss: 6.4160, Val loss: 8.9895, LR: 0.000952\n",
      "Epoch 8/100 - Train loss: 6.1270, Val loss: 9.5060, LR: 0.000938\n",
      "Epoch 9/100 - Train loss: 5.8700, Val loss: 9.7607, LR: 0.000922\n",
      "Epoch 10/100 - Train loss: 5.6879, Val loss: 9.4333, LR: 0.000905\n",
      "Epoch 11/100 - Train loss: 5.4467, Val loss: 8.9909, LR: 0.000885\n",
      "Epoch 12/100 - Train loss: 5.2432, Val loss: 9.3258, LR: 0.000864\n",
      "Epoch 13/100 - Train loss: 4.9397, Val loss: 9.4802, LR: 0.000842\n",
      "Epoch 14/100 - Train loss: 4.7155, Val loss: 9.2557, LR: 0.000819\n",
      "Early stopping at epoch 14\n",
      "\n",
      "Excluding 34145 data points where ride is closed from evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>▁</td></tr><tr><td>combined_mae</td><td>▁</td></tr><tr><td>combined_r2</td><td>▁</td></tr><tr><td>combined_rmse</td><td>▁</td></tr><tr><td>epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>learning_rate</td><td>███▇▇▇▆▆▅▄▄▃▂▁</td></tr><tr><td>linear_mae</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>val_loss</td><td>█▇▄▁▄▄▂▅▆▅▂▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_loss</td><td>8.8069</td></tr><tr><td>combined_mae</td><td>6.49438</td></tr><tr><td>combined_r2</td><td>0.66031</td></tr><tr><td>combined_rmse</td><td>9.81331</td></tr><tr><td>epoch</td><td>13</td></tr><tr><td>learning_rate</td><td>0.00082</td></tr><tr><td>linear_mae</td><td>6.58764</td></tr><tr><td>train_loss</td><td>4.7155</td></tr><tr><td>val_loss</td><td>9.25571</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">snowy-sweep-1</strong> at: <a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/runs/ihxhk0gy' target=\"_blank\">https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/runs/ihxhk0gy</a><br> View project at: <a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25' target=\"_blank\">https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25</a><br>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250525_202041-ihxhk0gy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hl4xx63y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_path: ../data/processed/ep/rides/poseidon.parquet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teta_min: 1e-07\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_channels: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_type: CosineAnnealingLR\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_length: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsplits_output_dir: ../data/processed/splits\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tt_max: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_ride: poseidon\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/maiko/Documents/HSLU/DSPRO2/HSLU.DSPRO2.Waitless/notebooks/wandb/run-20250525_203039-hl4xx63y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/runs/hl4xx63y' target=\"_blank\">unique-sweep-2</a></strong> to <a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/sweeps/cbguxinw' target=\"_blank\">https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/sweeps/cbguxinw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25' target=\"_blank\">https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/sweeps/cbguxinw' target=\"_blank\">https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/sweeps/cbguxinw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/runs/hl4xx63y' target=\"_blank\">https://wandb.ai/waitless-hslu-dspro2-fs25/waitless-tcn-hslu-dspro2-fs25/runs/hl4xx63y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model for ride: poseidon\n",
      "Found 190333 train, 43138 validation, and 38050 test samples\n",
      "Epoch 1/100 - Train loss: 8.8674, Val loss: 10.3797, LR: 0.000010\n",
      "Epoch 2/100 - Train loss: 8.5418, Val loss: 10.3329, LR: 0.000010\n",
      "Epoch 3/100 - Train loss: 8.4718, Val loss: 10.3179, LR: 0.000010\n",
      "Epoch 4/100 - Train loss: 8.4264, Val loss: 10.3085, LR: 0.000010\n",
      "Epoch 5/100 - Train loss: 8.4211, Val loss: 10.3107, LR: 0.000010\n",
      "Epoch 6/100 - Train loss: 8.3936, Val loss: 10.3041, LR: 0.000010\n",
      "Epoch 7/100 - Train loss: 8.3800, Val loss: 10.3042, LR: 0.000010\n",
      "Epoch 8/100 - Train loss: 8.3742, Val loss: 10.2950, LR: 0.000009\n",
      "Epoch 9/100 - Train loss: 8.3730, Val loss: 10.2940, LR: 0.000009\n",
      "Epoch 10/100 - Train loss: 8.3595, Val loss: 10.2918, LR: 0.000009\n",
      "Epoch 11/100 - Train loss: 8.3521, Val loss: 10.2875, LR: 0.000009\n",
      "Epoch 12/100 - Train loss: 8.3539, Val loss: 10.2922, LR: 0.000009\n",
      "Epoch 13/100 - Train loss: 8.3453, Val loss: 10.2760, LR: 0.000008\n",
      "Epoch 14/100 - Train loss: 8.3396, Val loss: 10.2771, LR: 0.000008\n",
      "Epoch 15/100 - Train loss: 8.3348, Val loss: 10.2723, LR: 0.000008\n",
      "Epoch 16/100 - Train loss: 8.3338, Val loss: 10.2765, LR: 0.000008\n",
      "Epoch 17/100 - Train loss: 8.3404, Val loss: 10.2661, LR: 0.000007\n",
      "Epoch 18/100 - Train loss: 8.3330, Val loss: 10.2662, LR: 0.000007\n",
      "Epoch 19/100 - Train loss: 8.3216, Val loss: 10.2604, LR: 0.000007\n",
      "Epoch 20/100 - Train loss: 8.3351, Val loss: 10.2546, LR: 0.000007\n",
      "Epoch 21/100 - Train loss: 8.3211, Val loss: 10.2480, LR: 0.000006\n"
     ]
    }
   ],
   "source": [
    "\n",
    "project_name = \"waitless-tcn-hslu-dspro2-fs25\"\n",
    "entity = \"waitless-hslu-dspro2-fs25\" \n",
    "wandb.login()\n",
    "sweep_id = setup_wandb_sweep(project_name=project_name, entity=entity)\n",
    "wandb.agent(sweep_id, train_with_wandb, count=10)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d60f4",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2bc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run: mild-sweep-1, combined_mae: 6.421060816451057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model for ride: poseidon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maiko/miniconda3/envs/dspro2/lib/python3.9/site-packages/torch/_weights_only_unpickler.py:549: UserWarning: Detected pickle protocol 4 in the checkpoint, which was not the default pickle protocol used by `torch.load` (2). The weights_only Unpickler might not support all instructions implemented by this protocol, please file an issue for adding support if you encounter this.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 149\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 185\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not create plot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[43mevaluate_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 114\u001b[0m, in \u001b[0;36mevaluate_best_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m tcn_model \u001b[38;5;241m=\u001b[39m TCNModel(\n\u001b[1;32m    106\u001b[0m     input_size\u001b[38;5;241m=\u001b[39minput_size,\n\u001b[1;32m    107\u001b[0m     output_size\u001b[38;5;241m=\u001b[39moutput_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m     dropout\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Load the state dict\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m tcn_model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtcn_model_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    115\u001b[0m tcn_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    116\u001b[0m tcn_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/miniconda3/envs/dspro2/lib/python3.9/site-packages/torch/serialization.py:1548\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(\n\u001b[1;32m   1542\u001b[0m             opened_file,\n\u001b[1;32m   1543\u001b[0m             map_location,\n\u001b[1;32m   1544\u001b[0m             _weights_only_unpickler,\n\u001b[1;32m   1545\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1546\u001b[0m         )\n\u001b[1;32m   1547\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1548\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(\n\u001b[1;32m   1550\u001b[0m     opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args\n\u001b[1;32m   1551\u001b[0m )\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 149\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def evaluate_best_model():\n",
    "    # Initialize wandb\n",
    "    api = wandb.Api()\n",
    "    \n",
    "    # Get the project and find the best run based on combined_mae metric\n",
    "    project = api.project(\"maikotrede-hochschule-luzern/queue-prediction-sweeps\")\n",
    "    runs = api.runs(\"maikotrede-hochschule-luzern/queue-prediction-sweeps\")\n",
    "    \n",
    "    # Find the best run with the lowest combined_mae\n",
    "    best_run = None\n",
    "    best_mae = float('inf')\n",
    "    \n",
    "    for run in runs:\n",
    "        if run.state == \"finished\" and \"combined_mae\" in run.summary:\n",
    "            mae = run.summary[\"combined_mae\"]\n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                best_run = run\n",
    "    \n",
    "    if best_run is None:\n",
    "        print(\"Could not find any completed runs with combined_mae metric\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Best run: {best_run.name}, combined_mae: {best_mae}\")\n",
    "    \n",
    "    # Get the config from the best run\n",
    "    config = best_run.config\n",
    "    \n",
    "    # Download the artifacts for the best run\n",
    "    linear_artifacts = best_run.logged_artifacts()\n",
    "    linear_model_artifact = None\n",
    "    tcn_model_artifact = None\n",
    "    \n",
    "    for artifact in linear_artifacts:\n",
    "        if \"linear_model\" in artifact.name:\n",
    "            linear_model_artifact = artifact\n",
    "        elif \"tcn_model\" in artifact.name:\n",
    "            tcn_model_artifact = artifact\n",
    "    \n",
    "    if linear_model_artifact is None or tcn_model_artifact is None:\n",
    "        print(\"Could not find model artifacts\")\n",
    "        return\n",
    "    \n",
    "    # Download artifacts\n",
    "    os.makedirs(\"downloaded_models\", exist_ok=True)\n",
    "    linear_model_path = linear_model_artifact.download(\"downloaded_models\")\n",
    "    tcn_model_path = tcn_model_artifact.download(\"downloaded_models\")\n",
    "    \n",
    "    # Load models\n",
    "    linear_model_file = os.path.join(linear_model_path, os.listdir(linear_model_path)[0])\n",
    "    tcn_model_file = os.path.join(tcn_model_path, os.listdir(tcn_model_path)[0])\n",
    "    \n",
    "    with open(linear_model_file, \"rb\") as f:\n",
    "        linear_model = pickle.load(f)\n",
    "    \n",
    "    # Load data\n",
    "    data_path = config[\"data_path\"]\n",
    "    splits_output_dir = config[\"splits_output_dir\"]\n",
    "    target_ride = config[\"target_ride\"]\n",
    "    seq_length = config[\"seq_length\"]\n",
    "    batch_size = config.get(\"batch_size\", 256)\n",
    "    \n",
    "    # Load and prepare test data\n",
    "    df = pd.read_parquet(data_path)\n",
    "    df = preprocess_data(df, target_ride)\n",
    "    \n",
    "    test_indices = pd.read_parquet(os.path.join(splits_output_dir, \"test_indices.parquet\"))\n",
    "    \n",
    "    ride_name_normalized = target_ride.replace(' ', '_')\n",
    "    test_indices = test_indices[test_indices['ride_name'] == ride_name_normalized]['original_index'].values\n",
    "    \n",
    "    df, feature_cols = create_features(df)\n",
    "    test_df = df.iloc[test_indices].copy()\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X_test = test_df[feature_cols].values\n",
    "    y_test = test_df['wait_time'].values\n",
    "    \n",
    "    # Get predictions from linear model\n",
    "    y_test_pred_linear = linear_model.predict(X_test)\n",
    "    \n",
    "    # Calculate residuals (actual - predicted)\n",
    "    test_residuals = y_test - y_test_pred_linear\n",
    "    \n",
    "    # Create dataset for TCN model\n",
    "    test_dataset = TimeSeriesDataset(X_test, test_residuals, seq_length)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Initialize TCN model with the same architecture\n",
    "    input_size = X_test.shape[1]\n",
    "    output_size = 1\n",
    "    \n",
    "    tcn_model = TCNModel(\n",
    "        input_size=input_size,\n",
    "        output_size=output_size,\n",
    "        num_channels=config[\"num_channels\"],\n",
    "        kernel_size=config[\"kernel_size\"],\n",
    "        dropout=config[\"dropout\"]\n",
    "    )\n",
    "    \n",
    "    # Load the state dict\n",
    "    tcn_model.load_state_dict(torch.load(tcn_model_file, map_location=device))\n",
    "    tcn_model.to(device)\n",
    "    tcn_model.eval()\n",
    "    \n",
    "    # Get TCN predictions on test data\n",
    "    all_tcn_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = tcn_model(inputs)\n",
    "            all_tcn_preds.extend(outputs.cpu().numpy().flatten())\n",
    "    \n",
    "    # Get the corresponding test data (accounting for sequence length)\n",
    "    y_test_seq_linear = y_test_pred_linear[seq_length:][:len(all_tcn_preds)]\n",
    "    y_test_seq_actual = y_test[seq_length:][:len(all_tcn_preds)]\n",
    "    \n",
    "    # Combine predictions\n",
    "    y_test_combined = y_test_seq_linear + np.array(all_tcn_preds)\n",
    "    \n",
    "    # Create evaluation dataframe\n",
    "    test_eval_df = test_df.iloc[seq_length:].reset_index(drop=True).iloc[:len(all_tcn_preds)].copy()\n",
    "    \n",
    "    # Filter out rows where ride is closed\n",
    "    if 'closed' in test_eval_df.columns:\n",
    "        open_ride_df = test_eval_df[test_eval_df['closed'] == 0]\n",
    "        y_test_open_actual = open_ride_df['wait_time'].values\n",
    "        y_test_open_linear = y_test_seq_linear[open_ride_df.index]\n",
    "        y_test_open_combined = y_test_combined[open_ride_df.index]\n",
    "    else:\n",
    "        y_test_open_actual = y_test_seq_actual\n",
    "        y_test_open_linear = y_test_seq_linear\n",
    "        y_test_open_combined = y_test_combined\n",
    "\n",
    "    linear_mae = mean_absolute_error(y_test_open_actual, y_test_open_linear)\n",
    "    linear_mse = mean_squared_error(y_test_open_actual, y_test_open_linear)\n",
    "    linear_rmse = np.sqrt(linear_mse)\n",
    "    linear_r2 = r2_score(y_test_open_actual, y_test_open_linear)\n",
    "    \n",
    "    combined_mae = mean_absolute_error(y_test_open_actual, y_test_open_combined)\n",
    "    combined_mse = mean_squared_error(y_test_open_actual, y_test_open_combined)\n",
    "    combined_rmse = np.sqrt(combined_mse)\n",
    "    combined_r2 = r2_score(y_test_open_actual, y_test_open_combined)\n",
    "    \n",
    "    print(\"\\nTest Set Evaluation:\")\n",
    "    print(f\"Linear Model - MAE: {linear_mae:.2f}, RMSE: {linear_rmse:.2f}, R²: {linear_r2:.4f}\")\n",
    "    print(f\"Combined Model - MAE: {combined_mae:.2f}, RMSE: {combined_rmse:.2f}, R²: {combined_r2:.4f}\")\n",
    "    print(f\"Improvement - MAE: {linear_mae - combined_mae:.2f} ({(1 - combined_mae/linear_mae) * 100:.2f}%)\")\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(y_test_open_actual[:100], label='Actual')\n",
    "        plt.plot(y_test_open_linear[:100], label='Linear Prediction')\n",
    "        plt.plot(y_test_open_combined[:100], label='Combined Prediction')\n",
    "        plt.legend()\n",
    "        plt.title(f'Actual vs Predicted Wait Times - {target_ride}')\n",
    "        plt.xlabel('Time Step')\n",
    "        plt.ylabel('Wait Time (minutes)')\n",
    "        plt.savefig(f\"{target_ride}_predictions.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Saved plot to {target_ride}_predictions.png\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not create plot: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a64df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769eccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspro2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
