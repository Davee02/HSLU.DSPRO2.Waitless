{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc8ee347",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Define consistent colors for plots\n",
    "TRAIN_COLOR = 'steelblue'\n",
    "TRAIN_FILL_COLOR = 'steelblue'\n",
    "TRAIN_FILL_ALPHA = 0.3\n",
    "VAL_COLOR = 'coral'\n",
    "VAL_FILL_COLOR = 'coral'\n",
    "VAL_FILL_ALPHA = 0.3\n",
    "TEST_COLOR = 'forestgreen'\n",
    "TEST_FILL_COLOR = 'forestgreen'\n",
    "TEST_FILL_ALPHA = 0.3\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fbed08",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c27ecbb6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_parquet(file_path)\n",
    "    return data\n",
    "\n",
    "def check_for_missing_values(data):\n",
    "    missing_values = data.isnull().sum()\n",
    "    if missing_values.any():\n",
    "        print(\"Missing values found in the dataset:\")\n",
    "        print(missing_values[missing_values > 0])\n",
    "    else:\n",
    "        print(\"No missing values found in the dataset.\")\n",
    "    return missing_values\n",
    "\n",
    "def split_data(data, train_years, val_year, test_year):\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    \n",
    "    train_data = data[data['timestamp'].dt.year.isin(train_years)]\n",
    "    val_data = data[data['timestamp'].dt.year == val_year]\n",
    "    test_data = data[data['timestamp'].dt.year == test_year]\n",
    "    \n",
    "    print(f\"Train data size: {len(train_data)}\")\n",
    "    print(f\"Validation data size: {len(val_data)}\")\n",
    "    print(f\"Test data size: {len(test_data)}\")\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def filter_ride_data(data, ride_name):\n",
    "    return data[data[f'ride_name_{ride_name}'] == True].copy()\n",
    "\n",
    "def get_all_rides(data):\n",
    "    ride_columns = [col for col in data.columns if col.startswith('ride_name_')]\n",
    "    return [col.replace('ride_name_', '') for col in ride_columns]\n",
    "\n",
    "def filter_to_operating_hours(ride_data):\n",
    "    # Determine operating hours from data where wait times > 0\n",
    "    operating_hours = ride_data[ride_data[\"wait_time\"] > 0].groupby(\n",
    "        ride_data[\"timestamp\"].dt.date\n",
    "    )[\"timestamp\"].agg(['min', 'max']).reset_index()\n",
    "    \n",
    "    # Extract opening and closing hours\n",
    "    operating_hours['opening_hour'] = pd.to_datetime(operating_hours['min']).dt.hour\n",
    "    operating_hours['closing_hour'] = pd.to_datetime(operating_hours['max']).dt.hour\n",
    "    \n",
    "    # Set reasonable boundaries for operating hours\n",
    "    operating_hours['opening_hour'] = operating_hours['opening_hour'].clip(lower=9, upper=11)\n",
    "    operating_hours['closing_hour'] = operating_hours['closing_hour'].clip(lower=17, upper=21)\n",
    "    \n",
    "    # Create date-to-hours mapping\n",
    "    date_to_hours = {}\n",
    "    for _, row in operating_hours.iterrows():\n",
    "        date_to_hours[row['timestamp']] = (row['opening_hour'], row['closing_hour'])\n",
    "    \n",
    "    # Filter data to operating hours only\n",
    "    def is_operating_hour(timestamp):\n",
    "        date = timestamp.date()\n",
    "        if date not in date_to_hours:\n",
    "            return 0\n",
    "        \n",
    "        open_hour, close_hour = date_to_hours[date]\n",
    "        hour = timestamp.hour\n",
    "        return 1 if open_hour <= hour < close_hour else 0\n",
    "    \n",
    "    ride_data['operating_hour'] = ride_data['timestamp'].apply(is_operating_hour)\n",
    "    ride_data = ride_data[ride_data['operating_hour'] == 1]\n",
    "    ride_data = ride_data.drop(columns=[\"operating_hour\"])\n",
    "    \n",
    "    return ride_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a4b25c",
   "metadata": {},
   "source": [
    "## Time Series Decomposition with Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fee60bb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BaseTimeSeriesModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.forecast = None\n",
    "        self.holidays = None\n",
    "        \n",
    "    def prepare_prophet_dataframe(self, data, include_y=True):\n",
    "        prophet_df = data[['timestamp', 'wait_time', 'temperature_unscaled', 'rain_unscaled', 'is_weekend']].copy()\n",
    "        prophet_df = prophet_df.rename(columns={'timestamp': 'ds', 'wait_time': 'y', 'temperature_unscaled': 'temperature', 'rain_unscaled': 'rain'})\n",
    "\n",
    "        if not include_y:\n",
    "            prophet_df = prophet_df.drop([\"y\"], axis=1) \n",
    "        \n",
    "        # Add additional features\n",
    "        prophet_df['temp_squared'] = prophet_df['temperature'] ** 2\n",
    "        prophet_df['high_temp'] = (prophet_df['temperature'] > 25).astype(int)\n",
    "        prophet_df['any_rain'] = (prophet_df['rain'] > 0).astype(int)\n",
    "        prophet_df['temp_weekend'] = prophet_df['temperature'] * prophet_df['is_weekend']\n",
    "        prophet_df['rain_weekend'] = prophet_df['rain'] * prophet_df['is_weekend']\n",
    "        \n",
    "        return prophet_df\n",
    "    \n",
    "    def create_holiday_dataframes(self, data):\n",
    "        holiday_dfs = []\n",
    "        \n",
    "        # Process country holidays\n",
    "        for country in ['swiss', 'german', 'french']:\n",
    "            holiday_col = f\"is_{country}_holiday\"\n",
    "            if holiday_col in data.columns:\n",
    "                country_holidays = data.loc[data[holiday_col] == 1, [\"timestamp\"]]\n",
    "                if len(country_holidays) > 0:\n",
    "                    country_holidays[\"ds\"] = pd.to_datetime(country_holidays[\"timestamp\"]).dt.date\n",
    "                    country_holidays = country_holidays.drop_duplicates(subset=[\"ds\"])\n",
    "                    country_holidays = country_holidays.drop(columns=[\"timestamp\"])\n",
    "                    country_holidays[\"holiday\"] = f\"{country}_holiday\"\n",
    "                    country_holidays[\"lower_window\"] = 0\n",
    "                    country_holidays[\"upper_window\"] = 0\n",
    "                    holiday_dfs.append(country_holidays.reset_index(drop=True))\n",
    "        # Combine all holidays\n",
    "        if holiday_dfs:\n",
    "            all_holidays = pd.concat(holiday_dfs)\n",
    "            all_holidays[\"ds\"] = pd.to_datetime(all_holidays[\"ds\"])\n",
    "            return all_holidays.sort_values(by=[\"ds\"]).reset_index(drop=True)\n",
    "        return None\n",
    "    \n",
    "    def fit(self, prophet_df):\n",
    "        # Create holidays dataframe\n",
    "        self.holidays = self.create_holiday_dataframes(prophet_df)\n",
    "        \n",
    "        # Create a Prophet model with configuration from prophet_model.py\n",
    "        self.model = Prophet(\n",
    "            # Core parameters\n",
    "            seasonality_mode='multiplicative',  # Better for tourism/attraction data\n",
    "            changepoint_prior_scale=0.05,       # Flexibility in trend changes\n",
    "            changepoint_range=0.95,             # Allow changepoints closer to the end\n",
    "\n",
    "            # Handling seasonality\n",
    "            seasonality_prior_scale=12,         # Stronger seasonality influence\n",
    "            yearly_seasonality=True,            # Capture yearly patterns\n",
    "            weekly_seasonality=True,            # Capture weekly patterns\n",
    "            daily_seasonality=True,             # Custom daily seasonality for operating hours\n",
    "\n",
    "            # Specific to park operation\n",
    "            holidays_prior_scale=15,            # Strong holiday effects for parks\n",
    "            holidays=self.holidays,             # Include holidays and covid periods\n",
    "            interval_width=0.95                 # 95% confidence interval\n",
    "        )\n",
    "\n",
    "        # Add weather and interaction regressors\n",
    "        self.model.add_regressor('temperature', mode='multiplicative', standardize=True)\n",
    "        self.model.add_regressor('rain', mode='multiplicative', standardize=True)\n",
    "        self.model.add_regressor('temp_squared', mode='additive', standardize=True)\n",
    "        self.model.add_regressor('high_temp', mode='multiplicative', standardize=False)\n",
    "        self.model.add_regressor('any_rain', mode='multiplicative', standardize=False)\n",
    "        self.model.add_regressor('temp_weekend', mode='additive', standardize=True)\n",
    "        self.model.add_regressor('rain_weekend', mode='multiplicative', standardize=True)\n",
    "        \n",
    "        prophet_df['between_covid_lockdowns'] = 0\n",
    "        covid_period = (prophet_df['ds'] >= '2020-05-20') & (prophet_df['ds'] <= '2020-11-01')\n",
    "        prophet_df.loc[covid_period, 'between_covid_lockdowns'] = 1\n",
    "        self.model.add_regressor('between_covid_lockdowns')\n",
    "        \n",
    "        prophet_df['covid_recovery'] = 0\n",
    "        recovery_period = (prophet_df['ds'] >= '2021-05-21') & (prophet_df['ds'] <= '2021-08-31')\n",
    "        prophet_df.loc[recovery_period, 'covid_recovery'] = 1\n",
    "        self.model.add_regressor('covid_recovery')\n",
    "\n",
    "        self.model.fit(prophet_df)\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, future_df):\n",
    "        # Add required columns for prediction if they're not already present\n",
    "        future_df = future_df.copy()\n",
    "        \n",
    "        # Add COVID regressors if they're not already present\n",
    "        if 'between_covid_lockdowns' not in future_df.columns:\n",
    "            future_df['between_covid_lockdowns'] = 0\n",
    "            covid_period = (future_df['ds'] >= '2020-05-20') & (future_df['ds'] <= '2020-11-01')\n",
    "            future_df.loc[covid_period, 'between_covid_lockdowns'] = 1\n",
    "            \n",
    "        if 'covid_recovery' not in future_df.columns:\n",
    "            future_df['covid_recovery'] = 0\n",
    "            recovery_period = (future_df['ds'] >= '2021-05-21') & (future_df['ds'] <= '2021-08-31')\n",
    "            future_df.loc[recovery_period, 'covid_recovery'] = 1\n",
    "        \n",
    "        # Make predictions\n",
    "        self.forecast = self.model.predict(future_df)\n",
    "        \n",
    "        # Apply post-processing\n",
    "        self.forecast = self.post_process_forecast(self.forecast)\n",
    "        \n",
    "        return self.forecast\n",
    "    \n",
    "    def post_process_forecast(self, forecast):\n",
    "        forecast = forecast.copy()\n",
    "        \n",
    "        # Correct negative predictions\n",
    "        negative_mask = forecast['yhat'] < 0\n",
    "        forecast.loc[negative_mask, 'yhat'] = 0\n",
    "        forecast.loc[negative_mask, 'yhat_lower'] = 0\n",
    "        forecast.loc[negative_mask, 'yhat_upper'] = 0\n",
    "        \n",
    "        return forecast\n",
    "    \n",
    "    def merge_predictions(self, original_data, forecast_data):\n",
    "        result = original_data.copy()\n",
    "        \n",
    "        # Identify forecast columns to keep\n",
    "        forecast_columns = ['ds', 'trend', 'yhat', 'yhat_lower', 'yhat_upper']\n",
    "        for component in ['weekly', 'daily']:\n",
    "            if component in forecast_data.columns:\n",
    "                forecast_columns.append(component)\n",
    "        \n",
    "        result = pd.merge(\n",
    "            result, \n",
    "            forecast_data[forecast_columns], \n",
    "            left_on='timestamp', \n",
    "            right_on='ds', \n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        result['residual'] = result['wait_time'] - result['yhat']\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d85884",
   "metadata": {},
   "source": [
    "## Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3769869c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_model(ride_df, actual_values, predictions, title=\"\"):\n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(predictions - actual_values))\n",
    "    rmse = np.sqrt(np.mean(np.square(predictions - actual_values)))\n",
    "    \n",
    "    # For sMAPE, avoid division by zero\n",
    "    epsilon = 1e-8\n",
    "    abs_pct_errors = np.abs(predictions - actual_values) / (np.abs(predictions) + np.abs(actual_values) + epsilon)\n",
    "    # Only include points where actual values are non-zero\n",
    "    non_zero_mask = (actual_values > 0) & (predictions > 0)\n",
    "    smape = np.mean(abs_pct_errors[non_zero_mask]) * 100 if np.any(non_zero_mask) else 0\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"\\n{title} MAE: {mae:.2f} minutes\")\n",
    "    print(f\"{title} RMSE: {rmse:.2f} minutes\")\n",
    "    print(f\"{title} sMAPE: {smape:.2f}%\")\n",
    "    \n",
    "    # Create a DataFrame with results for time-based analysis\n",
    "    results_df = pd.DataFrame({\n",
    "        'timestamp': ride_df['timestamp'].values,\n",
    "        'actual': actual_values,\n",
    "        'predicted': predictions,\n",
    "    })\n",
    "    \n",
    "    # Add time components\n",
    "    results_df['hour'] = results_df['timestamp'].dt.hour\n",
    "    results_df['day_of_week'] = results_df['timestamp'].dt.dayofweek\n",
    "    results_df['month'] = results_df['timestamp'].dt.month\n",
    "    \n",
    "    # Calculate errors\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = np.abs(results_df['error'])\n",
    "    results_df['pct_error'] = abs_pct_errors * 100\n",
    "    \n",
    "    # Create metrics dictionary\n",
    "    metrics = {\n",
    "        \"mae\": mae,\n",
    "        \"rmse\": rmse,\n",
    "        \"smape\": smape\n",
    "    }\n",
    "    \n",
    "    return metrics, results_df\n",
    "\n",
    "def create_evaluation_plots(results_df, title=\"\"):\n",
    "    \"\"\"Create evaluation plots for model performance\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Actual vs Predicted scatter plot\n",
    "    axes[0, 0].scatter(results_df['actual'], results_df['predicted'], alpha=0.5)\n",
    "    max_val = max(results_df['actual'].max(), results_df['predicted'].max())\n",
    "    axes[0, 0].plot([0, max_val], [0, max_val], 'k--')\n",
    "    axes[0, 0].set_xlabel('Actual Wait Time (minutes)')\n",
    "    axes[0, 0].set_ylabel('Predicted Wait Time (minutes)')\n",
    "    axes[0, 0].set_title(f'{title} - Actual vs Predicted')\n",
    "    \n",
    "    # Hourly error analysis\n",
    "    hourly_errors = results_df.groupby('hour')['abs_error'].mean()\n",
    "    hourly_errors.plot(kind='bar', ax=axes[0, 1])\n",
    "    axes[0, 1].set_xlabel('Hour of Day')\n",
    "    axes[0, 1].set_ylabel('Mean Absolute Error (minutes)')\n",
    "    axes[0, 1].set_title(f'{title} - Error by Hour')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Residual plot\n",
    "    axes[1, 0].scatter(results_df['predicted'], results_df['error'], alpha=0.5)\n",
    "    axes[1, 0].axhline(y=0, color='k', linestyle='--')\n",
    "    axes[1, 0].set_xlabel('Predicted Wait Time (minutes)')\n",
    "    axes[1, 0].set_ylabel('Residual (minutes)')\n",
    "    axes[1, 0].set_title(f'{title} - Residual Plot')\n",
    "    \n",
    "    # Time series plot (sample)\n",
    "    if len(results_df) > 1000:\n",
    "        # Sample for visualization if too many points\n",
    "        sample_df = results_df.sample(1000).sort_values('timestamp')\n",
    "    else:\n",
    "        sample_df = results_df.sort_values('timestamp')\n",
    "    \n",
    "    axes[1, 1].plot(sample_df['timestamp'], sample_df['actual'], label='Actual', alpha=0.7)\n",
    "    axes[1, 1].plot(sample_df['timestamp'], sample_df['predicted'], label='Predicted', alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('Time')\n",
    "    axes[1, 1].set_ylabel('Wait Time (minutes)')\n",
    "    axes[1, 1].set_title(f'{title} - Time Series (Sample)')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd166411",
   "metadata": {},
   "source": [
    "## Model Storage Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc02ffd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def save_model(ride_name, prophet_model, metrics, output_dir=\"models\"):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create ride-specific directory\n",
    "    ride_dir = os.path.join(output_dir, ride_name.replace(\" \", \"_\"))\n",
    "    os.makedirs(ride_dir, exist_ok=True)\n",
    "    \n",
    "    # Save Prophet model (using pickle)\n",
    "    with open(os.path.join(ride_dir, \"prophet_model.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(prophet_model.model, f)\n",
    "    \n",
    "    # Save holidays if they exist\n",
    "    if prophet_model.holidays is not None:\n",
    "        prophet_model.holidays.to_csv(os.path.join(ride_dir, \"holidays.csv\"), index=False)\n",
    "    \n",
    "    # Save metrics\n",
    "    with open(os.path.join(ride_dir, \"metrics.json\"), \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "    \n",
    "    print(f\"Models and results saved to {ride_dir}\")\n",
    "\n",
    "def load_model(ride_name, output_dir=\"models\"):\n",
    "    # Create ride-specific directory path\n",
    "    ride_dir = os.path.join(output_dir, ride_name.replace(\" \", \"_\"))\n",
    "    \n",
    "    # Check if models exist\n",
    "    if not os.path.exists(ride_dir):\n",
    "        return None, None\n",
    "    \n",
    "    # Load Prophet model\n",
    "    try:\n",
    "        with open(os.path.join(ride_dir, \"prophet_model.pkl\"), \"rb\") as f:\n",
    "            prophet_model_obj = pickle.load(f)\n",
    "    except:\n",
    "        print(f\"Could not load model for {ride_name}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Initialize BaseTimeSeriesModel and set the loaded model\n",
    "    prophet_ts = BaseTimeSeriesModel()\n",
    "    prophet_ts.model = prophet_model_obj\n",
    "    \n",
    "    # Load holidays if they exist\n",
    "    if os.path.exists(os.path.join(ride_dir, \"holidays.csv\")):\n",
    "        prophet_ts.holidays = pd.read_csv(os.path.join(ride_dir, \"holidays.csv\"))\n",
    "    \n",
    "    # Load metrics\n",
    "    with open(os.path.join(ride_dir, \"metrics.json\"), \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    return prophet_ts, metrics\n",
    "\n",
    "def get_processed_rides(output_dir=\"models\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        return []\n",
    "    \n",
    "    # Get all subdirectories in the output directory\n",
    "    processed_rides = [d for d in os.listdir(output_dir) \n",
    "                      if os.path.isdir(os.path.join(output_dir, d))]\n",
    "    \n",
    "    # Convert directory names back to ride names\n",
    "    processed_rides = [ride.replace(\"_\", \" \") for ride in processed_rides]\n",
    "    \n",
    "    return processed_rides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22897f71",
   "metadata": {},
   "source": [
    "## Multi-Ride Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd86f802",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_checkpoint_file(processed_rides, output_dir=\"models\"):\n",
    "    checkpoint_path = os.path.join(output_dir, \"checkpoint.json\")\n",
    "    with open(checkpoint_path, \"w\") as f:\n",
    "        json.dump({\"processed_rides\": processed_rides}, f, indent=4)\n",
    "\n",
    "def load_checkpoint_file(output_dir=\"models\"):\n",
    "    checkpoint_path = os.path.join(output_dir, \"checkpoint.json\")\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        with open(checkpoint_path, \"r\") as f:\n",
    "            checkpoint = json.load(f)\n",
    "        return checkpoint.get(\"processed_rides\", [])\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40c3d83",
   "metadata": {},
   "source": [
    "## Training Pipeline for Single Ride (Extended with Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "578157e0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process_single_ride_extended(ride_name, train_data, val_data, test_data, output_dir=\"models\"):\n",
    "    \"\"\"Process a single ride with both validation and test set evaluation.\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing ride: {ride_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Filter data for the current ride\n",
    "    ride_train_data = filter_ride_data(train_data, ride_name)\n",
    "    ride_val_data = filter_ride_data(val_data, ride_name)\n",
    "    ride_test_data = filter_ride_data(test_data, ride_name)\n",
    "    \n",
    "    print(f\"Training data size: {len(ride_train_data)}\")\n",
    "    print(f\"Validation data size: {len(ride_val_data)}\")\n",
    "    print(f\"Test data size: {len(ride_test_data)}\")\n",
    "    \n",
    "    # Skip if not enough data\n",
    "    if len(ride_train_data) < 100 or len(ride_val_data) < 50 or len(ride_test_data) < 50:\n",
    "        print(f\"Skipping {ride_name} due to insufficient data\")\n",
    "        return None\n",
    "    \n",
    "    # VALIDATION EVALUATION: Train on train data only, evaluate on validation set\n",
    "    print(\"Training Prophet model on train data for validation evaluation...\")\n",
    "    prophet_val = BaseTimeSeriesModel()\n",
    "    prophet_val_df = prophet_val.prepare_prophet_dataframe(ride_train_data)\n",
    "    prophet_val.fit(prophet_val_df)\n",
    "    \n",
    "    # Generate forecasts for validation data\n",
    "    print(\"Evaluating on validation set...\")\n",
    "    future_val = prophet_val.prepare_prophet_dataframe(ride_val_data, include_y=False)\n",
    "    val_forecast = prophet_val.predict(future_val)\n",
    "    \n",
    "    # Merge predictions with validation data\n",
    "    ride_val_data_with_forecast = pd.merge(\n",
    "        ride_val_data,\n",
    "        val_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']],\n",
    "        left_on='timestamp', \n",
    "        right_on='ds',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_actuals = ride_val_data_with_forecast['wait_time'].values\n",
    "    val_predictions = ride_val_data_with_forecast['yhat'].values\n",
    "    val_metrics, val_results_df = evaluate_model(\n",
    "        ride_val_data_with_forecast, val_actuals, val_predictions, \n",
    "        title=f\"{ride_name} - Validation\"\n",
    "    )\n",
    "    \n",
    "    # TEST EVALUATION: Train on combined train + validation data, evaluate on test set\n",
    "    print(\"Training Prophet model on combined train + validation data for test evaluation...\")\n",
    "    combined_train_val = pd.concat([ride_train_data, ride_val_data], ignore_index=True)\n",
    "    prophet_test = BaseTimeSeriesModel()\n",
    "    prophet_test_df = prophet_test.prepare_prophet_dataframe(combined_train_val)\n",
    "    prophet_test.fit(prophet_test_df)\n",
    "    \n",
    "    # Generate forecasts for test data\n",
    "    print(\"Evaluating on test set...\")\n",
    "    future_test = prophet_test.prepare_prophet_dataframe(ride_test_data, include_y=False)\n",
    "    test_forecast = prophet_test.predict(future_test)\n",
    "    \n",
    "    # Merge predictions with test data\n",
    "    ride_test_data_with_forecast = pd.merge(\n",
    "        ride_test_data,\n",
    "        test_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']],\n",
    "        left_on='timestamp', \n",
    "        right_on='ds',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_actuals = ride_test_data_with_forecast['wait_time'].values\n",
    "    test_predictions = ride_test_data_with_forecast['yhat'].values\n",
    "    test_metrics, test_results_df = evaluate_model(\n",
    "        ride_test_data_with_forecast, test_actuals, test_predictions, \n",
    "        title=f\"{ride_name} - Test\"\n",
    "    )\n",
    "    \n",
    "    # Create figures directory\n",
    "    fig_dir = os.path.join(output_dir, ride_name.replace(\" \", \"_\"), \"figures\")\n",
    "    os.makedirs(fig_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model components visualization (using test model which is trained on more data)\n",
    "    fig_components = prophet_test.model.plot_components(test_forecast, figsize=(14, 10))\n",
    "    fig_components.savefig(os.path.join(fig_dir, \"model_components.png\"))\n",
    "    plt.close(fig_components)\n",
    "\n",
    "    # Save evaluation figures\n",
    "    fig_val_eval = create_evaluation_plots(val_results_df, f\"{ride_name} - Validation\")\n",
    "    fig_val_eval.savefig(os.path.join(fig_dir, \"validation_evaluation.png\"))\n",
    "    plt.close(fig_val_eval)\n",
    "    \n",
    "    fig_test_eval = create_evaluation_plots(test_results_df, f\"{ride_name} - Test\")\n",
    "    fig_test_eval.savefig(os.path.join(fig_dir, \"test_evaluation.png\"))\n",
    "    plt.close(fig_test_eval)\n",
    "    \n",
    "    # Prepare combined metrics\n",
    "    combined_metrics = {\n",
    "        \"validation\": val_metrics,\n",
    "        \"test\": test_metrics,\n",
    "        \"data_counts\": {\n",
    "            \"train\": len(ride_train_data),\n",
    "            \"validation\": len(ride_val_data),\n",
    "            \"test\": len(ride_test_data),\n",
    "            \"combined_train_val\": len(combined_train_val)\n",
    "        },\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    \n",
    "    # Save models and results (save the test model which is trained on more data)\n",
    "    save_model(ride_name, prophet_test, combined_metrics, output_dir)\n",
    "    \n",
    "    # Save detailed results as CSV\n",
    "    results_dir = os.path.join(output_dir, ride_name.replace(\" \", \"_\"), \"results\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    val_results_df.to_csv(os.path.join(results_dir, \"validation_results.csv\"), index=False)\n",
    "    test_results_df.to_csv(os.path.join(results_dir, \"test_results.csv\"), index=False)\n",
    "    \n",
    "    return combined_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054e7b17",
   "metadata": {},
   "source": [
    "## Training Pipeline for All Rides (Extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f176a0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_summary_report_extended(all_results, output_dir=\"models\"):\n",
    "    \"\"\"Generate comprehensive summary report for both validation and test sets.\"\"\"\n",
    "    # Create lists to store summary data\n",
    "    summary_data = []\n",
    "    \n",
    "    # Extract data from results\n",
    "    for ride_name, metrics in all_results.items():\n",
    "        if not metrics:\n",
    "            continue\n",
    "        \n",
    "        # Base ride info\n",
    "        base_info = {\n",
    "            \"ride_name\": ride_name,\n",
    "            \"train_data_size\": metrics.get(\"data_counts\", {}).get(\"train\", 0),\n",
    "            \"val_data_size\": metrics.get(\"data_counts\", {}).get(\"validation\", 0),\n",
    "            \"test_data_size\": metrics.get(\"data_counts\", {}).get(\"test\", 0),\n",
    "            \"combined_train_val_size\": metrics.get(\"data_counts\", {}).get(\"combined_train_val\", 0)\n",
    "        }\n",
    "        \n",
    "        # Add validation metrics\n",
    "        if \"validation\" in metrics:\n",
    "            val_row = base_info.copy()\n",
    "            val_row[\"dataset\"] = \"validation\"\n",
    "            val_metrics = metrics[\"validation\"]\n",
    "            val_row[\"mae\"] = val_metrics.get(\"mae\", float('nan'))\n",
    "            val_row[\"rmse\"] = val_metrics.get(\"rmse\", float('nan'))\n",
    "            val_row[\"smape\"] = val_metrics.get(\"smape\", float('nan'))\n",
    "            summary_data.append(val_row)\n",
    "        \n",
    "        # Add test metrics\n",
    "        if \"test\" in metrics:\n",
    "            test_row = base_info.copy()\n",
    "            test_row[\"dataset\"] = \"test\"\n",
    "            test_metrics = metrics[\"test\"]\n",
    "            test_row[\"mae\"] = test_metrics.get(\"mae\", float('nan'))\n",
    "            test_row[\"rmse\"] = test_metrics.get(\"rmse\", float('nan'))\n",
    "            test_row[\"smape\"] = test_metrics.get(\"smape\", float('nan'))\n",
    "            summary_data.append(test_row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    detailed_summary = pd.DataFrame(summary_data)\n",
    "    \n",
    "    if len(detailed_summary) == 0:\n",
    "        print(\"No results to summarize.\")\n",
    "        return None\n",
    "    \n",
    "    # Save detailed summary\n",
    "    detailed_path = os.path.join(output_dir, \"detailed_prophet_summary_extended.csv\")\n",
    "    detailed_summary.to_csv(detailed_path, index=False)\n",
    "    \n",
    "    # Create aggregated summary for each dataset\n",
    "    val_summary = detailed_summary[detailed_summary['dataset'] == 'validation'].groupby('dataset').agg({\n",
    "        'mae': ['mean', 'std', 'median'],\n",
    "        'rmse': ['mean', 'std', 'median'],\n",
    "        'smape': ['mean', 'std', 'median']\n",
    "    }).round(2)\n",
    "    \n",
    "    test_summary = detailed_summary[detailed_summary['dataset'] == 'test'].groupby('dataset').agg({\n",
    "        'mae': ['mean', 'std', 'median'],\n",
    "        'rmse': ['mean', 'std', 'median'],\n",
    "        'smape': ['mean', 'std', 'median']\n",
    "    }).round(2)\n",
    "    \n",
    "    # Create simple summary DataFrame for comparison\n",
    "    simple_summary = []\n",
    "    \n",
    "    val_data = detailed_summary[detailed_summary['dataset'] == 'validation']\n",
    "    test_data = detailed_summary[detailed_summary['dataset'] == 'test']\n",
    "    \n",
    "    if len(val_data) > 0:\n",
    "        simple_summary.append({\n",
    "            'dataset': 'validation',\n",
    "            'count': len(val_data),\n",
    "            'mae_mean': val_data['mae'].mean(),\n",
    "            'mae_std': val_data['mae'].std(),\n",
    "            'rmse_mean': val_data['rmse'].mean(),\n",
    "            'rmse_std': val_data['rmse'].std(),\n",
    "            'smape_mean': val_data['smape'].mean(),\n",
    "            'smape_std': val_data['smape'].std()\n",
    "        })\n",
    "    \n",
    "    if len(test_data) > 0:\n",
    "        simple_summary.append({\n",
    "            'dataset': 'test',\n",
    "            'count': len(test_data),\n",
    "            'mae_mean': test_data['mae'].mean(),\n",
    "            'mae_std': test_data['mae'].std(),\n",
    "            'rmse_mean': test_data['rmse'].mean(),\n",
    "            'rmse_std': test_data['rmse'].std(),\n",
    "            'smape_mean': test_data['smape'].mean(),\n",
    "            'smape_std': test_data['smape'].std()\n",
    "        })\n",
    "    \n",
    "    simple_summary_df = pd.DataFrame(simple_summary)\n",
    "    \n",
    "    # Save simple summary\n",
    "    simple_path = os.path.join(output_dir, \"prophet_summary_extended.csv\")\n",
    "    simple_summary_df.to_csv(simple_path, index=False)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROPHET MODEL SUMMARY (VALIDATION & TEST SETS):\")\n",
    "    print(f\"Total rides processed: {detailed_summary['ride_name'].nunique()}\")\n",
    "    \n",
    "    if len(val_data) > 0:\n",
    "        print(f\"\\nValidation Set Performance:\")\n",
    "        print(f\"  Average MAE: {val_data['mae'].mean():.2f} ± {val_data['mae'].std():.2f}\")\n",
    "        print(f\"  Average RMSE: {val_data['rmse'].mean():.2f} ± {val_data['rmse'].std():.2f}\")\n",
    "        print(f\"  Average sMAPE: {val_data['smape'].mean():.2f}% ± {val_data['smape'].std():.2f}%\")\n",
    "    \n",
    "    if len(test_data) > 0:\n",
    "        print(f\"\\nTest Set Performance:\")\n",
    "        print(f\"  Average MAE: {test_data['mae'].mean():.2f} ± {test_data['mae'].std():.2f}\")\n",
    "        print(f\"  Average RMSE: {test_data['rmse'].mean():.2f} ± {test_data['rmse'].std():.2f}\")\n",
    "        print(f\"  Average sMAPE: {test_data['smape'].mean():.2f}% ± {test_data['smape'].std():.2f}%\")\n",
    "    \n",
    "    print(f\"\\nDetailed summary saved to: {detailed_path}\")\n",
    "    print(f\"Simple summary saved to: {simple_path}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_prophet_visualizations_extended(detailed_summary, simple_summary_df, output_dir)\n",
    "    \n",
    "    return detailed_summary, simple_summary_df\n",
    "\n",
    "def create_prophet_visualizations_extended(detailed_summary, simple_summary_df, output_dir):\n",
    "    \"\"\"Create visualizations for Prophet model results including both validation and test sets.\"\"\"\n",
    "    \n",
    "    # 1. Performance comparison (validation vs test)\n",
    "    if len(simple_summary_df) == 2:\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        datasets = simple_summary_df['dataset']\n",
    "        mae_means = simple_summary_df['mae_mean']\n",
    "        mae_stds = simple_summary_df['mae_std']\n",
    "        \n",
    "        x = np.arange(len(datasets))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars = plt.bar(x, mae_means, width, yerr=mae_stds, capsize=5, \n",
    "                      color=[VAL_COLOR if d == 'validation' else TEST_COLOR for d in datasets],\n",
    "                      alpha=0.8)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, mean_val in zip(bars, mae_means):\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + max(mae_means) * 0.01,\n",
    "                    f'{mean_val:.2f}', ha='center', va='bottom', fontsize=16)\n",
    "        \n",
    "        plt.title('Prophet Model: Average MAE Comparison (Validation vs Test)', fontsize=20)\n",
    "        plt.xlabel('Dataset', fontsize=14)\n",
    "        plt.ylabel('Average MAE (minutes)', fontsize=14)\n",
    "        plt.xticks(x, datasets)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"prophet_val_vs_test_comparison.png\"))\n",
    "        plt.savefig(os.path.join(output_dir, \"prophet_val_vs_test_comparison.svg\"))\n",
    "        plt.close()\n",
    "    \n",
    "    # 2. Distribution comparison\n",
    "    val_data = detailed_summary[detailed_summary['dataset'] == 'validation']\n",
    "    test_data = detailed_summary[detailed_summary['dataset'] == 'test']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    \n",
    "    # MAE distribution\n",
    "    if len(val_data) > 0:\n",
    "        axes[0].hist(val_data['mae'], bins=15, alpha=0.7, label='Validation', color=VAL_COLOR)\n",
    "    if len(test_data) > 0:\n",
    "        axes[0].hist(test_data['mae'], bins=15, alpha=0.7, label='Test', color=TEST_COLOR)\n",
    "    axes[0].set_xlabel('MAE (minutes)')\n",
    "    axes[0].set_ylabel('Number of Rides')\n",
    "    axes[0].set_title('MAE Distribution')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # RMSE distribution\n",
    "    if len(val_data) > 0:\n",
    "        axes[1].hist(val_data['rmse'], bins=15, alpha=0.7, label='Validation', color=VAL_COLOR)\n",
    "    if len(test_data) > 0:\n",
    "        axes[1].hist(test_data['rmse'], bins=15, alpha=0.7, label='Test', color=TEST_COLOR)\n",
    "    axes[1].set_xlabel('RMSE (minutes)')\n",
    "    axes[1].set_ylabel('Number of Rides')\n",
    "    axes[1].set_title('RMSE Distribution')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    # sMAPE distribution\n",
    "    if len(val_data) > 0:\n",
    "        axes[2].hist(val_data['smape'], bins=15, alpha=0.7, label='Validation', color=VAL_COLOR)\n",
    "    if len(test_data) > 0:\n",
    "        axes[2].hist(test_data['smape'], bins=15, alpha=0.7, label='Test', color=TEST_COLOR)\n",
    "    axes[2].set_xlabel('sMAPE (%)')\n",
    "    axes[2].set_ylabel('Number of Rides')\n",
    "    axes[2].set_title('sMAPE Distribution')\n",
    "    axes[2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"prophet_metrics_distribution_extended.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Ride performance ranking (test set)\n",
    "    if len(test_data) > 0:\n",
    "        test_sorted = test_data.sort_values('mae')\n",
    "        \n",
    "        plt.figure(figsize=(16, 10))\n",
    "        bars = plt.barh(range(len(test_sorted)), test_sorted['mae'], alpha=0.8, color=TEST_COLOR)\n",
    "        \n",
    "        plt.title('Prophet Model: Test Set MAE by Ride', fontsize=20, fontweight='bold')\n",
    "        plt.xlabel('Mean Absolute Error (MAE) - Minutes', fontsize=16)\n",
    "        plt.ylabel('Rides', fontsize=16)\n",
    "        plt.yticks(range(len(test_sorted)), test_sorted['ride_name'], fontsize=14)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, (bar, mae_val) in enumerate(zip(bars, test_sorted['mae'])):\n",
    "            plt.text(bar.get_width() + max(test_sorted['mae']) * 0.01, \n",
    "                    bar.get_y() + bar.get_height()/2, \n",
    "                    f'{mae_val:.1f}', ha='left', va='center', fontsize=16)\n",
    "        \n",
    "        plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"prophet_mae_by_ride_test.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(os.path.join(output_dir, \"prophet_mae_by_ride_test.svg\"), bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"Extended Prophet visualizations saved to output directory.\")\n",
    "\n",
    "def process_all_rides_extended(all_rides, train_data, val_data, test_data,\n",
    "                              output_dir=\"models\", resume=True):\n",
    "    \"\"\"Process all rides with Prophet models on both validation and test sets.\"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get list of already processed rides\n",
    "    processed_rides = []\n",
    "    if resume:\n",
    "        processed_rides = load_checkpoint_file(output_dir)\n",
    "        if processed_rides:\n",
    "            print(f\"Resuming from checkpoint. {len(processed_rides)} rides already processed.\")\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    all_results = {}\n",
    "    \n",
    "    # Process each ride\n",
    "    for i, ride_name in enumerate(tqdm(all_rides, desc=\"Processing rides\")):\n",
    "        if ride_name in processed_rides:\n",
    "            print(f\"Skipping {ride_name} (already processed)\")\n",
    "            # Load metrics for the summary\n",
    "            _, metrics = load_model(ride_name, output_dir)\n",
    "            if metrics:\n",
    "                all_results[ride_name] = metrics\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing ride {i+1}/{len(all_rides)}: {ride_name}\")\n",
    "        ride_metrics = process_single_ride_extended(ride_name, train_data, val_data, test_data,\n",
    "                                                   output_dir=output_dir)\n",
    "        \n",
    "        if ride_metrics:\n",
    "            all_results[ride_name] = ride_metrics\n",
    "            processed_rides.append(ride_name)\n",
    "            \n",
    "            # Update checkpoint after each ride\n",
    "            create_checkpoint_file(processed_rides, output_dir)\n",
    "    \n",
    "    # Generate summary report\n",
    "    generate_summary_report_extended(all_results, output_dir)\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83aab0c",
   "metadata": {},
   "source": [
    "## Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af52ee15",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def analyze_prophet_results_extended(output_dir=\"../models/prophet_enhanced/\"):\n",
    "    \"\"\"Load and analyze saved Prophet model results for both validation and test sets.\"\"\"\n",
    "    \n",
    "    # Check if summary files exist\n",
    "    detailed_path = os.path.join(output_dir, \"detailed_prophet_summary_extended.csv\")\n",
    "    simple_path = os.path.join(output_dir, \"prophet_summary_extended.csv\")\n",
    "    \n",
    "    if not os.path.exists(detailed_path) or not os.path.exists(simple_path):\n",
    "        print(\"Extended summary files not found. Run the processing pipeline first.\")\n",
    "        return None\n",
    "    \n",
    "    # Load summary data\n",
    "    detailed_summary = pd.read_csv(detailed_path)\n",
    "    simple_summary = pd.read_csv(simple_path)\n",
    "    \n",
    "    # Display key insights\n",
    "    print(\"=\"*60)\n",
    "    print(\"PROPHET MODEL ANALYSIS (VALIDATION & TEST SETS)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Split by dataset\n",
    "    val_data = detailed_summary[detailed_summary['dataset'] == 'validation']\n",
    "    test_data = detailed_summary[detailed_summary['dataset'] == 'test']\n",
    "    \n",
    "    print(\"\\n1. Overall Performance Summary:\")\n",
    "    print(simple_summary)\n",
    "    \n",
    "    if len(val_data) > 0:\n",
    "        print(\"\\n2. Validation Set - Top 10 rides (lowest MAE):\")\n",
    "        val_sorted = val_data.sort_values('mae')\n",
    "        print(val_sorted.head(10)[['ride_name', 'mae', 'rmse', 'smape']])\n",
    "    \n",
    "    if len(test_data) > 0:\n",
    "        print(\"\\n3. Test Set - Top 10 rides (lowest MAE):\")\n",
    "        test_sorted = test_data.sort_values('mae')\n",
    "        print(test_sorted.head(10)[['ride_name', 'mae', 'rmse', 'smape']])\n",
    "    \n",
    "    if len(val_data) > 0 and len(test_data) > 0:\n",
    "        print(\"\\n4. Validation vs Test Performance Comparison:\")\n",
    "        val_avg = val_data.groupby('dataset')[['mae', 'rmse', 'smape']].mean()\n",
    "        test_avg = test_data.groupby('dataset')[['mae', 'rmse', 'smape']].mean()\n",
    "        comparison_df = pd.concat([val_avg, test_avg])\n",
    "        print(comparison_df)\n",
    "    \n",
    "    return {\n",
    "        'detailed_summary': detailed_summary,\n",
    "        'simple_summary': simple_summary,\n",
    "        'val_data': val_data,\n",
    "        'test_data': test_data\n",
    "    }\n",
    "\n",
    "def create_prophet_method_summary_csv(all_results, output_dir=\"../models/prophet_enhanced/\", filename=\"prophet_method_summary.csv\"):\n",
    "    \"\"\"\n",
    "    Create a CSV file with Prophet model performance metrics in the same format as baselines.\n",
    "    \n",
    "    Args:\n",
    "        all_results: Dictionary containing all Prophet model results\n",
    "        output_dir: Directory to save the CSV file\n",
    "        filename: Name of the output CSV file\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Summary dataframe\n",
    "    \"\"\"\n",
    "    # Initialize data for Prophet\n",
    "    val_mae_values = []\n",
    "    val_rmse_values = []\n",
    "    val_smape_values = []\n",
    "    test_mae_values = []\n",
    "    test_rmse_values = []\n",
    "    test_smape_values = []\n",
    "    \n",
    "    # Collect metrics from all rides\n",
    "    for ride_name, ride_results in all_results.items():\n",
    "        if \"validation\" in ride_results:\n",
    "            val_metrics = ride_results[\"validation\"]\n",
    "            if \"mae\" in val_metrics and not np.isinf(val_metrics[\"mae\"]):\n",
    "                val_mae_values.append(val_metrics[\"mae\"])\n",
    "            if \"rmse\" in val_metrics and not np.isinf(val_metrics[\"rmse\"]):\n",
    "                val_rmse_values.append(val_metrics[\"rmse\"])\n",
    "            if \"smape\" in val_metrics and not np.isinf(val_metrics[\"smape\"]):\n",
    "                val_smape_values.append(val_metrics[\"smape\"])\n",
    "        \n",
    "        if \"test\" in ride_results:\n",
    "            test_metrics = ride_results[\"test\"]\n",
    "            if \"mae\" in test_metrics and not np.isinf(test_metrics[\"mae\"]):\n",
    "                test_mae_values.append(test_metrics[\"mae\"])\n",
    "            if \"rmse\" in test_metrics and not np.isinf(test_metrics[\"rmse\"]):\n",
    "                test_rmse_values.append(test_metrics[\"rmse\"])\n",
    "            if \"smape\" in test_metrics and not np.isinf(test_metrics[\"smape\"]):\n",
    "                test_smape_values.append(test_metrics[\"smape\"])\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    val_mae_avg = np.mean(val_mae_values) if val_mae_values else np.nan\n",
    "    val_rmse_avg = np.mean(val_rmse_values) if val_rmse_values else np.nan\n",
    "    val_smape_avg = np.mean(val_smape_values) if val_smape_values else np.nan\n",
    "    \n",
    "    test_mae_avg = np.mean(test_mae_values) if test_mae_values else np.nan\n",
    "    test_rmse_avg = np.mean(test_rmse_values) if test_rmse_values else np.nan\n",
    "    test_smape_avg = np.mean(test_smape_values) if test_smape_values else np.nan\n",
    "    \n",
    "    # Create summary data\n",
    "    summary_data = [{\n",
    "        'method_name': 'Prophet Enhanced',\n",
    "        'val_mae': val_mae_avg,\n",
    "        'val_rmse': val_rmse_avg,\n",
    "        'val_smape': val_smape_avg,\n",
    "        'test_mae': test_mae_avg,\n",
    "        'test_rmse': test_rmse_avg,\n",
    "        'test_smape': test_smape_avg\n",
    "    }]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Round values to 2 decimal places\n",
    "    numeric_columns = ['val_mae', 'val_rmse', 'val_smape', 'test_mae', 'test_rmse', 'test_smape']\n",
    "    for col in numeric_columns:\n",
    "        summary_df[col] = summary_df[col].round(2)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save to CSV with semicolon separator\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    summary_df.to_csv(output_path, sep=';', index=False)\n",
    "    \n",
    "    print(f\"Prophet method summary CSV saved to: {output_path}\")\n",
    "    print(\"\\nProphet model performance:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66147e",
   "metadata": {},
   "source": [
    "## Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bfeb617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded data with 7834739 rows\n",
      "No missing values found in the dataset.\n",
      "Train data size: 297362\n",
      "Validation data size: 61851\n",
      "Test data size: 55699\n",
      "Found 31 rides in the dataset:\n",
      "1. alpine express enzian\n",
      "2. arena of football  be part of it\n",
      "3. arthur\n",
      "4. atlantica supersplash\n",
      "5. atlantis adventure\n",
      "6. baaa express\n",
      "7. blue fire megacoaster\n",
      "8. castello dei medici\n",
      "9. dancing dingie\n",
      "10. euromir\n",
      "11. eurosat  cancan coaster\n",
      "12. eurotower\n",
      "13. fjordrafting\n",
      "14. jim button  journey through morrowland\n",
      "15. josefinas magical imperial journey\n",
      "16. kolumbusjolle\n",
      "17. madame freudenreich curiosits\n",
      "18. matterhornblitz\n",
      "19. old mac donalds tractor fun\n",
      "20. pegasus\n",
      "21. poppy towers\n",
      "22. poseidon\n",
      "23. silver star\n",
      "24. swiss bob run\n",
      "25. tirol log flume\n",
      "26. vienna wave swing  glckspilz\n",
      "27. vindjammer\n",
      "28. voletarium\n",
      "29. volo da vinci\n",
      "30. voltron nevera powered by rimac\n",
      "31. whale adventures  northern lights\n",
      "\n",
      "============================================================\n",
      "STARTING PROPHET MODEL PROCESSING FOR ALL RIDES (VALIDATION & TEST SETS)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:   0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ride 1/31: alpine express enzian\n",
      "\n",
      "==================================================\n",
      "Processing ride: alpine express enzian\n",
      "==================================================\n",
      "Training data size: 10302\n",
      "Validation data size: 2019\n",
      "Test data size: 1753\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:38:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:38:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "alpine express enzian - Validation MAE: 7.96 minutes\n",
      "alpine express enzian - Validation RMSE: 9.96 minutes\n",
      "alpine express enzian - Validation sMAPE: 28.06%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:38:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:38:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "alpine express enzian - Test MAE: 15.59 minutes\n",
      "alpine express enzian - Test RMSE: 19.08 minutes\n",
      "alpine express enzian - Test sMAPE: 26.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:   3%|▎         | 1/31 [00:16<08:27, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/alpine_express_enzian\n",
      "\n",
      "Processing ride 2/31: arena of football  be part of it\n",
      "\n",
      "==================================================\n",
      "Processing ride: arena of football  be part of it\n",
      "==================================================\n",
      "Training data size: 9612\n",
      "Validation data size: 2052\n",
      "Test data size: 1816\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:39:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:39:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "arena of football  be part of it - Validation MAE: 9.24 minutes\n",
      "arena of football  be part of it - Validation RMSE: 11.26 minutes\n",
      "arena of football  be part of it - Validation sMAPE: 42.75%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:39:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:39:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "arena of football  be part of it - Test MAE: 4.93 minutes\n",
      "arena of football  be part of it - Test RMSE: 5.08 minutes\n",
      "arena of football  be part of it - Test sMAPE: 95.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:   6%|▋         | 2/31 [00:39<09:41, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/arena_of_football__be_part_of_it\n",
      "\n",
      "Processing ride 3/31: arthur\n",
      "\n",
      "==================================================\n",
      "Processing ride: arthur\n",
      "==================================================\n",
      "Training data size: 10298\n",
      "Validation data size: 2067\n",
      "Test data size: 1832\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:39:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:39:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "arthur - Validation MAE: 23.45 minutes\n",
      "arthur - Validation RMSE: 27.85 minutes\n",
      "arthur - Validation sMAPE: 32.22%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:39:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:39:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "arthur - Test MAE: 7.48 minutes\n",
      "arthur - Test RMSE: 10.30 minutes\n",
      "arthur - Test sMAPE: 14.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  10%|▉         | 3/31 [01:04<10:28, 22.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/arthur\n",
      "\n",
      "Processing ride 4/31: atlantica supersplash\n",
      "\n",
      "==================================================\n",
      "Processing ride: atlantica supersplash\n",
      "==================================================\n",
      "Training data size: 9825\n",
      "Validation data size: 2065\n",
      "Test data size: 1826\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:39:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:39:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "atlantica supersplash - Validation MAE: 19.51 minutes\n",
      "atlantica supersplash - Validation RMSE: 23.63 minutes\n",
      "atlantica supersplash - Validation sMAPE: 39.99%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:39:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:40:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "atlantica supersplash - Test MAE: 12.11 minutes\n",
      "atlantica supersplash - Test RMSE: 17.90 minutes\n",
      "atlantica supersplash - Test sMAPE: 51.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  13%|█▎        | 4/31 [01:26<10:02, 22.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/atlantica_supersplash\n",
      "\n",
      "Processing ride 5/31: atlantis adventure\n",
      "\n",
      "==================================================\n",
      "Processing ride: atlantis adventure\n",
      "==================================================\n",
      "Training data size: 10289\n",
      "Validation data size: 2066\n",
      "Test data size: 1832\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:40:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:40:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "atlantis adventure - Validation MAE: 4.11 minutes\n",
      "atlantis adventure - Validation RMSE: 5.38 minutes\n",
      "atlantis adventure - Validation sMAPE: 23.89%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:40:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:40:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "atlantis adventure - Test MAE: 2.07 minutes\n",
      "atlantis adventure - Test RMSE: 2.69 minutes\n",
      "atlantis adventure - Test sMAPE: 40.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  16%|█▌        | 5/31 [01:48<09:38, 22.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/atlantis_adventure\n",
      "\n",
      "Processing ride 6/31: baaa express\n",
      "\n",
      "==================================================\n",
      "Processing ride: baaa express\n",
      "==================================================\n",
      "Training data size: 10291\n",
      "Validation data size: 2067\n",
      "Test data size: 1824\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:40:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:40:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "baaa express - Validation MAE: 4.60 minutes\n",
      "baaa express - Validation RMSE: 5.86 minutes\n",
      "baaa express - Validation sMAPE: 27.28%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:40:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:40:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "baaa express - Test MAE: 4.66 minutes\n",
      "baaa express - Test RMSE: 6.64 minutes\n",
      "baaa express - Test sMAPE: 50.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  19%|█▉        | 6/31 [01:57<07:24, 17.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/baaa_express\n",
      "\n",
      "Processing ride 7/31: blue fire megacoaster\n",
      "\n",
      "==================================================\n",
      "Processing ride: blue fire megacoaster\n",
      "==================================================\n",
      "Training data size: 10288\n",
      "Validation data size: 2067\n",
      "Test data size: 1823\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:40:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:40:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "blue fire megacoaster - Validation MAE: 17.44 minutes\n",
      "blue fire megacoaster - Validation RMSE: 21.31 minutes\n",
      "blue fire megacoaster - Validation sMAPE: 27.41%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:40:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:41:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "blue fire megacoaster - Test MAE: 17.13 minutes\n",
      "blue fire megacoaster - Test RMSE: 22.92 minutes\n",
      "blue fire megacoaster - Test sMAPE: 45.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  23%|██▎       | 7/31 [02:35<09:39, 24.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/blue_fire_megacoaster\n",
      "\n",
      "Processing ride 8/31: castello dei medici\n",
      "\n",
      "==================================================\n",
      "Processing ride: castello dei medici\n",
      "==================================================\n",
      "Training data size: 10193\n",
      "Validation data size: 2066\n",
      "Test data size: 1143\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:41:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:41:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "castello dei medici - Validation MAE: 3.50 minutes\n",
      "castello dei medici - Validation RMSE: 4.24 minutes\n",
      "castello dei medici - Validation sMAPE: 12.76%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:41:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:41:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "castello dei medici - Test MAE: 4.69 minutes\n",
      "castello dei medici - Test RMSE: 5.38 minutes\n",
      "castello dei medici - Test sMAPE: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  26%|██▌       | 8/31 [02:58<09:09, 23.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/castello_dei_medici\n",
      "\n",
      "Processing ride 9/31: dancing dingie\n",
      "\n",
      "==================================================\n",
      "Processing ride: dancing dingie\n",
      "==================================================\n",
      "Training data size: 10292\n",
      "Validation data size: 2066\n",
      "Test data size: 1824\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:41:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:41:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "dancing dingie - Validation MAE: 3.44 minutes\n",
      "dancing dingie - Validation RMSE: 4.51 minutes\n",
      "dancing dingie - Validation sMAPE: 25.19%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:41:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:42:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "dancing dingie - Test MAE: 2.43 minutes\n",
      "dancing dingie - Test RMSE: 3.30 minutes\n",
      "dancing dingie - Test sMAPE: 27.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  29%|██▉       | 9/31 [03:21<08:36, 23.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/dancing_dingie\n",
      "\n",
      "Processing ride 10/31: euromir\n",
      "\n",
      "==================================================\n",
      "Processing ride: euromir\n",
      "==================================================\n",
      "Training data size: 10289\n",
      "Validation data size: 2049\n",
      "Test data size: 1832\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:42:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:42:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "euromir - Validation MAE: 10.67 minutes\n",
      "euromir - Validation RMSE: 13.93 minutes\n",
      "euromir - Validation sMAPE: 24.05%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:42:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:42:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "euromir - Test MAE: 17.07 minutes\n",
      "euromir - Test RMSE: 21.67 minutes\n",
      "euromir - Test sMAPE: 67.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  32%|███▏      | 10/31 [03:46<08:24, 24.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/euromir\n",
      "\n",
      "Processing ride 11/31: eurosat  cancan coaster\n",
      "\n",
      "==================================================\n",
      "Processing ride: eurosat  cancan coaster\n",
      "==================================================\n",
      "Training data size: 8650\n",
      "Validation data size: 2067\n",
      "Test data size: 1832\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:42:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:42:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "eurosat  cancan coaster - Validation MAE: 10.79 minutes\n",
      "eurosat  cancan coaster - Validation RMSE: 13.68 minutes\n",
      "eurosat  cancan coaster - Validation sMAPE: 20.50%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:42:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:42:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "eurosat  cancan coaster - Test MAE: 22.10 minutes\n",
      "eurosat  cancan coaster - Test RMSE: 25.68 minutes\n",
      "eurosat  cancan coaster - Test sMAPE: 66.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  35%|███▌      | 11/31 [04:04<07:23, 22.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/eurosat__cancan_coaster\n",
      "\n",
      "Processing ride 12/31: eurotower\n",
      "\n",
      "==================================================\n",
      "Processing ride: eurotower\n",
      "==================================================\n",
      "Training data size: 10308\n",
      "Validation data size: 2067\n",
      "Test data size: 1824\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:42:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:42:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "eurotower - Validation MAE: 3.24 minutes\n",
      "eurotower - Validation RMSE: 4.92 minutes\n",
      "eurotower - Validation sMAPE: 19.93%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:42:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:42:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "eurotower - Test MAE: 7.37 minutes\n",
      "eurotower - Test RMSE: 9.14 minutes\n",
      "eurotower - Test sMAPE: 66.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  39%|███▊      | 12/31 [04:16<06:03, 19.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/eurotower\n",
      "\n",
      "Processing ride 13/31: fjordrafting\n",
      "\n",
      "==================================================\n",
      "Processing ride: fjordrafting\n",
      "==================================================\n",
      "Training data size: 9808\n",
      "Validation data size: 2066\n",
      "Test data size: 1825\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:43:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:43:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "fjordrafting - Validation MAE: 7.80 minutes\n",
      "fjordrafting - Validation RMSE: 10.14 minutes\n",
      "fjordrafting - Validation sMAPE: 24.12%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:43:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:43:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "fjordrafting - Test MAE: 14.28 minutes\n",
      "fjordrafting - Test RMSE: 19.81 minutes\n",
      "fjordrafting - Test sMAPE: 43.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  42%|████▏     | 13/31 [04:41<06:15, 20.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/fjordrafting\n",
      "\n",
      "Processing ride 14/31: jim button  journey through morrowland\n",
      "\n",
      "==================================================\n",
      "Processing ride: jim button  journey through morrowland\n",
      "==================================================\n",
      "Training data size: 8597\n",
      "Validation data size: 2065\n",
      "Test data size: 1820\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:43:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:43:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "jim button  journey through morrowland - Validation MAE: 3.62 minutes\n",
      "jim button  journey through morrowland - Validation RMSE: 4.33 minutes\n",
      "jim button  journey through morrowland - Validation sMAPE: 17.24%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:43:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:43:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "jim button  journey through morrowland - Test MAE: 2.05 minutes\n",
      "jim button  journey through morrowland - Test RMSE: 2.51 minutes\n",
      "jim button  journey through morrowland - Test sMAPE: 36.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  45%|████▌     | 14/31 [04:51<05:01, 17.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/jim_button__journey_through_morrowland\n",
      "\n",
      "Processing ride 15/31: josefinas magical imperial journey\n",
      "\n",
      "==================================================\n",
      "Processing ride: josefinas magical imperial journey\n",
      "==================================================\n",
      "Training data size: 10266\n",
      "Validation data size: 2067\n",
      "Test data size: 1821\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:43:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:43:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "josefinas magical imperial journey - Validation MAE: 4.71 minutes\n",
      "josefinas magical imperial journey - Validation RMSE: 6.19 minutes\n",
      "josefinas magical imperial journey - Validation sMAPE: 24.70%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:43:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:43:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "josefinas magical imperial journey - Test MAE: 2.57 minutes\n",
      "josefinas magical imperial journey - Test RMSE: 3.56 minutes\n",
      "josefinas magical imperial journey - Test sMAPE: 28.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  48%|████▊     | 15/31 [05:11<04:52, 18.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/josefinas_magical_imperial_journey\n",
      "\n",
      "Processing ride 16/31: kolumbusjolle\n",
      "\n",
      "==================================================\n",
      "Processing ride: kolumbusjolle\n",
      "==================================================\n",
      "Training data size: 10300\n",
      "Validation data size: 2067\n",
      "Test data size: 1821\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:43:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:43:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "kolumbusjolle - Validation MAE: 1.35 minutes\n",
      "kolumbusjolle - Validation RMSE: 1.89 minutes\n",
      "kolumbusjolle - Validation sMAPE: 14.35%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:43:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:44:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "kolumbusjolle - Test MAE: 1.20 minutes\n",
      "kolumbusjolle - Test RMSE: 1.76 minutes\n",
      "kolumbusjolle - Test sMAPE: 9.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  52%|█████▏    | 16/31 [05:20<03:51, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/kolumbusjolle\n",
      "\n",
      "Processing ride 17/31: madame freudenreich curiosits\n",
      "\n",
      "==================================================\n",
      "Processing ride: madame freudenreich curiosits\n",
      "==================================================\n",
      "Training data size: 8643\n",
      "Validation data size: 2066\n",
      "Test data size: 1832\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:44:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:44:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "madame freudenreich curiosits - Validation MAE: 0.07 minutes\n",
      "madame freudenreich curiosits - Validation RMSE: 0.54 minutes\n",
      "madame freudenreich curiosits - Validation sMAPE: 99.40%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:44:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:44:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "madame freudenreich curiosits - Test MAE: 0.27 minutes\n",
      "madame freudenreich curiosits - Test RMSE: 0.65 minutes\n",
      "madame freudenreich curiosits - Test sMAPE: 85.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  55%|█████▍    | 17/31 [05:39<03:50, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/madame_freudenreich_curiosits\n",
      "\n",
      "Processing ride 18/31: matterhornblitz\n",
      "\n",
      "==================================================\n",
      "Processing ride: matterhornblitz\n",
      "==================================================\n",
      "Training data size: 10299\n",
      "Validation data size: 2065\n",
      "Test data size: 1830\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:44:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:44:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "matterhornblitz - Validation MAE: 9.75 minutes\n",
      "matterhornblitz - Validation RMSE: 12.71 minutes\n",
      "matterhornblitz - Validation sMAPE: 18.23%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:44:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:44:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "matterhornblitz - Test MAE: 19.64 minutes\n",
      "matterhornblitz - Test RMSE: 23.71 minutes\n",
      "matterhornblitz - Test sMAPE: 65.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  58%|█████▊    | 18/31 [05:52<03:22, 15.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/matterhornblitz\n",
      "\n",
      "Processing ride 19/31: old mac donalds tractor fun\n",
      "\n",
      "==================================================\n",
      "Processing ride: old mac donalds tractor fun\n",
      "==================================================\n",
      "Training data size: 10292\n",
      "Validation data size: 2065\n",
      "Test data size: 1818\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:44:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:44:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "old mac donalds tractor fun - Validation MAE: 1.89 minutes\n",
      "old mac donalds tractor fun - Validation RMSE: 2.44 minutes\n",
      "old mac donalds tractor fun - Validation sMAPE: 38.95%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:44:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:44:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "old mac donalds tractor fun - Test MAE: 1.82 minutes\n",
      "old mac donalds tractor fun - Test RMSE: 2.54 minutes\n",
      "old mac donalds tractor fun - Test sMAPE: 59.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  61%|██████▏   | 19/31 [06:04<02:53, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/old_mac_donalds_tractor_fun\n",
      "\n",
      "Processing ride 20/31: pegasus\n",
      "\n",
      "==================================================\n",
      "Processing ride: pegasus\n",
      "==================================================\n",
      "Training data size: 10299\n",
      "Validation data size: 2067\n",
      "Test data size: 1831\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:44:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:44:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "pegasus - Validation MAE: 7.80 minutes\n",
      "pegasus - Validation RMSE: 10.05 minutes\n",
      "pegasus - Validation sMAPE: 32.09%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:44:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:45:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "pegasus - Test MAE: 6.36 minutes\n",
      "pegasus - Test RMSE: 9.33 minutes\n",
      "pegasus - Test sMAPE: 40.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  65%|██████▍   | 20/31 [06:19<02:40, 14.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/pegasus\n",
      "\n",
      "Processing ride 21/31: poppy towers\n",
      "\n",
      "==================================================\n",
      "Processing ride: poppy towers\n",
      "==================================================\n",
      "Training data size: 10276\n",
      "Validation data size: 2065\n",
      "Test data size: 1822\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:45:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:45:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "poppy towers - Validation MAE: 1.93 minutes\n",
      "poppy towers - Validation RMSE: 2.60 minutes\n",
      "poppy towers - Validation sMAPE: 21.54%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:45:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:45:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "poppy towers - Test MAE: 3.17 minutes\n",
      "poppy towers - Test RMSE: 3.46 minutes\n",
      "poppy towers - Test sMAPE: 50.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  68%|██████▊   | 21/31 [06:36<02:33, 15.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/poppy_towers\n",
      "\n",
      "Processing ride 22/31: poseidon\n",
      "\n",
      "==================================================\n",
      "Processing ride: poseidon\n",
      "==================================================\n",
      "Training data size: 9832\n",
      "Validation data size: 2064\n",
      "Test data size: 1826\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:45:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:45:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "poseidon - Validation MAE: 8.21 minutes\n",
      "poseidon - Validation RMSE: 11.32 minutes\n",
      "poseidon - Validation sMAPE: 19.56%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:45:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:45:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "poseidon - Test MAE: 13.27 minutes\n",
      "poseidon - Test RMSE: 21.38 minutes\n",
      "poseidon - Test sMAPE: 73.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  71%|███████   | 22/31 [06:46<02:04, 13.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/poseidon\n",
      "\n",
      "Processing ride 23/31: silver star\n",
      "\n",
      "==================================================\n",
      "Processing ride: silver star\n",
      "==================================================\n",
      "Training data size: 10244\n",
      "Validation data size: 2064\n",
      "Test data size: 1826\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:45:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:45:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "silver star - Validation MAE: 9.07 minutes\n",
      "silver star - Validation RMSE: 11.66 minutes\n",
      "silver star - Validation sMAPE: 21.60%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:45:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:45:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "silver star - Test MAE: 8.65 minutes\n",
      "silver star - Test RMSE: 11.81 minutes\n",
      "silver star - Test sMAPE: 21.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  74%|███████▍  | 23/31 [06:58<01:45, 13.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/silver_star\n",
      "\n",
      "Processing ride 24/31: swiss bob run\n",
      "\n",
      "==================================================\n",
      "Processing ride: swiss bob run\n",
      "==================================================\n",
      "Training data size: 10293\n",
      "Validation data size: 2066\n",
      "Test data size: 1826\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:45:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:45:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "swiss bob run - Validation MAE: 6.74 minutes\n",
      "swiss bob run - Validation RMSE: 9.12 minutes\n",
      "swiss bob run - Validation sMAPE: 14.36%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:45:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:45:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "swiss bob run - Test MAE: 7.84 minutes\n",
      "swiss bob run - Test RMSE: 10.27 minutes\n",
      "swiss bob run - Test sMAPE: 19.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  77%|███████▋  | 24/31 [07:06<01:22, 11.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/swiss_bob_run\n",
      "\n",
      "Processing ride 25/31: tirol log flume\n",
      "\n",
      "==================================================\n",
      "Processing ride: tirol log flume\n",
      "==================================================\n",
      "Training data size: 9849\n",
      "Validation data size: 2019\n",
      "Test data size: 1752\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:45:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:45:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "tirol log flume - Validation MAE: 7.83 minutes\n",
      "tirol log flume - Validation RMSE: 11.43 minutes\n",
      "tirol log flume - Validation sMAPE: 35.72%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:45:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:46:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "tirol log flume - Test MAE: 44.43 minutes\n",
      "tirol log flume - Test RMSE: 51.52 minutes\n",
      "tirol log flume - Test sMAPE: 54.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  81%|████████  | 25/31 [07:18<01:10, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/tirol_log_flume\n",
      "\n",
      "Processing ride 26/31: vienna wave swing  glckspilz\n",
      "\n",
      "==================================================\n",
      "Processing ride: vienna wave swing  glckspilz\n",
      "==================================================\n",
      "Training data size: 8416\n",
      "Validation data size: 2067\n",
      "Test data size: 1822\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:46:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:46:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "vienna wave swing  glckspilz - Validation MAE: 2.19 minutes\n",
      "vienna wave swing  glckspilz - Validation RMSE: 2.69 minutes\n",
      "vienna wave swing  glckspilz - Validation sMAPE: 18.45%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:46:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:46:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "vienna wave swing  glckspilz - Test MAE: 1.33 minutes\n",
      "vienna wave swing  glckspilz - Test RMSE: 1.81 minutes\n",
      "vienna wave swing  glckspilz - Test sMAPE: 12.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  84%|████████▍ | 26/31 [07:25<00:52, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/vienna_wave_swing__glckspilz\n",
      "\n",
      "Processing ride 27/31: vindjammer\n",
      "\n",
      "==================================================\n",
      "Processing ride: vindjammer\n",
      "==================================================\n",
      "Training data size: 10258\n",
      "Validation data size: 2064\n",
      "Test data size: 1802\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:46:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:46:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "vindjammer - Validation MAE: 2.39 minutes\n",
      "vindjammer - Validation RMSE: 3.08 minutes\n",
      "vindjammer - Validation sMAPE: 19.63%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:46:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:46:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "vindjammer - Test MAE: 2.32 minutes\n",
      "vindjammer - Test RMSE: 2.90 minutes\n",
      "vindjammer - Test sMAPE: 29.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  87%|████████▋ | 27/31 [07:39<00:45, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/vindjammer\n",
      "\n",
      "Processing ride 28/31: voletarium\n",
      "\n",
      "==================================================\n",
      "Processing ride: voletarium\n",
      "==================================================\n",
      "Training data size: 8430\n",
      "Validation data size: 2067\n",
      "Test data size: 1832\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:46:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:46:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "voletarium - Validation MAE: 13.99 minutes\n",
      "voletarium - Validation RMSE: 19.32 minutes\n",
      "voletarium - Validation sMAPE: 38.49%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:46:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:46:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "voletarium - Test MAE: 21.51 minutes\n",
      "voletarium - Test RMSE: 26.96 minutes\n",
      "voletarium - Test sMAPE: 65.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  90%|█████████ | 28/31 [07:55<00:38, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/voletarium\n",
      "\n",
      "Processing ride 29/31: volo da vinci\n",
      "\n",
      "==================================================\n",
      "Processing ride: volo da vinci\n",
      "==================================================\n",
      "Training data size: 10309\n",
      "Validation data size: 2066\n",
      "Test data size: 1830\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:46:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:46:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "volo da vinci - Validation MAE: 4.95 minutes\n",
      "volo da vinci - Validation RMSE: 6.26 minutes\n",
      "volo da vinci - Validation sMAPE: 19.15%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:46:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:46:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "volo da vinci - Test MAE: 7.45 minutes\n",
      "volo da vinci - Test RMSE: 9.36 minutes\n",
      "volo da vinci - Test sMAPE: 43.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides:  94%|█████████▎| 29/31 [08:13<00:28, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/volo_da_vinci\n",
      "\n",
      "Processing ride 30/31: voltron nevera powered by rimac\n",
      "\n",
      "==================================================\n",
      "Processing ride: voltron nevera powered by rimac\n",
      "==================================================\n",
      "Training data size: 0\n",
      "Validation data size: 0\n",
      "Test data size: 1770\n",
      "Skipping voltron nevera powered by rimac due to insufficient data\n",
      "\n",
      "Processing ride 31/31: whale adventures  northern lights\n",
      "\n",
      "==================================================\n",
      "Processing ride: whale adventures  northern lights\n",
      "==================================================\n",
      "Training data size: 10314\n",
      "Validation data size: 2063\n",
      "Test data size: 1832\n",
      "Training Prophet model on train data for validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:46:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:47:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation set...\n",
      "\n",
      "whale adventures  northern lights - Validation MAE: 0.94 minutes\n",
      "whale adventures  northern lights - Validation RMSE: 2.47 minutes\n",
      "whale adventures  northern lights - Validation sMAPE: 92.22%\n",
      "Training Prophet model on combined train + validation data for test evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:47:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:47:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "\n",
      "whale adventures  northern lights - Test MAE: 1.26 minutes\n",
      "whale adventures  northern lights - Test RMSE: 2.85 minutes\n",
      "whale adventures  northern lights - Test sMAPE: 75.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rides: 100%|██████████| 31/31 [08:39<00:00, 16.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and results saved to ../models/prophet_enhanced_extended/whale_adventures__northern_lights\n",
      "\n",
      "================================================================================\n",
      "PROPHET MODEL SUMMARY (VALIDATION & TEST SETS):\n",
      "Total rides processed: 30\n",
      "\n",
      "Validation Set Performance:\n",
      "  Average MAE: 7.10 ± 5.64\n",
      "  Average RMSE: 9.16 ± 6.84\n",
      "  Average sMAPE: 29.79% ± 19.66%\n",
      "\n",
      "Test Set Performance:\n",
      "  Average MAE: 9.24 ± 9.40\n",
      "  Average RMSE: 11.87 ± 11.29\n",
      "  Average sMAPE: 45.50% ± 23.69%\n",
      "\n",
      "Detailed summary saved to: ../models/prophet_enhanced_extended/detailed_prophet_summary_extended.csv\n",
      "Simple summary saved to: ../models/prophet_enhanced_extended/prophet_summary_extended.csv\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended Prophet visualizations saved to output directory.\n",
      "\n",
      "============================================================\n",
      "PROPHET MODEL PROCESSING COMPLETED\n",
      "============================================================\n",
      "============================================================\n",
      "PROPHET MODEL ANALYSIS (VALIDATION & TEST SETS)\n",
      "============================================================\n",
      "\n",
      "1. Overall Performance Summary:\n",
      "      dataset  count  mae_mean   mae_std  rmse_mean   rmse_std  smape_mean  \\\n",
      "0  validation     30  7.104824  5.635081   9.159882   6.840383   29.794987   \n",
      "1        test     30  9.235983  9.399306  11.865569  11.287848   45.495572   \n",
      "\n",
      "   smape_std  \n",
      "0  19.660159  \n",
      "1  23.691822  \n",
      "\n",
      "2. Validation Set - Top 10 rides (lowest MAE):\n",
      "                            ride_name       mae      rmse      smape\n",
      "32      madame freudenreich curiosits  0.067799  0.538258  99.403340\n",
      "58  whale adventures  northern lights  0.938673  2.467813  92.219341\n",
      "30                      kolumbusjolle  1.348201  1.886739  14.349242\n",
      "36        old mac donalds tractor fun  1.886466  2.437464  38.950417\n",
      "40                       poppy towers  1.933295  2.600554  21.541371\n",
      "50       vienna wave swing  glckspilz  2.188961  2.688666  18.453290\n",
      "52                         vindjammer  2.385782  3.080116  19.634775\n",
      "22                          eurotower  3.243853  4.920032  19.934691\n",
      "16                     dancing dingie  3.435152  4.509491  25.193178\n",
      "14                castello dei medici  3.495330  4.242565  12.758473\n",
      "\n",
      "3. Test Set - Top 10 rides (lowest MAE):\n",
      "                                 ride_name       mae      rmse      smape\n",
      "33           madame freudenreich curiosits  0.274711  0.652057  85.069042\n",
      "31                           kolumbusjolle  1.198191  1.756801   9.550812\n",
      "59       whale adventures  northern lights  1.257202  2.845277  75.239485\n",
      "51            vienna wave swing  glckspilz  1.334251  1.810414  12.413205\n",
      "37             old mac donalds tractor fun  1.821257  2.539070  59.207665\n",
      "27  jim button  journey through morrowland  2.051548  2.511614  36.948866\n",
      "9                       atlantis adventure  2.066609  2.694630  40.397698\n",
      "53                              vindjammer  2.324498  2.902633  29.115357\n",
      "17                          dancing dingie  2.425416  3.295068  27.273136\n",
      "29      josefinas magical imperial journey  2.570647  3.563201  28.533321\n",
      "\n",
      "4. Validation vs Test Performance Comparison:\n",
      "                 mae       rmse      smape\n",
      "dataset                                   \n",
      "validation  7.104824   9.159882  29.794987\n",
      "test        9.235983  11.865569  45.495572\n",
      "Prophet method summary CSV saved to: ../models/prophet_enhanced_extended/prophet_method_summary.csv\n",
      "\n",
      "Prophet model performance:\n",
      "     method_name  val_mae  val_rmse  val_smape  test_mae  test_rmse  test_smape\n",
      "Prophet Enhanced      7.1      9.16      29.79      9.24      11.87        45.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method_name</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_rmse</th>\n",
       "      <th>val_smape</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_smape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prophet Enhanced</td>\n",
       "      <td>7.1</td>\n",
       "      <td>9.16</td>\n",
       "      <td>29.79</td>\n",
       "      <td>9.24</td>\n",
       "      <td>11.87</td>\n",
       "      <td>45.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method_name  val_mae  val_rmse  val_smape  test_mae  test_rmse  \\\n",
       "0  Prophet Enhanced      7.1      9.16      29.79      9.24      11.87   \n",
       "\n",
       "   test_smape  \n",
       "0        45.5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "data = load_data(\"../data/processed/ep/final_cleaned_processed_wait_times.parquet\")\n",
    "print(f\"Loaded data with {len(data)} rows\")\n",
    "\n",
    "check_for_missing_values(data)\n",
    "\n",
    "data = filter_to_operating_hours(data)\n",
    "\n",
    "# Define time periods for splitting\n",
    "train_years, val_year, test_year = list(range(2017, 2023)), 2023, 2024\n",
    "\n",
    "# Split the data\n",
    "train_data, val_data, test_data = split_data(data, train_years, val_year, test_year)\n",
    "\n",
    "# Get all rides in the dataset\n",
    "all_rides = get_all_rides(data)\n",
    "print(f\"Found {len(all_rides)} rides in the dataset:\")\n",
    "for i, ride in enumerate(all_rides):\n",
    "    print(f\"{i+1}. {ride}\")\n",
    "\n",
    "# Set output directory for models and results\n",
    "output_dir = \"../models/prophet_enhanced_extended/\"\n",
    "\n",
    "# Process all rides with extended evaluation (including test set)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING PROPHET MODEL PROCESSING FOR ALL RIDES (VALIDATION & TEST SETS)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = process_all_rides_extended(\n",
    "    all_rides=all_rides,\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    test_data=test_data,\n",
    "    output_dir=output_dir,\n",
    "    resume=True  # Resume from checkpoint if available\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROPHET MODEL PROCESSING COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze the extended results\n",
    "results_analysis = analyze_prophet_results_extended(output_dir)\n",
    "\n",
    "# Create method summary CSV for comparison with baselines\n",
    "create_prophet_method_summary_csv(results, output_dir)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "dspro2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
