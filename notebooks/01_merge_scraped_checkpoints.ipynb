{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure that checkpoints exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_save_dir = \"../data/raw/checkpoints\"\n",
    "merged_save_dir = \"../data/raw\"\n",
    "\n",
    "if not os.path.exists(checkpoint_save_dir):\n",
    "    print(\"Checkpoint directory does not exist. RUn the 01_queue-times-scrape.py script first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 folders: ['309', '51']\n"
     ]
    }
   ],
   "source": [
    "folders = [os.path.basename(folder) for folder in glob.glob(checkpoint_save_dir + \"/*\")]\n",
    "\n",
    "print(f\"Found {len(folders)} folders: {folders}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all scraped checkpoint files and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files_in_dir(dir_name):\n",
    "  ride_files = glob.glob(os.path.join(checkpoint_save_dir, dir_name, \"ride_queue_times_checkpoint_*.parquet\"))\n",
    "  weather_files = glob.glob(os.path.join(checkpoint_save_dir, dir_name, \"weather_data_checkpoint_*.parquet\"))\n",
    "  save_dir = os.path.join(merged_save_dir, dir_name)\n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "  print(f\"Found {len(ride_files)} ride checkpoints and {len(weather_files)} weather checkpoints.\")\n",
    "\n",
    "  if ride_files:\n",
    "      ride_dfs = [pd.read_parquet(file) for file in ride_files]\n",
    "\n",
    "      merged_rides = pd.concat([df for df in ride_dfs if not df.empty], ignore_index=True)\n",
    "      merged_rides.to_parquet(os.path.join(merged_save_dir, dir_name, \"merged_rides.parquet\"), engine=\"pyarrow\")\n",
    "      print(f\"Merged {len(ride_files)} ride checkpoint files with {len(merged_rides)} entries into 'merged_rides.parquet'\")\n",
    "  else:\n",
    "      print(\"No ride checkpoint files found.\")\n",
    "\n",
    "  if weather_files:\n",
    "      weather_dfs = [pd.read_parquet(file) for file in weather_files]\n",
    "\n",
    "      merged_weather = pd.concat([df for df in weather_dfs if not df.empty], ignore_index=True)\n",
    "      merged_weather.to_parquet(os.path.join(merged_save_dir, dir_name, \"merged_weather.parquet\"), engine=\"pyarrow\")\n",
    "      print(f\"Merged {len(weather_files)} weather checkpoint files with {len(merged_weather)} entries into 'merged_weather.parquet'\")\n",
    "  else:\n",
    "      print(\"No weather checkpoint files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 ride checkpoints and 50 weather checkpoints.\n",
      "Merged 50 ride checkpoint files with 2215265 entries into 'merged_rides.parquet'\n",
      "Merged 50 weather checkpoint files with 18191 entries into 'merged_weather.parquet'\n",
      "Found 75 ride checkpoints and 75 weather checkpoints.\n",
      "Merged 75 ride checkpoint files with 6268117 entries into 'merged_rides.parquet'\n",
      "Merged 75 weather checkpoint files with 19943 entries into 'merged_weather.parquet'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_647816/1473639731.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_weather = pd.concat([df for df in weather_dfs if not df.empty], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "for folder in folders:\n",
    "    merge_files_in_dir(folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspro2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
